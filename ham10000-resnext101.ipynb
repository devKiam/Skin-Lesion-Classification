{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6699621,"sourceType":"datasetVersion","datasetId":3861661},{"sourceId":7081071,"sourceType":"datasetVersion","datasetId":3259629}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\n\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:01:56.504158Z","iopub.execute_input":"2023-12-03T16:01:56.504426Z","iopub.status.idle":"2023-12-03T16:02:00.408619Z","shell.execute_reply.started":"2023-12-03T16:01:56.504401Z","shell.execute_reply":"2023-12-03T16:02:00.407542Z"},"trusted":true},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'2.0.0'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:00.417108Z","iopub.execute_input":"2023-12-03T16:02:00.417425Z","iopub.status.idle":"2023-12-03T16:02:00.504749Z","shell.execute_reply.started":"2023-12-03T16:02:00.417395Z","shell.execute_reply":"2023-12-03T16:02:00.503622Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import os\nimport zipfile\n\nfrom pathlib import Path\nimport random\nimport shutil\nfrom shutil import copyfile\n\nimport requests\nimport pandas as pd\n\n# Setup path to data folder\ndata_path = Path(\"/kaggle/input/ham10000-splitted/Images splitted/Splitted\")\nimage_path = data_path ","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:00.507802Z","iopub.execute_input":"2023-12-03T16:02:00.508366Z","iopub.status.idle":"2023-12-03T16:02:01.039482Z","shell.execute_reply.started":"2023-12-03T16:02:00.508332Z","shell.execute_reply":"2023-12-03T16:02:01.038475Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"classes = os.listdir(f'{image_path}/train')\nclasses_no_of_data_dict = {}\n# classes.remove(\"desktop.ini\")\nclasses\n\nfor i in range(len(classes)):\n    classes_no_of_data_dict[classes[i]] = len(os.listdir(f'{image_path}/train/{classes[i]}'))\n    \n# for i in range(len(classes)):\n#     temp = len(os.listdir(f'{image_path}/test/{classes[i]}'))\n#     classes_no_of_data_dict[classes[i]] = classes_no_of_data_dict[classes[i]] + temp\n\nclasses_no_of_data_dict","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:01.048313Z","iopub.execute_input":"2023-12-03T16:02:01.048609Z","iopub.status.idle":"2023-12-03T16:02:03.602377Z","shell.execute_reply.started":"2023-12-03T16:02:01.048581Z","shell.execute_reply":"2023-12-03T16:02:03.601428Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'mel': 891,\n 'vasc': 114,\n 'df': 93,\n 'nv': 5365,\n 'bkl': 880,\n 'akiec': 262,\n 'bcc': 412}"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# classlist = os.listdir(image_path_all)    \n# filepaths = []\n# labels = []\n\n\n# for klass in classlist:\n#     classpath=os.path.join(image_path_all,klass)\n#     if os.path.isdir(classpath):\n#         flist=os.listdir(classpath)        \n#         for f in flist:\n#             fpath=os.path.join(classpath,f)        \n#             filepaths.append(fpath)\n#             labels.append(klass)\n            \n# Fseries=pd.Series(filepaths, name='filepaths')\n# Lseries=pd.Series(labels, name='labels')    \n# df=pd.concat([Fseries, Lseries], axis=1)  \n\n\n# print (df.head())\n# print('df length: ', len(df))\n# print (df['labels'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:04.244401Z","iopub.execute_input":"2023-12-03T16:02:04.244710Z","iopub.status.idle":"2023-12-03T16:02:04.249245Z","shell.execute_reply.started":"2023-12-03T16:02:04.244684Z","shell.execute_reply":"2023-12-03T16:02:04.248293Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# import shutil\n# from shutil import copyfile\n\n# working_dir = data_path\n\n# aug_dir=os.path.join(working_dir, 'aug')\n\n# if os.path.isdir(aug_dir):\n#     shutil.rmtree(aug_dir)\n# os.mkdir(aug_dir)\n\n# for label in df['labels'].unique():\n#     dir_path=os.path.join(aug_dir,label)    \n#     os.mkdir(dir_path)\n    \n# print(os.listdir(aug_dir))","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:04.250340Z","iopub.execute_input":"2023-12-03T16:02:04.250654Z","iopub.status.idle":"2023-12-03T16:02:04.259613Z","shell.execute_reply.started":"2023-12-03T16:02:04.250629Z","shell.execute_reply":"2023-12-03T16:02:04.258904Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Setup train and testing paths\ntrain_dir = image_path / \"train\"\ntest_dir = image_path / \"test\"\n\ntrain_dir, test_dir","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:04.331932Z","iopub.execute_input":"2023-12-03T16:02:04.332241Z","iopub.status.idle":"2023-12-03T16:02:04.347941Z","shell.execute_reply.started":"2023-12-03T16:02:04.332218Z","shell.execute_reply":"2023-12-03T16:02:04.347007Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(PosixPath('/kaggle/input/ham10000-splitted/Images splitted/Splitted/train'),\n PosixPath('/kaggle/input/ham10000-splitted/Images splitted/Splitted/test'))"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torchvision.transforms.functional import InterpolationMode\n\n# Create image size (from Table 3 in the ViT paper) \nIMG_SIZE = 224\n# IMG_SIZE = 64\n# IMG_SIZE = 56\n# IMG_SIZE = 150\n# IMG_SIZE = 450\n# IMG_SIZE = 600\n\n# Create transform pipeline manually   \ndata_transform = transforms.Compose([\n#     transforms.CenterCrop(200),\n#     transforms.RandAugment(num_ops = 8, \n#                            magnitude = 9, \n#                            num_magnitude_bins = 31, \n#                            interpolation = InterpolationMode.BILINEAR, \n#                            ),\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n#     transforms.RandomRotation((-120,120)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n#     transforms.RandomAffine(degrees=360, scale=(1.0, 1.3)),\n#     transforms.RandomAdjustSharpness(sharpness_factor=0),\n#     transforms.RandomAdjustSharpness(sharpness_factor=2),\n    transforms.RandomPerspective(distortion_scale=0.2),\n    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    \n    # Calculated for train data\n    transforms.Normalize([0.5018, 0.5015, 0.5013], [0.1029, 0.0985, 0.0807]),\n])     \n\nprint(f\"Manually created transforms: {data_transform}\")\n\n\n\n\n\ndata_transform_test = transforms.Compose([\n#     transforms.CenterCrop(200),\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n\n    # Calculated for test data\n    transforms.Normalize([0.5018, 0.5015, 0.5013], [0.1029, 0.0985, 0.0807]),\n])  \n\n\n# Use ImageFolder to create dataset(s)\ntrain_data = datasets.ImageFolder(root=train_dir, # target folder of images\n                                  transform=data_transform, # transforms to perform on data (images)\n                                  target_transform=None) # transforms to perform on labels (if necessary)\n\n\ntest_data = datasets.ImageFolder(root=test_dir,\n                                 transform=data_transform_test,\n                                )\n\nprint(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:04.349336Z","iopub.execute_input":"2023-12-03T16:02:04.349643Z","iopub.status.idle":"2023-12-03T16:02:14.754807Z","shell.execute_reply.started":"2023-12-03T16:02:04.349613Z","shell.execute_reply":"2023-12-03T16:02:14.753834Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Manually created transforms: Compose(\n    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n    ToTensor()\n    RandomHorizontalFlip(p=0.5)\n    RandomVerticalFlip(p=0.5)\n    RandomPerspective(p=0.5)\n    Normalize(mean=[0.5018, 0.5015, 0.5013], std=[0.1029, 0.0985, 0.0807])\n)\nTrain data:\nDataset ImageFolder\n    Number of datapoints: 8017\n    Root location: /kaggle/input/ham10000-splitted/Images splitted/Splitted/train\n    StandardTransform\nTransform: Compose(\n               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n               ToTensor()\n               RandomHorizontalFlip(p=0.5)\n               RandomVerticalFlip(p=0.5)\n               RandomPerspective(p=0.5)\n               Normalize(mean=[0.5018, 0.5015, 0.5013], std=[0.1029, 0.0985, 0.0807])\n           )\nTest data:\nDataset ImageFolder\n    Number of datapoints: 1998\n    Root location: /kaggle/input/ham10000-splitted/Images splitted/Splitted/test\n    StandardTransform\nTransform: Compose(\n               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n               ToTensor()\n               Normalize(mean=[0.5018, 0.5015, 0.5013], std=[0.1029, 0.0985, 0.0807])\n           )\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### 2.2 Auto Transform","metadata":{}},{"cell_type":"code","source":"import torchvision\n\nweights = torchvision.models.ResNeXt101_32X8D_Weights.DEFAULT \nweights","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:14.756195Z","iopub.execute_input":"2023-12-03T16:02:14.756557Z","iopub.status.idle":"2023-12-03T16:02:14.763149Z","shell.execute_reply.started":"2023-12-03T16:02:14.756523Z","shell.execute_reply":"2023-12-03T16:02:14.762166Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"ResNeXt101_32X8D_Weights.IMAGENET1K_V2"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Get the transforms used to create our pretrained weights\nauto_transforms = weights.transforms()\nauto_transforms","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:14.764488Z","iopub.execute_input":"2023-12-03T16:02:14.764801Z","iopub.status.idle":"2023-12-03T16:02:14.777332Z","shell.execute_reply.started":"2023-12-03T16:02:14.764771Z","shell.execute_reply":"2023-12-03T16:02:14.776476Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"ImageClassification(\n    crop_size=[224]\n    resize_size=[232]\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n    interpolation=InterpolationMode.BILINEAR\n)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# from torchvision import datasets, transforms\n\n# # Use ImageFolder to create dataset(s)\n# train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n#                                   transform=auto_transforms, # transforms to perform on data (images)\n#                                   target_transform=None) # transforms to perform on labels (if necessary)\n\n# test_data = datasets.ImageFolder(root=test_dir, \n#                                  transform=auto_transforms)\n\n# print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:14.778393Z","iopub.execute_input":"2023-12-03T16:02:14.778713Z","iopub.status.idle":"2023-12-03T16:02:14.786877Z","shell.execute_reply.started":"2023-12-03T16:02:14.778681Z","shell.execute_reply":"2023-12-03T16:02:14.786013Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Get class names as a list\nclass_names = train_data.classes\nclass_names","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:14.788027Z","iopub.execute_input":"2023-12-03T16:02:14.788301Z","iopub.status.idle":"2023-12-03T16:02:14.797411Z","shell.execute_reply.started":"2023-12-03T16:02:14.788278Z","shell.execute_reply":"2023-12-03T16:02:14.796471Z"},"trusted":true},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Can also get class names as a dict\nclass_dict = train_data.class_to_idx\nclass_dict","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:14.798306Z","iopub.execute_input":"2023-12-03T16:02:14.798541Z","iopub.status.idle":"2023-12-03T16:02:14.808331Z","shell.execute_reply.started":"2023-12-03T16:02:14.798520Z","shell.execute_reply":"2023-12-03T16:02:14.807580Z"},"trusted":true},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# weights = []\n\n# for (X,y) in train_data:\n#     if y == 0:\n#         weights.append(1.0/1445) # Aptos\n# #         weights.append(1.0/53728)\n\n#     if y == 1:\n#         weights.append(1.0/297)\n# #         weights.append(1.0/5261)\n#     if y == 2:\n#         weights.append(1.0/800)\n# #         weights.append(1.0/11322)\n#     if y == 3:\n#         weights.append(1.0/237)\n# #         weights.append(1.0/1768)\n#     if y == 4:\n#         weights.append(1.0/155)\n# #         weights.append(1.0/1825)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:14.809386Z","iopub.execute_input":"2023-12-03T16:02:14.809653Z","iopub.status.idle":"2023-12-03T16:02:14.818008Z","shell.execute_reply.started":"2023-12-03T16:02:14.809629Z","shell.execute_reply":"2023-12-03T16:02:14.817160Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Check the lengths\nlen(train_data), len(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:14.819288Z","iopub.execute_input":"2023-12-03T16:02:14.819579Z","iopub.status.idle":"2023-12-03T16:02:14.829335Z","shell.execute_reply.started":"2023-12-03T16:02:14.819547Z","shell.execute_reply":"2023-12-03T16:02:14.828482Z"},"trusted":true},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(8017, 1998)"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# ## testing optimal num_worker value\n\n# from time import time\n# import multiprocessing as mp\n# from torch.utils.data import DataLoader\n\n# for num_workers in range(1, 100, 1):  \n#     train_loader = DataLoader(test_data,shuffle=True,num_workers=num_workers,batch_size=1,pin_memory=True)\n#     start = time()\n#     for epoch in range(1):\n#         for i, data in enumerate(train_loader, 0):\n#             pass\n#     end = time()\n#     print(\"Finish with:{} second, num_workers={}\".format(end - start, num_workers))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-03T16:02:14.830466Z","iopub.execute_input":"2023-12-03T16:02:14.830718Z","iopub.status.idle":"2023-12-03T16:02:14.843167Z","shell.execute_reply.started":"2023-12-03T16:02:14.830696Z","shell.execute_reply":"2023-12-03T16:02:14.842389Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Turn train and test Datasets into DataLoaders\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\n# from torchsampler import ImbalancedDatasetSampler\n\nBATCH_SIZE = 32\n\n# sampler = WeightedRandomSampler(sweights, \n#                                 num_samples=8017,\n#                                 replacement=True)\n\n\n\ntrain_dataloader = DataLoader(dataset=train_data, \n                              batch_size=BATCH_SIZE, # how many samples per batch?\n                              num_workers=4, # how many subprocesses to use for data loading? (higher = more)\n                              shuffle=True,\n                              pin_memory=True,\n#                               sampler=sampler, \n                              ) # shuffle the data?\n\n\n\ntest_dataloader = DataLoader(dataset=test_data, \n                             batch_size=BATCH_SIZE, \n                             num_workers=4, \n                             shuffle=False,\n                             pin_memory=True,\n                             ) # don't usually need to shuffle testing data\n\n\nlen(train_dataloader), len(test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:14.844201Z","iopub.execute_input":"2023-12-03T16:02:14.844515Z","iopub.status.idle":"2023-12-03T16:02:14.856798Z","shell.execute_reply.started":"2023-12-03T16:02:14.844475Z","shell.execute_reply":"2023-12-03T16:02:14.855915Z"},"trusted":true},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(251, 63)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# # python code to calculate mean and std \n\n# import torch\n# from torch.utils.data import DataLoader\n\n# batch_size = 64\n\n\n# def batch_mean_and_sd(test_dataloader):\n    \n#     cnt = 0\n#     fst_moment = torch.empty(3)\n#     snd_moment = torch.empty(3)\n\n#     for images, _ in test_dataloader:\n#         b, c, h, w = images.shape\n#         nb_pixels = b * h * w\n#         sum_ = torch.sum(images, dim=[0, 2, 3])\n#         sum_of_square = torch.sum(images ** 2,\n#                                   dim=[0, 2, 3])\n#         fst_moment = (cnt * fst_moment + sum_) / (\n#                       cnt + nb_pixels)\n#         snd_moment = (cnt * snd_moment + sum_of_square) / (\n#                             cnt + nb_pixels)\n#         cnt += nb_pixels\n\n#     mean, std = fst_moment, torch.sqrt(\n#       snd_moment - fst_moment ** 2)        \n#     return mean,std\n  \n    \n    \n# mean, std = batch_mean_and_sd(train_dataloader)\n# print(\"mean and std: \\n\", mean, std)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:14.857821Z","iopub.execute_input":"2023-12-03T16:02:14.858135Z","iopub.status.idle":"2023-12-03T16:02:14.866871Z","shell.execute_reply.started":"2023-12-03T16:02:14.858105Z","shell.execute_reply":"2023-12-03T16:02:14.866017Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Check out single image size/shape\nimg, label = next(iter(train_dataloader))\n\n# Batch size will now be 1, try changing the batch_size parameter above and see what happens\nprint(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\nprint(f\"Label shape: {label.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:14.868040Z","iopub.execute_input":"2023-12-03T16:02:14.868391Z","iopub.status.idle":"2023-12-03T16:02:20.399492Z","shell.execute_reply.started":"2023-12-03T16:02:14.868362Z","shell.execute_reply":"2023-12-03T16:02:20.398479Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Image shape: torch.Size([32, 3, 224, 224]) -> [batch_size, color_channels, height, width]\nLabel shape: torch.Size([32])\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"### Experimentations","metadata":{}},{"cell_type":"code","source":"# ## Monitoring labels in batches\n# total = [0,0,0,0,0]\n# for batch, (X, y) in enumerate(train_dataloader):\n#     print(f\"{batch}th batch\")\n#     Y = y.tolist()\n#     print(f\"0 : {Y.count(0)}\\n1 : {Y.count(1)}\\n2 : {Y.count(2)}\\n3 : {Y.count(3)}\\n4 : {Y.count(4)}\")\n#     total[0] += Y.count(0)\n#     total[1] += Y.count(1)\n#     total[2] += Y.count(2)\n#     total[3] += Y.count(3)\n#     total[4] += Y.count(4)\n# total","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:20.406433Z","iopub.execute_input":"2023-12-03T16:02:20.406734Z","iopub.status.idle":"2023-12-03T16:02:20.411427Z","shell.execute_reply.started":"2023-12-03T16:02:20.406708Z","shell.execute_reply":"2023-12-03T16:02:20.410480Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# a = torch.randn(4, 4)\n# a\n# # tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n# #         [-0.7401, -0.8805, -0.3402, -1.1936],\n# #         [ 0.4907, -1.3948, -1.0691, -0.3132],\n# #         [-1.6092,  0.5419, -0.2993,  0.3195]])\n# # >>> torch.argmax(a)\n# # tensor(0)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:20.412629Z","iopub.execute_input":"2023-12-03T16:02:20.412902Z","iopub.status.idle":"2023-12-03T16:02:20.421180Z","shell.execute_reply.started":"2023-12-03T16:02:20.412878Z","shell.execute_reply":"2023-12-03T16:02:20.420399Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# torch.argmax(a, dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:20.422211Z","iopub.execute_input":"2023-12-03T16:02:20.422531Z","iopub.status.idle":"2023-12-03T16:02:20.431594Z","shell.execute_reply.started":"2023-12-03T16:02:20.422498Z","shell.execute_reply":"2023-12-03T16:02:20.430601Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# y_predicted = []\n# Y = []\n# for batch, (X, y) in enumerate(train_dataloader):\n#     # print(y, end=\"\\n\\n\")\n#     X = X.to(device)\n#     y_pred = model(X)\n#     y_predicted = y_pred\n#     Y = y \n#     # print(y_pred)\n#     break\n# print(y_predicted,end=\"/n\")\n# print(Y)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:20.432573Z","iopub.execute_input":"2023-12-03T16:02:20.433096Z","iopub.status.idle":"2023-12-03T16:02:20.440732Z","shell.execute_reply.started":"2023-12-03T16:02:20.433071Z","shell.execute_reply":"2023-12-03T16:02:20.440009Z"},"trusted":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# logits = torch.softmax(y_predicted, dim=1)\n# logits","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:20.441687Z","iopub.execute_input":"2023-12-03T16:02:20.442216Z","iopub.status.idle":"2023-12-03T16:02:20.453807Z","shell.execute_reply.started":"2023-12-03T16:02:20.442192Z","shell.execute_reply":"2023-12-03T16:02:20.453012Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# logits + logits","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:20.454937Z","iopub.execute_input":"2023-12-03T16:02:20.455240Z","iopub.status.idle":"2023-12-03T16:02:20.463035Z","shell.execute_reply.started":"2023-12-03T16:02:20.455216Z","shell.execute_reply":"2023-12-03T16:02:20.462230Z"},"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# y_pred_class = torch.argmax(torch.softmax(y_predicted, dim=1), dim=1)\n# print(y_pred_class)\n\n# Y = Y.to(device)\n# y_pred_class = y_pred_class.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:20.464118Z","iopub.execute_input":"2023-12-03T16:02:20.465411Z","iopub.status.idle":"2023-12-03T16:02:20.471537Z","shell.execute_reply.started":"2023-12-03T16:02:20.465379Z","shell.execute_reply":"2023-12-03T16:02:20.470713Z"},"trusted":true},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# (y_pred_class == Y).sum().item()/len(y_pred_class)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:20.472521Z","iopub.execute_input":"2023-12-03T16:02:20.472770Z","iopub.status.idle":"2023-12-03T16:02:20.480774Z","shell.execute_reply.started":"2023-12-03T16:02:20.472745Z","shell.execute_reply":"2023-12-03T16:02:20.480033Z"},"trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Get a batch of images\nimage_batch, label_batch = next(iter(train_dataloader))\n\n# Get a single image from the batch\nimage, label = image_batch[0], label_batch[0]\n\n# View the batch shapes\nimage.shape, label","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:20.481833Z","iopub.execute_input":"2023-12-03T16:02:20.482169Z","iopub.status.idle":"2023-12-03T16:02:22.197143Z","shell.execute_reply.started":"2023-12-03T16:02:20.482145Z","shell.execute_reply":"2023-12-03T16:02:22.195985Z"},"trusted":true},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(torch.Size([3, 224, 224]), tensor(2))"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Sequential as Seq\n# from gcn_lib import Grapher, act_layer\n\nimport sys\nsys.path.append(\"/kaggle/input/vig-pytorch/\")\nfrom gcn_lib import Grapher, act_layer\n\n\nfrom timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\nfrom timm.models.helpers import load_pretrained\nfrom timm.models.layers import DropPath, to_2tuple, trunc_normal_\nfrom timm.models.registry import register_model","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:22.198450Z","iopub.execute_input":"2023-12-03T16:02:22.198764Z","iopub.status.idle":"2023-12-03T16:02:23.689166Z","shell.execute_reply.started":"2023-12-03T16:02:22.198736Z","shell.execute_reply":"2023-12-03T16:02:23.688138Z"},"trusted":true},"outputs":[],"execution_count":37},{"cell_type":"code","source":"model = torchvision.models.resnext101_32x8d(weights=weights).to(device)\n# model","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:23.690254Z","iopub.execute_input":"2023-12-03T16:02:23.690540Z","iopub.status.idle":"2023-12-03T16:02:26.973562Z","shell.execute_reply.started":"2023-12-03T16:02:23.690515Z","shell.execute_reply":"2023-12-03T16:02:26.972665Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_32x8d-110c445d.pth\n100%|██████████| 340M/340M [00:01<00:00, 258MB/s]  \n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"from torchinfo import summary\n\n# Create an instance\nmodel_summary = model\n\n# Print an input and output summary \nsummary(model=model_summary,\n        input_size=(16, 3, 224, 224), # (batch_size, num_patches, embedding_dimension)\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:26.974759Z","iopub.execute_input":"2023-12-03T16:02:26.975068Z","iopub.status.idle":"2023-12-03T16:02:33.070438Z","shell.execute_reply.started":"2023-12-03T16:02:26.975041Z","shell.execute_reply":"2023-12-03T16:02:33.069459Z"},"trusted":true},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"========================================================================================================================\nLayer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n========================================================================================================================\nResNet (ResNet)                          [16, 3, 224, 224]    [16, 1000]           --                   True\n├─Conv2d (conv1)                         [16, 3, 224, 224]    [16, 64, 112, 112]   9,408                True\n├─BatchNorm2d (bn1)                      [16, 64, 112, 112]   [16, 64, 112, 112]   128                  True\n├─ReLU (relu)                            [16, 64, 112, 112]   [16, 64, 112, 112]   --                   --\n├─MaxPool2d (maxpool)                    [16, 64, 112, 112]   [16, 64, 56, 56]     --                   --\n├─Sequential (layer1)                    [16, 64, 56, 56]     [16, 256, 56, 56]    --                   True\n│    └─Bottleneck (0)                    [16, 64, 56, 56]     [16, 256, 56, 56]    --                   True\n│    │    └─Conv2d (conv1)               [16, 64, 56, 56]     [16, 256, 56, 56]    16,384               True\n│    │    └─BatchNorm2d (bn1)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv2)               [16, 256, 56, 56]    [16, 256, 56, 56]    18,432               True\n│    │    └─BatchNorm2d (bn2)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv3)               [16, 256, 56, 56]    [16, 256, 56, 56]    65,536               True\n│    │    └─BatchNorm2d (bn3)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─Sequential (downsample)      [16, 64, 56, 56]     [16, 256, 56, 56]    16,896               True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    └─Bottleneck (1)                    [16, 256, 56, 56]    [16, 256, 56, 56]    --                   True\n│    │    └─Conv2d (conv1)               [16, 256, 56, 56]    [16, 256, 56, 56]    65,536               True\n│    │    └─BatchNorm2d (bn1)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv2)               [16, 256, 56, 56]    [16, 256, 56, 56]    18,432               True\n│    │    └─BatchNorm2d (bn2)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv3)               [16, 256, 56, 56]    [16, 256, 56, 56]    65,536               True\n│    │    └─BatchNorm2d (bn3)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    └─Bottleneck (2)                    [16, 256, 56, 56]    [16, 256, 56, 56]    --                   True\n│    │    └─Conv2d (conv1)               [16, 256, 56, 56]    [16, 256, 56, 56]    65,536               True\n│    │    └─BatchNorm2d (bn1)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv2)               [16, 256, 56, 56]    [16, 256, 56, 56]    18,432               True\n│    │    └─BatchNorm2d (bn2)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv3)               [16, 256, 56, 56]    [16, 256, 56, 56]    65,536               True\n│    │    └─BatchNorm2d (bn3)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n├─Sequential (layer2)                    [16, 256, 56, 56]    [16, 512, 28, 28]    --                   True\n│    └─Bottleneck (0)                    [16, 256, 56, 56]    [16, 512, 28, 28]    --                   True\n│    │    └─Conv2d (conv1)               [16, 256, 56, 56]    [16, 512, 56, 56]    131,072              True\n│    │    └─BatchNorm2d (bn1)            [16, 512, 56, 56]    [16, 512, 56, 56]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 56, 56]    [16, 512, 56, 56]    --                   --\n│    │    └─Conv2d (conv2)               [16, 512, 56, 56]    [16, 512, 28, 28]    73,728               True\n│    │    └─BatchNorm2d (bn2)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv3)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn3)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─Sequential (downsample)      [16, 256, 56, 56]    [16, 512, 28, 28]    132,096              True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    └─Bottleneck (1)                    [16, 512, 28, 28]    [16, 512, 28, 28]    --                   True\n│    │    └─Conv2d (conv1)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn1)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv2)               [16, 512, 28, 28]    [16, 512, 28, 28]    73,728               True\n│    │    └─BatchNorm2d (bn2)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv3)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn3)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    └─Bottleneck (2)                    [16, 512, 28, 28]    [16, 512, 28, 28]    --                   True\n│    │    └─Conv2d (conv1)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn1)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv2)               [16, 512, 28, 28]    [16, 512, 28, 28]    73,728               True\n│    │    └─BatchNorm2d (bn2)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv3)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn3)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    └─Bottleneck (3)                    [16, 512, 28, 28]    [16, 512, 28, 28]    --                   True\n│    │    └─Conv2d (conv1)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn1)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv2)               [16, 512, 28, 28]    [16, 512, 28, 28]    73,728               True\n│    │    └─BatchNorm2d (bn2)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv3)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn3)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n├─Sequential (layer3)                    [16, 512, 28, 28]    [16, 1024, 14, 14]   --                   True\n│    └─Bottleneck (0)                    [16, 512, 28, 28]    [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 512, 28, 28]    [16, 1024, 28, 28]   524,288              True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 28, 28]   [16, 1024, 28, 28]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 28, 28]   [16, 1024, 28, 28]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 28, 28]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─Sequential (downsample)      [16, 512, 28, 28]    [16, 1024, 14, 14]   526,336              True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (1)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (2)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (3)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (4)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (5)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (6)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (7)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (8)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (9)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (10)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (11)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (12)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (13)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (14)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (15)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (16)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (17)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (18)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (19)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (20)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (21)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (22)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n├─Sequential (layer4)                    [16, 1024, 14, 14]   [16, 2048, 7, 7]     --                   True\n│    └─Bottleneck (0)                    [16, 1024, 14, 14]   [16, 2048, 7, 7]     --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 2048, 14, 14]   2,097,152            True\n│    │    └─BatchNorm2d (bn1)            [16, 2048, 14, 14]   [16, 2048, 14, 14]   4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 14, 14]   [16, 2048, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 2048, 14, 14]   [16, 2048, 7, 7]     1,179,648            True\n│    │    └─BatchNorm2d (bn2)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    │    └─Conv2d (conv3)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,194,304            True\n│    │    └─BatchNorm2d (bn3)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─Sequential (downsample)      [16, 1024, 14, 14]   [16, 2048, 7, 7]     2,101,248            True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    └─Bottleneck (1)                    [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   True\n│    │    └─Conv2d (conv1)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,194,304            True\n│    │    └─BatchNorm2d (bn1)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    │    └─Conv2d (conv2)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     1,179,648            True\n│    │    └─BatchNorm2d (bn2)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    │    └─Conv2d (conv3)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,194,304            True\n│    │    └─BatchNorm2d (bn3)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    └─Bottleneck (2)                    [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   True\n│    │    └─Conv2d (conv1)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,194,304            True\n│    │    └─BatchNorm2d (bn1)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    │    └─Conv2d (conv2)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     1,179,648            True\n│    │    └─BatchNorm2d (bn2)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    │    └─Conv2d (conv3)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,194,304            True\n│    │    └─BatchNorm2d (bn3)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n├─AdaptiveAvgPool2d (avgpool)            [16, 2048, 7, 7]     [16, 2048, 1, 1]     --                   --\n├─Linear (fc)                            [16, 2048]           [16, 1000]           2,049,000            True\n========================================================================================================================\nTotal params: 88,791,336\nTrainable params: 88,791,336\nNon-trainable params: 0\nTotal mult-adds (G): 262.63\n========================================================================================================================\nInput size (MB): 9.63\nForward/backward pass size (MB): 7989.75\nParams size (MB): 355.17\nEstimated Total Size (MB): 8354.55\n========================================================================================================================"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"# Set the manual seeds\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\n# Get the length of class_names (one output unit for each class)\noutput_shape = len(class_names)\n\n# Recreate the classifier layer and seed it to the target device\nmodel.fc = torch.nn.Linear(in_features=2048, \n                    out_features=output_shape, # same number of output units as our number of classes\n                    bias=True).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:33.077434Z","iopub.execute_input":"2023-12-03T16:02:33.077728Z","iopub.status.idle":"2023-12-03T16:02:33.167301Z","shell.execute_reply.started":"2023-12-03T16:02:33.077702Z","shell.execute_reply":"2023-12-03T16:02:33.166377Z"},"trusted":true},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Print an input and output summary of our Transformer Encoder (uncomment for full output)\nsummary(model=model_summary,\n        input_size=(16, 3, 224, 224), # (batch_size, num_patches, embedding_dimension)\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:33.168299Z","iopub.execute_input":"2023-12-03T16:02:33.168567Z","iopub.status.idle":"2023-12-03T16:02:33.291703Z","shell.execute_reply.started":"2023-12-03T16:02:33.168544Z","shell.execute_reply":"2023-12-03T16:02:33.290845Z"},"trusted":true},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"========================================================================================================================\nLayer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n========================================================================================================================\nResNet (ResNet)                          [16, 3, 224, 224]    [16, 7]              --                   True\n├─Conv2d (conv1)                         [16, 3, 224, 224]    [16, 64, 112, 112]   9,408                True\n├─BatchNorm2d (bn1)                      [16, 64, 112, 112]   [16, 64, 112, 112]   128                  True\n├─ReLU (relu)                            [16, 64, 112, 112]   [16, 64, 112, 112]   --                   --\n├─MaxPool2d (maxpool)                    [16, 64, 112, 112]   [16, 64, 56, 56]     --                   --\n├─Sequential (layer1)                    [16, 64, 56, 56]     [16, 256, 56, 56]    --                   True\n│    └─Bottleneck (0)                    [16, 64, 56, 56]     [16, 256, 56, 56]    --                   True\n│    │    └─Conv2d (conv1)               [16, 64, 56, 56]     [16, 256, 56, 56]    16,384               True\n│    │    └─BatchNorm2d (bn1)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv2)               [16, 256, 56, 56]    [16, 256, 56, 56]    18,432               True\n│    │    └─BatchNorm2d (bn2)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv3)               [16, 256, 56, 56]    [16, 256, 56, 56]    65,536               True\n│    │    └─BatchNorm2d (bn3)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─Sequential (downsample)      [16, 64, 56, 56]     [16, 256, 56, 56]    16,896               True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    └─Bottleneck (1)                    [16, 256, 56, 56]    [16, 256, 56, 56]    --                   True\n│    │    └─Conv2d (conv1)               [16, 256, 56, 56]    [16, 256, 56, 56]    65,536               True\n│    │    └─BatchNorm2d (bn1)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv2)               [16, 256, 56, 56]    [16, 256, 56, 56]    18,432               True\n│    │    └─BatchNorm2d (bn2)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv3)               [16, 256, 56, 56]    [16, 256, 56, 56]    65,536               True\n│    │    └─BatchNorm2d (bn3)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    └─Bottleneck (2)                    [16, 256, 56, 56]    [16, 256, 56, 56]    --                   True\n│    │    └─Conv2d (conv1)               [16, 256, 56, 56]    [16, 256, 56, 56]    65,536               True\n│    │    └─BatchNorm2d (bn1)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv2)               [16, 256, 56, 56]    [16, 256, 56, 56]    18,432               True\n│    │    └─BatchNorm2d (bn2)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n│    │    └─Conv2d (conv3)               [16, 256, 56, 56]    [16, 256, 56, 56]    65,536               True\n│    │    └─BatchNorm2d (bn3)            [16, 256, 56, 56]    [16, 256, 56, 56]    512                  True\n│    │    └─ReLU (relu)                  [16, 256, 56, 56]    [16, 256, 56, 56]    --                   --\n├─Sequential (layer2)                    [16, 256, 56, 56]    [16, 512, 28, 28]    --                   True\n│    └─Bottleneck (0)                    [16, 256, 56, 56]    [16, 512, 28, 28]    --                   True\n│    │    └─Conv2d (conv1)               [16, 256, 56, 56]    [16, 512, 56, 56]    131,072              True\n│    │    └─BatchNorm2d (bn1)            [16, 512, 56, 56]    [16, 512, 56, 56]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 56, 56]    [16, 512, 56, 56]    --                   --\n│    │    └─Conv2d (conv2)               [16, 512, 56, 56]    [16, 512, 28, 28]    73,728               True\n│    │    └─BatchNorm2d (bn2)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv3)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn3)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─Sequential (downsample)      [16, 256, 56, 56]    [16, 512, 28, 28]    132,096              True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    └─Bottleneck (1)                    [16, 512, 28, 28]    [16, 512, 28, 28]    --                   True\n│    │    └─Conv2d (conv1)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn1)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv2)               [16, 512, 28, 28]    [16, 512, 28, 28]    73,728               True\n│    │    └─BatchNorm2d (bn2)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv3)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn3)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    └─Bottleneck (2)                    [16, 512, 28, 28]    [16, 512, 28, 28]    --                   True\n│    │    └─Conv2d (conv1)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn1)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv2)               [16, 512, 28, 28]    [16, 512, 28, 28]    73,728               True\n│    │    └─BatchNorm2d (bn2)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv3)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn3)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    └─Bottleneck (3)                    [16, 512, 28, 28]    [16, 512, 28, 28]    --                   True\n│    │    └─Conv2d (conv1)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn1)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv2)               [16, 512, 28, 28]    [16, 512, 28, 28]    73,728               True\n│    │    └─BatchNorm2d (bn2)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n│    │    └─Conv2d (conv3)               [16, 512, 28, 28]    [16, 512, 28, 28]    262,144              True\n│    │    └─BatchNorm2d (bn3)            [16, 512, 28, 28]    [16, 512, 28, 28]    1,024                True\n│    │    └─ReLU (relu)                  [16, 512, 28, 28]    [16, 512, 28, 28]    --                   --\n├─Sequential (layer3)                    [16, 512, 28, 28]    [16, 1024, 14, 14]   --                   True\n│    └─Bottleneck (0)                    [16, 512, 28, 28]    [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 512, 28, 28]    [16, 1024, 28, 28]   524,288              True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 28, 28]   [16, 1024, 28, 28]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 28, 28]   [16, 1024, 28, 28]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 28, 28]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─Sequential (downsample)      [16, 512, 28, 28]    [16, 1024, 14, 14]   526,336              True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (1)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (2)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (3)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (4)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (5)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (6)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (7)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (8)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (9)                    [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (10)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (11)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (12)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (13)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (14)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (15)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (16)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (17)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (18)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (19)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (20)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (21)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    └─Bottleneck (22)                   [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn1)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   294,912              True\n│    │    └─BatchNorm2d (bn2)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n│    │    └─Conv2d (conv3)               [16, 1024, 14, 14]   [16, 1024, 14, 14]   1,048,576            True\n│    │    └─BatchNorm2d (bn3)            [16, 1024, 14, 14]   [16, 1024, 14, 14]   2,048                True\n│    │    └─ReLU (relu)                  [16, 1024, 14, 14]   [16, 1024, 14, 14]   --                   --\n├─Sequential (layer4)                    [16, 1024, 14, 14]   [16, 2048, 7, 7]     --                   True\n│    └─Bottleneck (0)                    [16, 1024, 14, 14]   [16, 2048, 7, 7]     --                   True\n│    │    └─Conv2d (conv1)               [16, 1024, 14, 14]   [16, 2048, 14, 14]   2,097,152            True\n│    │    └─BatchNorm2d (bn1)            [16, 2048, 14, 14]   [16, 2048, 14, 14]   4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 14, 14]   [16, 2048, 14, 14]   --                   --\n│    │    └─Conv2d (conv2)               [16, 2048, 14, 14]   [16, 2048, 7, 7]     1,179,648            True\n│    │    └─BatchNorm2d (bn2)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    │    └─Conv2d (conv3)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,194,304            True\n│    │    └─BatchNorm2d (bn3)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─Sequential (downsample)      [16, 1024, 14, 14]   [16, 2048, 7, 7]     2,101,248            True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    └─Bottleneck (1)                    [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   True\n│    │    └─Conv2d (conv1)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,194,304            True\n│    │    └─BatchNorm2d (bn1)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    │    └─Conv2d (conv2)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     1,179,648            True\n│    │    └─BatchNorm2d (bn2)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    │    └─Conv2d (conv3)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,194,304            True\n│    │    └─BatchNorm2d (bn3)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    └─Bottleneck (2)                    [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   True\n│    │    └─Conv2d (conv1)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,194,304            True\n│    │    └─BatchNorm2d (bn1)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    │    └─Conv2d (conv2)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     1,179,648            True\n│    │    └─BatchNorm2d (bn2)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n│    │    └─Conv2d (conv3)               [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,194,304            True\n│    │    └─BatchNorm2d (bn3)            [16, 2048, 7, 7]     [16, 2048, 7, 7]     4,096                True\n│    │    └─ReLU (relu)                  [16, 2048, 7, 7]     [16, 2048, 7, 7]     --                   --\n├─AdaptiveAvgPool2d (avgpool)            [16, 2048, 7, 7]     [16, 2048, 1, 1]     --                   --\n├─Linear (fc)                            [16, 2048]           [16, 7]              14,343               True\n========================================================================================================================\nTotal params: 86,756,679\nTrainable params: 86,756,679\nNon-trainable params: 0\nTotal mult-adds (G): 262.59\n========================================================================================================================\nInput size (MB): 9.63\nForward/backward pass size (MB): 7989.63\nParams size (MB): 347.03\nEstimated Total Size (MB): 8346.29\n========================================================================================================================"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"model = nn.DataParallel(model)  ### for two GPU faster computations ","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:33.292811Z","iopub.execute_input":"2023-12-03T16:02:33.293100Z","iopub.status.idle":"2023-12-03T16:02:33.297509Z","shell.execute_reply.started":"2023-12-03T16:02:33.293075Z","shell.execute_reply":"2023-12-03T16:02:33.296636Z"},"trusted":true},"outputs":[],"execution_count":43},{"cell_type":"code","source":"import wandb\n\n# start a new wandb run to track this script\ntracking = wandb.init(\n    # set the wandb project where this run will be logged\n    project=\"Glaucoma Fundus Imaging\",\n    name=\"HAM10000: ResNext101\",\n#     name=\"Origa: Fb_model\",\n    notes=\"\",\n    # track hyperparameters and run metadata\n    config={\n        \"learning_rate\": 2e-3,\n        \"architecture\": \"fb\",\n        \"dataset\": \"Default\",\n        \"epochs\": 200,\n    }\n)\n\n# 4b7dfb240ea0d5aae1afac2de518c0e940547396","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:02:33.308258Z","iopub.execute_input":"2023-12-03T16:02:33.308925Z","iopub.status.idle":"2023-12-03T16:03:39.876323Z","shell.execute_reply.started":"2023-12-03T16:02:33.308893Z","shell.execute_reply":"2023-12-03T16:03:39.875294Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231203_160308-j4a3vilx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging/runs/j4a3vilx' target=\"_blank\">HAM10000: ResNext101</a></strong> to <a href='https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging' target=\"_blank\">https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging/runs/j4a3vilx' target=\"_blank\">https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging/runs/j4a3vilx</a>"},"metadata":{}}],"execution_count":45},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"\"\"\"\nContains functions for training and testing a PyTorch model.\n\"\"\"\nfrom typing import Dict, List, Tuple\nfrom sklearn.metrics import classification_report\n\nimport torch\n\nfrom tqdm.auto import tqdm\nimport wandb\n\n\ndef train_step(model: torch.nn.Module, \n               dataloader: torch.utils.data.DataLoader, \n               loss_fn: torch.nn.Module, \n               optimizer: torch.optim.Optimizer,\n               device: torch.device,\n               len_train_data) -> Tuple[float, float]:\n    \"\"\"Trains a PyTorch model for a single epoch.\n\n    Turns a target PyTorch model to training mode and then\n    runs through all of the required training steps (forward\n    pass, loss calculation, optimizer step).\n\n    Args:\n    model: A PyTorch model to be trained.\n    dataloader: A DataLoader instance for the model to be trained on.\n    loss_fn: A PyTorch loss function to minimize.\n    optimizer: A PyTorch optimizer to help minimize the loss function.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A tuple of training loss and training accuracy metrics.\n    In the form (train_loss, train_accuracy). For example:\n\n    (0.1112, 0.8743)\n    \"\"\"\n    # Put model in train mode\n    model.train()\n\n    # Setup train loss and train accuracy values\n    train_loss = 0.0 \n    train_acc = 0.0\n\n    # for evaluation\n    y_true_train_data = []\n    y_predicted_train_data = []\n\n    # Loop through data loader data batches\n    for batch, (X, y) in enumerate(dataloader):\n        # Send data to target device\n        X, y = X.to(device), y.to(device)\n\n\n        # 1. Forward pass\n        y_pred = model(X)\n        \n#         y_pred = y_pred.logits\n\n        # 2. Calculate  and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item() \n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n        # Calculate and accumulate accuracy metric across all batches\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        # train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n        train_acc += (y_pred_class == y).sum().item()\n        \n        # for evaluaiton\n        y_true_train_data.append(y)\n        y_predicted_train_data.append(y_pred_class)\n\n    # Adjust metrics to get average loss and accuracy per batch \n    train_loss = train_loss / len(dataloader)\n#     train_acc = train_acc / len(dataloader)\n    train_acc = train_acc / len_train_data\n    \n    #     New way of accuracy calculation\n    true = 0\n    tot = 0\n    for i in range(len(y_true_train_data)):\n        x = (y_true_train_data[i] == y_predicted_train_data[i])\n        for j in range(len(x)):\n            tot += 1\n            if x[j] == True:\n                true += 1\n    train_acc = (true/tot)\n\n    # return train_loss, train_acc\n    return train_loss, train_acc, y_true_train_data, y_predicted_train_data\n\n\n\n\ndef test_step(model: torch.nn.Module, \n              dataloader: torch.utils.data.DataLoader,\n              loss_fn: torch.nn.Module,\n              device: torch.device,\n              len_test_data) -> Tuple[float, float]:\n    \"\"\"Tests a PyTorch model for a single epoch.\n\n    Turns a target PyTorch model to \"eval\" mode and then performs\n    a forward pass on a testing dataset.\n\n    Args:\n    model: A PyTorch model to be tested.\n    dataloader: A DataLoader instance for the model to be tested on.\n    loss_fn: A PyTorch loss function to calculate loss on the test data.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A tuple of testing loss and testing accuracy metrics.\n    In the form (test_loss, test_accuracy). For example:\n\n    (0.0223, 0.8985)\n    \"\"\"\n    # Put model in eval mode\n    model.eval() \n\n    # Setup test loss and test accuracy values\n    test_loss = 0.0 \n    test_acc = 0.0\n\n    # for evaluation\n    y_true_test_data = []\n    y_predicted_test_data = []\n\n\n    # Turn on inference context manager\n    with torch.inference_mode():\n\n        # Loop through DataLoader batches\n        for batch, (X, y) in enumerate(dataloader):\n            # Send data to target device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred_logits = model(X)\n            \n#             test_pred_logits = test_pred_logits.logits\n            \n            # 2. Calculate and accumulate loss\n            loss = loss_fn(test_pred_logits, y)\n            test_loss += loss.item()\n\n            # Calculate and accumulate accuracy\n            test_pred_labels = test_pred_logits.argmax(dim=1)\n            # test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n            test_acc += (test_pred_labels == y).sum().item()\n\n            # test_pred_labels = torch.argmax(torch.softmax(test_pred_logits, dim=1), dim=1)\n            # test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels)) \n            \n\n            # for evaluaiton\n            y_true_test_data.append(y)\n            y_predicted_test_data.append(test_pred_labels)\n\n\n    # Adjust metrics to get average loss and accuracy per batch \n    test_loss = test_loss / len(dataloader)\n#     test_acc = test_acc / len(dataloader)\n    test_acc = test_acc / len_test_data\n\n\n    \n#     New way of accuracy calculation\n    true = 0\n    tot = 0\n    for i in range(len(y_true_test_data)):\n        x = (y_true_test_data[i] == y_predicted_test_data[i])\n        for j in range(len(x)):\n            tot += 1\n            if x[j] == True:\n                true += 1\n    test_acc = (true/tot)\n    \n    # return test_loss, test_acc\n    return test_loss, test_acc, y_true_test_data, y_predicted_test_data\n\n\n\n\ndef train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader,\n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device,\n          tracking,\n          best_accuracy,\n          len_train_data,\n          len_test_data,\n        ) -> Dict[str, List[float]]:\n    \"\"\"Trains and tests a PyTorch model.\n\n    Passes a target PyTorch models through train_step() and test_step()\n    functions for a number of epochs, training and testing the model\n    in the same epoch loop.\n\n    Calculates, prints and stores evaluation metrics throughout.\n\n    Args:\n    model: A PyTorch model to be trained and tested.\n    train_dataloader: A DataLoader instance for the model to be trained on.\n    test_dataloader: A DataLoader instance for the model to be tested on.\n    optimizer: A PyTorch optimizer to help minimize the loss function.\n    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n    epochs: An integer indicating how many epochs to train for.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A dictionary of training and testing loss as well as training and\n    testing accuracy metrics. Each metric has a value in a list for \n    each epoch.\n    In the form: {train_loss: [...],\n              train_acc: [...],\n              test_loss: [...],\n              test_acc: [...]} \n    For example if training for epochs=2: \n             {train_loss: [2.0616, 1.0537],\n              train_acc: [0.3945, 0.3945],\n              test_loss: [1.2641, 1.5706],\n              test_acc: [0.3400, 0.2973]} \n    \"\"\"\n    # Create empty results dictionary\n    results = {\"train_loss\": [],\n               \"train_acc\": [],\n               \"test_loss\": [],\n               \"test_acc\": []\n    }\n\n\n        \n    # Loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc, y_true_train_data, y_predicted_train_data = train_step(model=model,\n                                                                                      dataloader=train_dataloader,\n                                                                                      loss_fn=loss_fn,\n                                                                                      optimizer=optimizer,\n                                                                                      device=device,\n                                                                                      len_train_data=len_train_data,\n                                                                                      )\n        test_loss, test_acc, y_true_test_data, y_predicted_test_data = test_step(model=model,\n                                                                                 dataloader=test_dataloader,\n                                                                                 loss_fn=loss_fn,\n                                                                                 device=device,\n                                                                                 len_test_data=len_test_data,\n                                                                                 )\n\n        if best_accuracy < test_acc:\n            print(f\"\\nAccuracy Improved ({best_accuracy} to {test_acc}), Saving the model...............................................\\n\")\n            best_accuracy = test_acc\n            best_y_true_test_data = y_true_test_data\n            best_y_predicted_test_data = y_predicted_test_data\n\n            model_name_path = f\"{best_accuracy} acc.pth\"\n            torch.save(model.state_dict(), model_name_path)\n            \n            \n                        \n            # taking \"y_predicted_train_data\" & \"y_true_train_data\" into 1D array because it came out as batch by batch 2D list\n            predicted_train_data_1D = []\n            true_train_data_1D = []\n\n            for i in range(len(y_predicted_train_data)):\n                for j in range(len(y_predicted_train_data[i])):\n                    predicted_train_data_1D.append(y_predicted_train_data[i][j])\n                    true_train_data_1D.append(y_true_train_data[i][j])\n\n            # taking both into CPU\n            predicted_train_data_cpu = torch.tensor(predicted_train_data_1D, device = 'cpu')\n            true_train_data_cpu = torch.tensor(true_train_data_1D, device = 'cpu')\n\n\n\n            # now same procedure for test data's\n            predicted_test_data_1D = []\n            true_test_data_1D = []\n\n            for i in range(len(y_predicted_test_data)):\n                for j in range(len(y_predicted_test_data[i])):\n                    predicted_test_data_1D.append(y_predicted_test_data[i][j])\n                    true_test_data_1D.append(y_true_test_data[i][j])\n\n            # taking both into CPU\n            predicted_test_data_cpu = torch.tensor(predicted_test_data_1D, device = 'cpu')\n            true_test_data_cpu = torch.tensor(true_test_data_1D, device = 'cpu')\n\n\n\n            # now same procedure for best test data's\n            best_predicted_test_data_1D = []\n            best_true_test_data_1D = []\n\n            for i in range(len(best_y_predicted_test_data)):\n                for j in range(len(best_y_predicted_test_data[i])):\n                    best_predicted_test_data_1D.append(best_y_predicted_test_data[i][j])\n                    best_true_test_data_1D.append(best_y_true_test_data[i][j])\n\n            # taking both into CPU\n            best_predicted_test_data_cpu = torch.tensor(best_predicted_test_data_1D, device = 'cpu')\n            best_true_test_data_cpu = torch.tensor(best_true_test_data_1D, device = 'cpu')\n            \n            \n\n            # Generate a classification report\n            # F1 score on train data\n            y_true_train = true_train_data_cpu\n            y_pred_train = predicted_train_data_cpu\n\n            report = classification_report(y_true_train, y_pred_train, target_names=class_names)\n\n            print(f\"Evaluation report on Train data: \\n\\n{report}\\n\\n\\n\\n\")\n\n\n            # F1 score on test data\n            y_true_test = true_test_data_cpu\n            y_pred_test = predicted_test_data_cpu\n\n            report = classification_report(y_true_test, y_pred_test, target_names=class_names)\n\n            print(f\"Evaluation report on Test data: \\n\\n{report}\")\n            \n            \n            \n            \n            \n            \n        #     Live result tracking#####################################\n        #     for i in range(len(y_true_test_data)):\n        #         print(f\"{y_true_test_data[i]} and {y_predicted_test_data[i]}\")\n        acc_0 = 0\n        acc_1 = 0\n        total_0 = 0\n        total_1 = 0\n        for i in range(len(y_predicted_test_data)):\n            for j in range(len(y_true_test_data[i])):\n                if (y_true_test_data[i][j] == 0):\n                    total_0 += 1\n                    if (y_true_test_data[i][j] == y_predicted_test_data[i][j]):\n                        acc_0 += 1\n                elif (y_true_test_data[i][j] == 1): \n                    total_1 += 1\n                    if (y_true_test_data[i][j] == y_predicted_test_data[i][j]):\n                        acc_1 += 1\n#         print(f\"\\n0: {acc_0}/{total_0} and 1: {acc_1}/{total_1}\\n\\n\")\n        #     Live result tracking#####################################\n\n        \n        # Print out what's happening\n        print(\n          f\"Epoch: {epoch+1} | \"\n          f\"train_loss: {train_loss:.4f} | \"\n          f\"train_acc: {train_acc:.4f} | \"\n          f\"test_loss: {test_loss:.4f} | \"\n          f\"test_acc: {test_acc:.4f} | \"\n#           f\"0: {acc_0}/{total_0} | \"\n#           f\"1: {acc_1}/{total_1}\"\n        )\n        \n\n        # Update results dictionary\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n\n        \n        tracking.log({\n            \"train_acc\": train_acc,\n            \"test_acc\": test_acc,\n        })\n\n    # Return the filled results at the end of the epochs\n    # return results\n    \n\n    return results, y_true_train_data, y_predicted_train_data, y_true_test_data, y_predicted_test_data, best_accuracy, best_y_true_test_data, best_y_predicted_test_data\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:03:39.880571Z","iopub.execute_input":"2023-12-03T16:03:39.880867Z","iopub.status.idle":"2023-12-03T16:03:40.535399Z","shell.execute_reply.started":"2023-12-03T16:03:39.880841Z","shell.execute_reply":"2023-12-03T16:03:40.534445Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"from going_modular import engine\n\noptimizer = torch.optim.AdamW(params=model.parameters(), \n                              lr = 1e-3,\n                              betas=(0.9, 0.999), \n                              weight_decay=0.05,\n#                               weight_decay=1e-5\n                              ) # from the ViT paper section 4.1 (Training & Fine-tuning) and Table 3 for ViT-* ImageNet-1k\n\n# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=5)\n# Setup the loss function for multi-class classification\nloss_fn = torch.nn.CrossEntropyLoss()\n\n# Set the seeds\n# set_seeds()\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\nbest_accuracy=0.0","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:03:40.537930Z","iopub.execute_input":"2023-12-03T16:03:40.538295Z","iopub.status.idle":"2023-12-03T16:03:40.572790Z","shell.execute_reply.started":"2023-12-03T16:03:40.538263Z","shell.execute_reply":"2023-12-03T16:03:40.571887Z"},"trusted":true},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Train the model and save the training results to a dictionary\nresults, y_true_train_data, y_predicted_train_data, y_true_test_data, y_predicted_test_data, best_accuracy, best_y_true_test_data, best_y_predicted_test_data = train(model=model,\n                                                                                                           train_dataloader=train_dataloader,\n                                                                                                           test_dataloader=test_dataloader,\n                                                                                                           optimizer=optimizer,\n                                                                                                           loss_fn=loss_fn,\n                                                                                                           epochs=300,\n                                                                                                           device=device,\n                                                                                                           tracking=tracking,\n                                                                                                           best_accuracy=best_accuracy,\n                                                                                                           len_train_data=len(train_data),\n                                                                                                           len_test_data=len(test_data)\n                                                                                                           )","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:03:40.574034Z","iopub.execute_input":"2023-12-03T16:03:40.574782Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d5444a58b7a4078b41010e969c2de3a"}},"metadata":{}},{"name":"stdout","text":"\nAccuracy Improved (0.0 to 0.7962962962962963), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.43      0.25      0.31       262\n         bcc       0.49      0.44      0.46       412\n         bkl       0.52      0.45      0.48       880\n          df       0.00      0.00      0.00        93\n         mel       0.45      0.28      0.35       891\n          nv       0.82      0.93      0.87      5365\n        vasc       0.59      0.39      0.47       114\n\n    accuracy                           0.74      8017\n   macro avg       0.47      0.39      0.42      8017\nweighted avg       0.70      0.74      0.71      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.82      0.28      0.41        65\n         bcc       0.62      0.65      0.63       102\n         bkl       0.63      0.59      0.61       219\n          df       0.38      0.59      0.46        22\n         mel       0.65      0.36      0.46       222\n          nv       0.87      0.94      0.90      1340\n        vasc       0.44      0.89      0.59        28\n\n    accuracy                           0.80      1998\n   macro avg       0.63      0.61      0.58      1998\nweighted avg       0.79      0.80      0.78      1998\n\nEpoch: 1 | train_loss: 0.7373 | train_acc: 0.7376 | test_loss: 0.6082 | test_acc: 0.7963 | \n\nAccuracy Improved (0.7962962962962963 to 0.7982982982982983), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.46      0.35      0.40       262\n         bcc       0.59      0.61      0.60       412\n         bkl       0.59      0.54      0.56       880\n          df       0.57      0.31      0.40        93\n         mel       0.56      0.38      0.45       891\n          nv       0.86      0.94      0.90      5365\n        vasc       0.80      0.75      0.78       114\n\n    accuracy                           0.79      8017\n   macro avg       0.64      0.55      0.59      8017\nweighted avg       0.77      0.79      0.77      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.93      0.20      0.33        65\n         bcc       0.55      0.76      0.64       102\n         bkl       0.73      0.45      0.56       219\n          df       0.75      0.55      0.63        22\n         mel       0.64      0.33      0.44       222\n          nv       0.84      0.97      0.90      1340\n        vasc       0.95      0.64      0.77        28\n\n    accuracy                           0.80      1998\n   macro avg       0.77      0.56      0.61      1998\nweighted avg       0.79      0.80      0.77      1998\n\nEpoch: 2 | train_loss: 0.5899 | train_acc: 0.7853 | test_loss: 0.5483 | test_acc: 0.7983 | \n\nAccuracy Improved (0.7982982982982983 to 0.8268268268268268), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.59      0.51      0.54       262\n         bcc       0.73      0.75      0.74       412\n         bkl       0.65      0.61      0.63       880\n          df       0.61      0.43      0.50        93\n         mel       0.60      0.46      0.52       891\n          nv       0.88      0.94      0.91      5365\n        vasc       0.81      0.81      0.81       114\n\n    accuracy                           0.82      8017\n   macro avg       0.70      0.64      0.66      8017\nweighted avg       0.80      0.82      0.81      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.67      0.60      0.63        65\n         bcc       0.70      0.77      0.73       102\n         bkl       0.79      0.62      0.70       219\n          df       0.57      0.55      0.56        22\n         mel       0.58      0.48      0.52       222\n          nv       0.90      0.94      0.92      1340\n        vasc       0.50      0.89      0.64        28\n\n    accuracy                           0.83      1998\n   macro avg       0.67      0.69      0.67      1998\nweighted avg       0.82      0.83      0.82      1998\n\nEpoch: 3 | train_loss: 0.5017 | train_acc: 0.8150 | test_loss: 0.5230 | test_acc: 0.8268 | \nEpoch: 4 | train_loss: 0.4702 | train_acc: 0.8290 | test_loss: 0.5288 | test_acc: 0.8258 | \nEpoch: 5 | train_loss: 0.4427 | train_acc: 0.8395 | test_loss: 0.5556 | test_acc: 0.8153 | \nEpoch: 6 | train_loss: 0.4040 | train_acc: 0.8481 | test_loss: 0.6015 | test_acc: 0.8068 | \n\nAccuracy Improved (0.8268268268268268 to 0.8478478478478478), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.68      0.59      0.63       262\n         bcc       0.78      0.83      0.80       412\n         bkl       0.75      0.72      0.73       880\n          df       0.78      0.63      0.70        93\n         mel       0.67      0.55      0.60       891\n          nv       0.91      0.94      0.92      5365\n        vasc       0.93      0.91      0.92       114\n\n    accuracy                           0.85      8017\n   macro avg       0.78      0.74      0.76      8017\nweighted avg       0.85      0.85      0.85      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.57      0.66      0.61        65\n         bcc       0.75      0.81      0.78       102\n         bkl       0.79      0.68      0.73       219\n          df       0.79      0.50      0.61        22\n         mel       0.75      0.41      0.53       222\n          nv       0.89      0.97      0.92      1340\n        vasc       0.88      0.75      0.81        28\n\n    accuracy                           0.85      1998\n   macro avg       0.77      0.68      0.71      1998\nweighted avg       0.84      0.85      0.84      1998\n\nEpoch: 7 | train_loss: 0.3884 | train_acc: 0.8539 | test_loss: 0.4541 | test_acc: 0.8478 | \nEpoch: 8 | train_loss: 0.3512 | train_acc: 0.8694 | test_loss: 0.5333 | test_acc: 0.8313 | \nEpoch: 9 | train_loss: 0.3512 | train_acc: 0.8703 | test_loss: 0.5025 | test_acc: 0.8328 | \nEpoch: 10 | train_loss: 0.3183 | train_acc: 0.8846 | test_loss: 1.1437 | test_acc: 0.8443 | \nEpoch: 11 | train_loss: 0.3209 | train_acc: 0.8819 | test_loss: 0.4938 | test_acc: 0.8323 | \n\nAccuracy Improved (0.8478478478478478 to 0.8593593593593594), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.77      0.73      0.75       262\n         bcc       0.85      0.85      0.85       412\n         bkl       0.80      0.79      0.80       880\n          df       0.89      0.78      0.83        93\n         mel       0.74      0.63      0.68       891\n          nv       0.93      0.96      0.94      5365\n        vasc       0.93      0.92      0.93       114\n\n    accuracy                           0.89      8017\n   macro avg       0.84      0.81      0.83      8017\nweighted avg       0.88      0.89      0.88      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.78      0.55      0.65        65\n         bcc       0.80      0.80      0.80       102\n         bkl       0.75      0.79      0.77       219\n          df       0.47      0.86      0.61        22\n         mel       0.67      0.61      0.64       222\n          nv       0.93      0.93      0.93      1340\n        vasc       0.79      0.93      0.85        28\n\n    accuracy                           0.86      1998\n   macro avg       0.74      0.78      0.75      1998\nweighted avg       0.86      0.86      0.86      1998\n\nEpoch: 12 | train_loss: 0.2945 | train_acc: 0.8874 | test_loss: 0.4126 | test_acc: 0.8594 | \nEpoch: 13 | train_loss: 0.2864 | train_acc: 0.8943 | test_loss: 0.4296 | test_acc: 0.8559 | \nEpoch: 14 | train_loss: 0.2675 | train_acc: 0.8991 | test_loss: 0.4422 | test_acc: 0.8478 | \nEpoch: 15 | train_loss: 0.2521 | train_acc: 0.9088 | test_loss: 0.5099 | test_acc: 0.8418 | \nEpoch: 16 | train_loss: 0.2459 | train_acc: 0.9104 | test_loss: 0.4673 | test_acc: 0.8544 | \nEpoch: 17 | train_loss: 0.2306 | train_acc: 0.9157 | test_loss: 0.4780 | test_acc: 0.8438 | \nEpoch: 18 | train_loss: 0.2367 | train_acc: 0.9134 | test_loss: 0.4862 | test_acc: 0.8433 | \nEpoch: 19 | train_loss: 0.2030 | train_acc: 0.9245 | test_loss: 0.5597 | test_acc: 0.8333 | \n\nAccuracy Improved (0.8593593593593594 to 0.8648648648648649), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.85      0.83      0.84       262\n         bcc       0.95      0.93      0.94       412\n         bkl       0.85      0.84      0.84       880\n          df       0.91      0.85      0.88        93\n         mel       0.84      0.77      0.80       891\n          nv       0.95      0.97      0.96      5365\n        vasc       0.97      0.99      0.98       114\n\n    accuracy                           0.93      8017\n   macro avg       0.90      0.88      0.89      8017\nweighted avg       0.92      0.93      0.92      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.75      0.68      0.71        65\n         bcc       0.76      0.83      0.79       102\n         bkl       0.83      0.67      0.74       219\n          df       0.68      0.68      0.68        22\n         mel       0.75      0.57      0.65       222\n          nv       0.90      0.96      0.93      1340\n        vasc       0.76      0.93      0.84        28\n\n    accuracy                           0.86      1998\n   macro avg       0.78      0.76      0.76      1998\nweighted avg       0.86      0.86      0.86      1998\n\nEpoch: 20 | train_loss: 0.2057 | train_acc: 0.9257 | test_loss: 0.4462 | test_acc: 0.8649 | \nEpoch: 21 | train_loss: 0.1998 | train_acc: 0.9250 | test_loss: 0.4942 | test_acc: 0.8554 | \nEpoch: 22 | train_loss: 0.1857 | train_acc: 0.9287 | test_loss: 0.5362 | test_acc: 0.8529 | \nEpoch: 23 | train_loss: 0.1861 | train_acc: 0.9305 | test_loss: 0.5304 | test_acc: 0.8539 | \nEpoch: 24 | train_loss: 0.1750 | train_acc: 0.9338 | test_loss: 0.5266 | test_acc: 0.8504 | \nEpoch: 25 | train_loss: 0.1576 | train_acc: 0.9394 | test_loss: 0.6136 | test_acc: 0.8579 | \nEpoch: 26 | train_loss: 0.1784 | train_acc: 0.9345 | test_loss: 0.4996 | test_acc: 0.8418 | \nEpoch: 27 | train_loss: 0.1717 | train_acc: 0.9360 | test_loss: 0.4667 | test_acc: 0.8624 | \nEpoch: 28 | train_loss: 0.1515 | train_acc: 0.9476 | test_loss: 0.9341 | test_acc: 0.8478 | \nEpoch: 29 | train_loss: 0.1467 | train_acc: 0.9466 | test_loss: 0.5449 | test_acc: 0.8423 | \nEpoch: 30 | train_loss: 0.1480 | train_acc: 0.9470 | test_loss: 6.6894 | test_acc: 0.8168 | \n\nAccuracy Improved (0.8648648648648649 to 0.8668668668668669), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.89      0.87      0.88       262\n         bcc       0.94      0.94      0.94       412\n         bkl       0.91      0.90      0.91       880\n          df       0.94      0.89      0.92        93\n         mel       0.87      0.84      0.85       891\n          nv       0.97      0.98      0.97      5365\n        vasc       0.97      0.99      0.98       114\n\n    accuracy                           0.95      8017\n   macro avg       0.93      0.92      0.92      8017\nweighted avg       0.95      0.95      0.95      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.84      0.55      0.67        65\n         bcc       0.79      0.78      0.79       102\n         bkl       0.67      0.90      0.77       219\n          df       0.78      0.82      0.80        22\n         mel       0.76      0.53      0.62       222\n          nv       0.93      0.94      0.94      1340\n        vasc       0.91      0.71      0.80        28\n\n    accuracy                           0.87      1998\n   macro avg       0.81      0.75      0.77      1998\nweighted avg       0.87      0.87      0.86      1998\n\nEpoch: 31 | train_loss: 0.1401 | train_acc: 0.9461 | test_loss: 1.5556 | test_acc: 0.8669 | \nEpoch: 32 | train_loss: 0.1427 | train_acc: 0.9481 | test_loss: 0.4914 | test_acc: 0.8574 | \nEpoch: 33 | train_loss: 0.1399 | train_acc: 0.9515 | test_loss: 0.5864 | test_acc: 0.8564 | \n\nAccuracy Improved (0.8668668668668669 to 0.8688688688688688), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.88      0.89      0.89       262\n         bcc       0.94      0.94      0.94       412\n         bkl       0.90      0.88      0.89       880\n          df       0.97      0.94      0.95        93\n         mel       0.89      0.85      0.87       891\n          nv       0.97      0.98      0.97      5365\n        vasc       0.98      0.96      0.97       114\n\n    accuracy                           0.95      8017\n   macro avg       0.93      0.92      0.93      8017\nweighted avg       0.95      0.95      0.95      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.64      0.66      0.65        65\n         bcc       0.93      0.67      0.78       102\n         bkl       0.71      0.88      0.78       219\n          df       0.94      0.73      0.82        22\n         mel       0.67      0.75      0.71       222\n          nv       0.95      0.92      0.93      1340\n        vasc       0.88      0.82      0.85        28\n\n    accuracy                           0.87      1998\n   macro avg       0.82      0.77      0.79      1998\nweighted avg       0.88      0.87      0.87      1998\n\nEpoch: 34 | train_loss: 0.1460 | train_acc: 0.9472 | test_loss: 0.6001 | test_acc: 0.8689 | \nEpoch: 35 | train_loss: 0.1165 | train_acc: 0.9586 | test_loss: 0.5890 | test_acc: 0.8579 | \n\nAccuracy Improved (0.8688688688688688 to 0.8733733733733734), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.92      0.89      0.90       262\n         bcc       0.94      0.95      0.95       412\n         bkl       0.91      0.91      0.91       880\n          df       0.97      0.96      0.96        93\n         mel       0.89      0.85      0.87       891\n          nv       0.97      0.98      0.97      5365\n        vasc       0.99      0.98      0.99       114\n\n    accuracy                           0.95      8017\n   macro avg       0.94      0.93      0.94      8017\nweighted avg       0.95      0.95      0.95      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.70      0.75      0.73        65\n         bcc       0.79      0.82      0.81       102\n         bkl       0.89      0.62      0.73       219\n          df       0.81      0.77      0.79        22\n         mel       0.67      0.70      0.68       222\n          nv       0.92      0.96      0.94      1340\n        vasc       0.83      0.86      0.84        28\n\n    accuracy                           0.87      1998\n   macro avg       0.80      0.78      0.79      1998\nweighted avg       0.87      0.87      0.87      1998\n\nEpoch: 36 | train_loss: 0.1288 | train_acc: 0.9521 | test_loss: 0.5221 | test_acc: 0.8734 | \nEpoch: 37 | train_loss: 0.1119 | train_acc: 0.9601 | test_loss: 0.5148 | test_acc: 0.8619 | \nEpoch: 38 | train_loss: 0.1164 | train_acc: 0.9597 | test_loss: 0.5070 | test_acc: 0.8519 | \nEpoch: 39 | train_loss: 0.0971 | train_acc: 0.9667 | test_loss: 0.6205 | test_acc: 0.8509 | \nEpoch: 40 | train_loss: 0.1239 | train_acc: 0.9535 | test_loss: 0.4939 | test_acc: 0.8619 | \nEpoch: 41 | train_loss: 0.1111 | train_acc: 0.9612 | test_loss: 0.5176 | test_acc: 0.8509 | \nEpoch: 42 | train_loss: 0.1183 | train_acc: 0.9597 | test_loss: 0.6132 | test_acc: 0.8619 | \nEpoch: 43 | train_loss: 0.1119 | train_acc: 0.9611 | test_loss: 0.4840 | test_acc: 0.8539 | \nEpoch: 44 | train_loss: 0.0952 | train_acc: 0.9643 | test_loss: 0.5177 | test_acc: 0.8544 | \nEpoch: 45 | train_loss: 0.1028 | train_acc: 0.9642 | test_loss: 0.4646 | test_acc: 0.8719 | \nEpoch: 46 | train_loss: 0.1046 | train_acc: 0.9630 | test_loss: 0.5014 | test_acc: 0.8709 | \nEpoch: 47 | train_loss: 0.1016 | train_acc: 0.9628 | test_loss: 0.5784 | test_acc: 0.8519 | \n\nAccuracy Improved (0.8733733733733734 to 0.8818818818818819), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.93      0.96      0.94       262\n         bcc       0.96      0.97      0.96       412\n         bkl       0.95      0.93      0.94       880\n          df       0.95      0.92      0.93        93\n         mel       0.92      0.90      0.91       891\n          nv       0.98      0.98      0.98      5365\n        vasc       1.00      0.99      1.00       114\n\n    accuracy                           0.97      8017\n   macro avg       0.95      0.95      0.95      8017\nweighted avg       0.97      0.97      0.97      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.83      0.69      0.76        65\n         bcc       0.89      0.83      0.86       102\n         bkl       0.84      0.73      0.78       219\n          df       0.83      0.68      0.75        22\n         mel       0.72      0.66      0.69       222\n          nv       0.91      0.96      0.94      1340\n        vasc       0.93      0.89      0.91        28\n\n    accuracy                           0.88      1998\n   macro avg       0.85      0.78      0.81      1998\nweighted avg       0.88      0.88      0.88      1998\n\nEpoch: 48 | train_loss: 0.1038 | train_acc: 0.9658 | test_loss: 0.4472 | test_acc: 0.8819 | \nEpoch: 49 | train_loss: 0.0947 | train_acc: 0.9681 | test_loss: 0.4598 | test_acc: 0.8779 | \nEpoch: 50 | train_loss: 0.0803 | train_acc: 0.9714 | test_loss: 0.5147 | test_acc: 0.8769 | \n\nAccuracy Improved (0.8818818818818819 to 0.8843843843843844), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.93      0.93      0.93       262\n         bcc       0.96      0.96      0.96       412\n         bkl       0.92      0.91      0.92       880\n          df       0.99      0.98      0.98        93\n         mel       0.93      0.91      0.92       891\n          nv       0.98      0.99      0.98      5365\n        vasc       0.98      0.97      0.98       114\n\n    accuracy                           0.97      8017\n   macro avg       0.96      0.95      0.95      8017\nweighted avg       0.97      0.97      0.97      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.62      0.86      0.72        65\n         bcc       0.85      0.81      0.83       102\n         bkl       0.73      0.86      0.79       219\n          df       0.94      0.68      0.79        22\n         mel       0.83      0.58      0.68       222\n          nv       0.94      0.95      0.95      1340\n        vasc       0.88      0.82      0.85        28\n\n    accuracy                           0.88      1998\n   macro avg       0.83      0.80      0.80      1998\nweighted avg       0.89      0.88      0.88      1998\n\nEpoch: 51 | train_loss: 0.0943 | train_acc: 0.9656 | test_loss: 0.4690 | test_acc: 0.8844 | \nEpoch: 52 | train_loss: 0.1016 | train_acc: 0.9645 | test_loss: 0.5615 | test_acc: 0.8579 | \nEpoch: 53 | train_loss: 0.0958 | train_acc: 0.9659 | test_loss: 0.4970 | test_acc: 0.8689 | \nEpoch: 54 | train_loss: 0.0877 | train_acc: 0.9679 | test_loss: 0.5163 | test_acc: 0.8574 | \nEpoch: 55 | train_loss: 0.1049 | train_acc: 0.9636 | test_loss: 0.8457 | test_acc: 0.8599 | \nEpoch: 56 | train_loss: 0.0904 | train_acc: 0.9683 | test_loss: 0.5333 | test_acc: 0.8634 | \nEpoch: 57 | train_loss: 0.0884 | train_acc: 0.9688 | test_loss: 0.4870 | test_acc: 0.8584 | \nEpoch: 58 | train_loss: 0.0953 | train_acc: 0.9668 | test_loss: 0.4911 | test_acc: 0.8804 | \nEpoch: 59 | train_loss: 0.0998 | train_acc: 0.9652 | test_loss: 0.5324 | test_acc: 0.8584 | \nEpoch: 60 | train_loss: 0.0955 | train_acc: 0.9649 | test_loss: 0.5562 | test_acc: 0.8739 | \nEpoch: 61 | train_loss: 0.0775 | train_acc: 0.9733 | test_loss: 0.4734 | test_acc: 0.8824 | \nEpoch: 62 | train_loss: 0.0905 | train_acc: 0.9688 | test_loss: 0.4825 | test_acc: 0.8759 | \nEpoch: 63 | train_loss: 0.0754 | train_acc: 0.9756 | test_loss: 0.5608 | test_acc: 0.8574 | \nEpoch: 64 | train_loss: 0.0936 | train_acc: 0.9662 | test_loss: 0.5021 | test_acc: 0.8699 | \nEpoch: 65 | train_loss: 0.0952 | train_acc: 0.9663 | test_loss: 0.4586 | test_acc: 0.8819 | \nEpoch: 66 | train_loss: 0.0714 | train_acc: 0.9754 | test_loss: 0.7575 | test_acc: 0.8193 | \nEpoch: 67 | train_loss: 0.0797 | train_acc: 0.9729 | test_loss: 0.5345 | test_acc: 0.8744 | \nEpoch: 68 | train_loss: 0.0803 | train_acc: 0.9701 | test_loss: 0.5699 | test_acc: 0.8539 | \nEpoch: 69 | train_loss: 0.0811 | train_acc: 0.9708 | test_loss: 0.6200 | test_acc: 0.8554 | \nEpoch: 70 | train_loss: 0.0871 | train_acc: 0.9727 | test_loss: 0.5126 | test_acc: 0.8654 | \nEpoch: 71 | train_loss: 0.0779 | train_acc: 0.9744 | test_loss: 0.5972 | test_acc: 0.8689 | \nEpoch: 72 | train_loss: 0.0809 | train_acc: 0.9719 | test_loss: 0.4986 | test_acc: 0.8809 | \nEpoch: 73 | train_loss: 0.0756 | train_acc: 0.9733 | test_loss: 0.5177 | test_acc: 0.8734 | \nEpoch: 74 | train_loss: 0.0736 | train_acc: 0.9741 | test_loss: 0.4936 | test_acc: 0.8724 | \nEpoch: 75 | train_loss: 0.0860 | train_acc: 0.9693 | test_loss: 0.5030 | test_acc: 0.8729 | \nEpoch: 76 | train_loss: 0.0904 | train_acc: 0.9702 | test_loss: 0.5313 | test_acc: 0.8669 | \nEpoch: 77 | train_loss: 0.0830 | train_acc: 0.9708 | test_loss: 0.5069 | test_acc: 0.8749 | \nEpoch: 78 | train_loss: 0.0796 | train_acc: 0.9729 | test_loss: 0.5589 | test_acc: 0.8483 | \nEpoch: 79 | train_loss: 0.0711 | train_acc: 0.9743 | test_loss: 0.5251 | test_acc: 0.8779 | \nEpoch: 80 | train_loss: 0.0610 | train_acc: 0.9788 | test_loss: 0.5855 | test_acc: 0.8724 | \nEpoch: 81 | train_loss: 0.0790 | train_acc: 0.9736 | test_loss: 0.5739 | test_acc: 0.8619 | \nEpoch: 82 | train_loss: 0.0659 | train_acc: 0.9763 | test_loss: 0.5621 | test_acc: 0.8639 | \nEpoch: 83 | train_loss: 0.0904 | train_acc: 0.9676 | test_loss: 0.6259 | test_acc: 0.8458 | \nEpoch: 84 | train_loss: 0.0658 | train_acc: 0.9777 | test_loss: 0.5980 | test_acc: 0.8659 | \nEpoch: 85 | train_loss: 0.0837 | train_acc: 0.9702 | test_loss: 0.5920 | test_acc: 0.8619 | \nEpoch: 86 | train_loss: 0.0650 | train_acc: 0.9751 | test_loss: 0.5562 | test_acc: 0.8764 | \nEpoch: 87 | train_loss: 0.0675 | train_acc: 0.9777 | test_loss: 0.5900 | test_acc: 0.8534 | \nEpoch: 88 | train_loss: 0.0735 | train_acc: 0.9743 | test_loss: 0.5717 | test_acc: 0.8554 | \nEpoch: 89 | train_loss: 0.0555 | train_acc: 0.9808 | test_loss: 0.7459 | test_acc: 0.8483 | \nEpoch: 90 | train_loss: 0.0923 | train_acc: 0.9677 | test_loss: 0.5806 | test_acc: 0.8549 | \nEpoch: 91 | train_loss: 0.0768 | train_acc: 0.9753 | test_loss: 0.5380 | test_acc: 0.8804 | \nEpoch: 92 | train_loss: 0.0713 | train_acc: 0.9733 | test_loss: 0.5295 | test_acc: 0.8674 | \nEpoch: 93 | train_loss: 0.0720 | train_acc: 0.9756 | test_loss: 0.5528 | test_acc: 0.8649 | \nEpoch: 94 | train_loss: 0.0713 | train_acc: 0.9759 | test_loss: 0.5590 | test_acc: 0.8734 | \nEpoch: 95 | train_loss: 0.0714 | train_acc: 0.9744 | test_loss: 0.6806 | test_acc: 0.8554 | \nEpoch: 96 | train_loss: 0.0813 | train_acc: 0.9714 | test_loss: 0.6433 | test_acc: 0.8233 | \nEpoch: 97 | train_loss: 0.0723 | train_acc: 0.9744 | test_loss: 0.5819 | test_acc: 0.8609 | \nEpoch: 98 | train_loss: 0.0656 | train_acc: 0.9777 | test_loss: 0.6399 | test_acc: 0.8514 | \nEpoch: 99 | train_loss: 0.0684 | train_acc: 0.9774 | test_loss: 0.6719 | test_acc: 0.8549 | \nEpoch: 100 | train_loss: 0.0688 | train_acc: 0.9758 | test_loss: 0.7204 | test_acc: 0.8549 | \nEpoch: 101 | train_loss: 0.0785 | train_acc: 0.9716 | test_loss: 0.6239 | test_acc: 0.8539 | \nEpoch: 102 | train_loss: 0.0589 | train_acc: 0.9788 | test_loss: 0.5685 | test_acc: 0.8734 | \nEpoch: 103 | train_loss: 0.0819 | train_acc: 0.9707 | test_loss: 0.5117 | test_acc: 0.8744 | \nEpoch: 104 | train_loss: 0.0704 | train_acc: 0.9758 | test_loss: 0.6207 | test_acc: 0.8579 | \nEpoch: 105 | train_loss: 0.0747 | train_acc: 0.9739 | test_loss: 0.5123 | test_acc: 0.8714 | \nEpoch: 106 | train_loss: 0.0574 | train_acc: 0.9812 | test_loss: 0.6209 | test_acc: 0.8774 | \nEpoch: 107 | train_loss: 0.0686 | train_acc: 0.9764 | test_loss: 0.4905 | test_acc: 0.8739 | \nEpoch: 108 | train_loss: 0.0634 | train_acc: 0.9797 | test_loss: 0.5733 | test_acc: 0.8664 | \n\nAccuracy Improved (0.8843843843843844 to 0.8883883883883884), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.93      0.94      0.93       262\n         bcc       0.96      0.96      0.96       412\n         bkl       0.96      0.95      0.95       880\n          df       0.96      0.97      0.96        93\n         mel       0.94      0.92      0.93       891\n          nv       0.99      0.99      0.99      5365\n        vasc       0.97      0.98      0.98       114\n\n    accuracy                           0.97      8017\n   macro avg       0.96      0.96      0.96      8017\nweighted avg       0.97      0.97      0.97      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.78      0.55      0.65        65\n         bcc       0.79      0.87      0.83       102\n         bkl       0.80      0.80      0.80       219\n          df       0.82      0.82      0.82        22\n         mel       0.72      0.71      0.72       222\n          nv       0.94      0.95      0.95      1340\n        vasc       1.00      0.82      0.90        28\n\n    accuracy                           0.89      1998\n   macro avg       0.84      0.79      0.81      1998\nweighted avg       0.89      0.89      0.89      1998\n\nEpoch: 109 | train_loss: 0.0722 | train_acc: 0.9734 | test_loss: 0.4821 | test_acc: 0.8884 | \nEpoch: 110 | train_loss: 0.0552 | train_acc: 0.9808 | test_loss: 0.6028 | test_acc: 0.8649 | \nEpoch: 111 | train_loss: 0.0676 | train_acc: 0.9753 | test_loss: 0.5827 | test_acc: 0.8639 | \nEpoch: 112 | train_loss: 0.0716 | train_acc: 0.9752 | test_loss: 0.5334 | test_acc: 0.8669 | \nEpoch: 113 | train_loss: 0.0737 | train_acc: 0.9749 | test_loss: 0.6767 | test_acc: 0.8453 | \nEpoch: 114 | train_loss: 0.0761 | train_acc: 0.9724 | test_loss: 0.8972 | test_acc: 0.8644 | \nEpoch: 115 | train_loss: 0.0692 | train_acc: 0.9756 | test_loss: 0.5881 | test_acc: 0.8654 | \nEpoch: 116 | train_loss: 0.0642 | train_acc: 0.9787 | test_loss: 0.7142 | test_acc: 0.8749 | \nEpoch: 117 | train_loss: 0.0655 | train_acc: 0.9768 | test_loss: 0.6307 | test_acc: 0.8574 | \nEpoch: 118 | train_loss: 0.0679 | train_acc: 0.9754 | test_loss: 0.5908 | test_acc: 0.8559 | \nEpoch: 119 | train_loss: 0.0735 | train_acc: 0.9738 | test_loss: 0.5533 | test_acc: 0.8679 | \nEpoch: 120 | train_loss: 0.0605 | train_acc: 0.9783 | test_loss: 0.5606 | test_acc: 0.8724 | \nEpoch: 121 | train_loss: 0.0638 | train_acc: 0.9783 | test_loss: 0.6394 | test_acc: 0.8458 | \nEpoch: 122 | train_loss: 0.0672 | train_acc: 0.9765 | test_loss: 0.6178 | test_acc: 0.8519 | \nEpoch: 123 | train_loss: 0.0577 | train_acc: 0.9804 | test_loss: 0.5568 | test_acc: 0.8699 | \nEpoch: 124 | train_loss: 0.0651 | train_acc: 0.9769 | test_loss: 0.5935 | test_acc: 0.8584 | \nEpoch: 125 | train_loss: 0.0756 | train_acc: 0.9721 | test_loss: 0.5890 | test_acc: 0.8714 | \nEpoch: 126 | train_loss: 0.0640 | train_acc: 0.9779 | test_loss: 0.5890 | test_acc: 0.8729 | \nEpoch: 127 | train_loss: 0.0600 | train_acc: 0.9783 | test_loss: 0.5960 | test_acc: 0.8584 | \nEpoch: 128 | train_loss: 0.0625 | train_acc: 0.9772 | test_loss: 0.5977 | test_acc: 0.8639 | \nEpoch: 129 | train_loss: 0.0684 | train_acc: 0.9761 | test_loss: 0.6923 | test_acc: 0.8549 | \nEpoch: 130 | train_loss: 0.0719 | train_acc: 0.9773 | test_loss: 0.5274 | test_acc: 0.8604 | \nEpoch: 131 | train_loss: 0.0553 | train_acc: 0.9818 | test_loss: 0.5782 | test_acc: 0.8684 | \nEpoch: 132 | train_loss: 0.0676 | train_acc: 0.9761 | test_loss: 0.5670 | test_acc: 0.8729 | \nEpoch: 133 | train_loss: 0.0635 | train_acc: 0.9770 | test_loss: 0.6271 | test_acc: 0.8473 | \nEpoch: 134 | train_loss: 0.0699 | train_acc: 0.9761 | test_loss: 0.9528 | test_acc: 0.7497 | \nEpoch: 135 | train_loss: 0.0812 | train_acc: 0.9722 | test_loss: 0.5622 | test_acc: 0.8589 | \nEpoch: 136 | train_loss: 0.0618 | train_acc: 0.9783 | test_loss: 0.5472 | test_acc: 0.8834 | \nEpoch: 137 | train_loss: 0.0758 | train_acc: 0.9749 | test_loss: 0.4967 | test_acc: 0.8734 | \nEpoch: 138 | train_loss: 0.0642 | train_acc: 0.9793 | test_loss: 0.5423 | test_acc: 0.8669 | \nEpoch: 139 | train_loss: 0.0539 | train_acc: 0.9823 | test_loss: 0.6568 | test_acc: 0.8664 | \nEpoch: 140 | train_loss: 0.0788 | train_acc: 0.9707 | test_loss: 0.6127 | test_acc: 0.8559 | \nEpoch: 141 | train_loss: 0.0563 | train_acc: 0.9809 | test_loss: 0.6677 | test_acc: 0.8684 | \nEpoch: 142 | train_loss: 0.0493 | train_acc: 0.9837 | test_loss: 0.6323 | test_acc: 0.8669 | \nEpoch: 143 | train_loss: 0.0759 | train_acc: 0.9728 | test_loss: 0.6137 | test_acc: 0.8448 | \nEpoch: 144 | train_loss: 0.0713 | train_acc: 0.9743 | test_loss: 0.6685 | test_acc: 0.8524 | \nEpoch: 145 | train_loss: 0.0816 | train_acc: 0.9698 | test_loss: 0.5018 | test_acc: 0.8874 | \nEpoch: 146 | train_loss: 0.0577 | train_acc: 0.9789 | test_loss: 0.5992 | test_acc: 0.8684 | \nEpoch: 147 | train_loss: 0.0605 | train_acc: 0.9783 | test_loss: 0.6134 | test_acc: 0.8534 | \nEpoch: 148 | train_loss: 0.0650 | train_acc: 0.9769 | test_loss: 0.7858 | test_acc: 0.8208 | \nEpoch: 149 | train_loss: 0.0551 | train_acc: 0.9809 | test_loss: 0.6010 | test_acc: 0.8644 | \nEpoch: 150 | train_loss: 0.0605 | train_acc: 0.9787 | test_loss: 0.5431 | test_acc: 0.8544 | \nEpoch: 151 | train_loss: 0.0814 | train_acc: 0.9707 | test_loss: 0.5289 | test_acc: 0.8544 | \nEpoch: 152 | train_loss: 0.0656 | train_acc: 0.9769 | test_loss: 0.6444 | test_acc: 0.8569 | \nEpoch: 153 | train_loss: 0.0773 | train_acc: 0.9739 | test_loss: 0.5526 | test_acc: 0.8694 | \nEpoch: 154 | train_loss: 0.0692 | train_acc: 0.9758 | test_loss: 0.5719 | test_acc: 0.8659 | \nEpoch: 155 | train_loss: 0.0604 | train_acc: 0.9793 | test_loss: 0.5154 | test_acc: 0.8859 | \nEpoch: 156 | train_loss: 0.0446 | train_acc: 0.9854 | test_loss: 0.6619 | test_acc: 0.8609 | \nEpoch: 157 | train_loss: 0.0701 | train_acc: 0.9738 | test_loss: 0.7136 | test_acc: 0.8418 | \nEpoch: 158 | train_loss: 0.0707 | train_acc: 0.9764 | test_loss: 0.5777 | test_acc: 0.8719 | \nEpoch: 159 | train_loss: 0.0697 | train_acc: 0.9763 | test_loss: 0.5162 | test_acc: 0.8779 | \nEpoch: 160 | train_loss: 0.0613 | train_acc: 0.9790 | test_loss: 0.6114 | test_acc: 0.8559 | \nEpoch: 161 | train_loss: 0.0634 | train_acc: 0.9779 | test_loss: 0.6007 | test_acc: 0.8624 | \nEpoch: 162 | train_loss: 0.0587 | train_acc: 0.9790 | test_loss: 0.6031 | test_acc: 0.8729 | \nEpoch: 163 | train_loss: 0.0782 | train_acc: 0.9708 | test_loss: 0.7139 | test_acc: 0.8478 | \nEpoch: 164 | train_loss: 0.0691 | train_acc: 0.9758 | test_loss: 0.6732 | test_acc: 0.8529 | \nEpoch: 165 | train_loss: 0.0680 | train_acc: 0.9764 | test_loss: 0.5919 | test_acc: 0.8709 | \nEpoch: 166 | train_loss: 0.0562 | train_acc: 0.9809 | test_loss: 0.7202 | test_acc: 0.8644 | \nEpoch: 167 | train_loss: 0.0635 | train_acc: 0.9780 | test_loss: 0.5472 | test_acc: 0.8549 | \nEpoch: 168 | train_loss: 0.0716 | train_acc: 0.9748 | test_loss: 0.5815 | test_acc: 0.8634 | \nEpoch: 169 | train_loss: 0.0623 | train_acc: 0.9775 | test_loss: 0.5529 | test_acc: 0.8714 | \nEpoch: 170 | train_loss: 0.0639 | train_acc: 0.9778 | test_loss: 0.6649 | test_acc: 0.8498 | \nEpoch: 171 | train_loss: 0.0637 | train_acc: 0.9795 | test_loss: 0.6034 | test_acc: 0.8483 | \nEpoch: 172 | train_loss: 0.0724 | train_acc: 0.9747 | test_loss: 0.5954 | test_acc: 0.8619 | \nEpoch: 173 | train_loss: 0.0630 | train_acc: 0.9774 | test_loss: 0.5149 | test_acc: 0.8629 | \nEpoch: 174 | train_loss: 0.0697 | train_acc: 0.9747 | test_loss: 0.5502 | test_acc: 0.8734 | \nEpoch: 175 | train_loss: 0.0658 | train_acc: 0.9789 | test_loss: 0.5515 | test_acc: 0.8604 | \nEpoch: 176 | train_loss: 0.0570 | train_acc: 0.9807 | test_loss: 0.5931 | test_acc: 0.8649 | \nEpoch: 177 | train_loss: 0.0633 | train_acc: 0.9761 | test_loss: 0.7173 | test_acc: 0.8233 | \nEpoch: 178 | train_loss: 0.0693 | train_acc: 0.9753 | test_loss: 0.7963 | test_acc: 0.8338 | \nEpoch: 179 | train_loss: 0.0648 | train_acc: 0.9788 | test_loss: 0.6758 | test_acc: 0.8559 | \nEpoch: 180 | train_loss: 0.0736 | train_acc: 0.9732 | test_loss: 0.6293 | test_acc: 0.8614 | \nEpoch: 181 | train_loss: 0.0666 | train_acc: 0.9769 | test_loss: 0.5509 | test_acc: 0.8629 | \n","output_type":"stream"}],"execution_count":null}]}