{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6593890,"sourceType":"datasetVersion","datasetId":3259629},{"sourceId":6594068,"sourceType":"datasetVersion","datasetId":3805471},{"sourceId":6618979,"sourceType":"datasetVersion","datasetId":3820073},{"sourceId":6619867,"sourceType":"datasetVersion","datasetId":3820601},{"sourceId":6690251,"sourceType":"datasetVersion","datasetId":3857852},{"sourceId":6693195,"sourceType":"datasetVersion","datasetId":3859103},{"sourceId":6694105,"sourceType":"datasetVersion","datasetId":3859504},{"sourceId":6699621,"sourceType":"datasetVersion","datasetId":3861661}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 0. Importing necessary libraries,<br> Creating a folder for storing python scripts,<br> Setting up device-agnostic code\n\nSince we're going to be creating Python scripts out of our most useful code cells, let's create a folder for storing those scripts.\n\nWe'll call the folder `TinyVGG_pytorch` and create it using Python's [`os.makedirs()`](https://docs.python.org/3/library/os.html) method.","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\n\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:38.574604Z","iopub.execute_input":"2023-10-15T14:14:38.574929Z","iopub.status.idle":"2023-10-15T14:14:43.873577Z","shell.execute_reply.started":"2023-10-15T14:14:38.574904Z","shell.execute_reply":"2023-10-15T14:14:43.872594Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'2.0.0'"},"metadata":{}}]},{"cell_type":"markdown","source":"Creating a folder for python scripts","metadata":{}},{"cell_type":"code","source":"# os.makedirs(\"going_modular\", exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:43.878273Z","iopub.execute_input":"2023-10-15T14:14:43.878593Z","iopub.status.idle":"2023-10-15T14:14:43.884912Z","shell.execute_reply.started":"2023-10-15T14:14:43.878570Z","shell.execute_reply":"2023-10-15T14:14:43.883691Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Setting up device-agnostic code","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\n# temp = torch.cuda.device_count()\n# temp\n# torch.cuda.get_device_capability()\n\n\n# import psutil\n# psutil.cpu_count(logical=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:43.886683Z","iopub.execute_input":"2023-10-15T14:14:43.887452Z","iopub.status.idle":"2023-10-15T14:14:43.998647Z","shell.execute_reply.started":"2023-10-15T14:14:43.887419Z","shell.execute_reply":"2023-10-15T14:14:43.997537Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"# **0. Data Preparation**","metadata":{}},{"cell_type":"code","source":"# import os\n# import zipfile\n\n# from pathlib import Path\n# import random\n# import shutil\n# from shutil import copyfile\n\n# import requests\n# import pandas as pd\n\n# # Setup path to data folder\n# data_path = Path(\"/kaggle/input/ham10000/HAM10000\")\n# # image_path = data_path / \"Retinal_image_Aptos_Eyepacs_splitted\" # FOLDER path = splitted dataset into Train & Test\n# # image_path_all = data_path / \"15 test test\" # FOLDER path = not yet splitted dataset\n# classes_dir = Path(\"/kaggle/working/Classes\")\n# csv_location = data_path/'HAM10000_metadata.csv'","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.001756Z","iopub.execute_input":"2023-10-15T14:14:44.004217Z","iopub.status.idle":"2023-10-15T14:14:44.011001Z","shell.execute_reply.started":"2023-10-15T14:14:44.004183Z","shell.execute_reply":"2023-10-15T14:14:44.010147Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# # tasks -\n# #          1. taking the \"train\" folder images into \"____all\" folder using train.csv with making no of folder-classes inside it\n\n# import shutil\n# from tqdm import tqdm\n\n# df_train_csv = pd.read_csv(csv_location)\n# # print(df_train_csv.columns)\n# class_names = df_train_csv['dx'].unique()\n# print(df_train_csv['dx'].value_counts())\n\n\n# # COMMENT IT IF MAKING DIRECTORIES && NOT COPYING----------(train)-------------------\n\n# ## making directories according to no of classes\n# if not os.path.exists(classes_dir):\n#     os.makedirs(classes_dir)\n    \n# for i in range(len(class_names)):\n#     name = class_names[i]\n#     os.makedirs(f'{classes_dir}/{name}', exist_ok=True)  \n\n\n\n\n# # # taking images from train folder --> __all forder's class folder\n# for i in tqdm(range(len(df_train_csv))):\n#     image_name = df_train_csv[\"image_id\"][i]\n#     class_name = df_train_csv[\"dx\"][i]\n#     source_path =  data_path/\"Images\"/f\"{image_name}.jpg\"\n#     destination =  classes_dir/f\"{class_name}\"\n#     shutil.copy(source_path, destination)\n# #     print(os.access(destination, os.W_OK))\n\n# # COMMENT IT IF NOT COPYING--------------------------------(train)-------------------\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.012345Z","iopub.execute_input":"2023-10-15T14:14:44.016097Z","iopub.status.idle":"2023-10-15T14:14:44.023526Z","shell.execute_reply.started":"2023-10-15T14:14:44.016061Z","shell.execute_reply":"2023-10-15T14:14:44.022627Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# # Split the dataset if not splitted into - \"Retinal_image_splitted\" folder\n\n# source_path = classes_dir\n# source_path_class_based_list = []\n\n# for i in range(len(class_names)):\n#     source_path_class_based_list.append(os.path.join(source_path, f\"{class_names[i]}\"))\n\n# # # Deletes all non-image files (there are two .db files bundled into the dataset)\n# # # !find / tmp/PetImages / -type f ! -name \"*.jpg\" -exec rm {} +\n\n# for i in range(len(class_names)):\n#     print(f\"There are {len(os.listdir(source_path_class_based_list[i]))} images of Class {class_names[i]}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.024698Z","iopub.execute_input":"2023-10-15T14:14:44.027940Z","iopub.status.idle":"2023-10-15T14:14:44.039438Z","shell.execute_reply.started":"2023-10-15T14:14:44.027907Z","shell.execute_reply":"2023-10-15T14:14:44.038322Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# # Define root directory\n# if not os.path.exists('/kaggle/working/Splitted'):\n#     os.makedirs(Path('/kaggle/working/Splitted'))\n    \n# root_dir = Path('/kaggle/working/Splitted')\n\n# # Empty directory to prevent FileExistsError is the function is run several times\n# if os.path.exists(root_dir):\n#     shutil.rmtree(f\"{root_dir}/\")\n\n# # GRADED FUNCTION: create_train_val_dirs\n\n\n# def create_train_val_dirs(root_path, class_names):\n#     \"\"\"\n#     Creates directories for the train and test sets\n\n#     Args:\n#       root_path (string) - the base directory path to create subdirectories from\n\n#     Returns:\n#       None\n#     \"\"\"\n#     # START CODE HERE\n\n#     # HINT:\n#     # Use os.makedirs to create your directories with intermediate subdirectories\n#     # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n\n#     import os\n\n#     training_dir = os.path.join(root_dir, \"train\")\n#     testing_dir = os.path.join(root_dir, \"test\")\n    \n#     if not (os.path.exists(training_dir) and os.path.exists(testing_dir)):\n#         os.makedirs(training_dir)\n#         os.makedirs(testing_dir)\n    \n    \n#     training_dir_classes_list = []\n    \n#     for i in range(len(class_names)):\n#         path_train = os.path.join(training_dir, f\"{class_names[i]}\")\n#         if not os.path.exists(path_train):\n#             os.makedirs(path_train)\n        \n#         path_test = os.path.join(testing_dir, f\"{class_names[i]}\")\n#         if not os.path.exists(path_test):\n#             os.makedirs(path_test)\n\n#     return training_dir, testing_dir\n#     # END CODE HERE\n\n\n# try:\n#     training_dir, testing_dir = create_train_val_dirs(root_path=root_dir, \n#                                                       class_names=class_names)\n# except FileExistsError:\n#     print(\"You should not be seeing this since the upper directory is removed beforehand\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.040261Z","iopub.execute_input":"2023-10-15T14:14:44.040649Z","iopub.status.idle":"2023-10-15T14:14:44.051825Z","shell.execute_reply.started":"2023-10-15T14:14:44.040518Z","shell.execute_reply":"2023-10-15T14:14:44.050764Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# # Test your create_train_val_dirs function\n\n# for rootdir, dirs, files in os.walk(root_dir):\n#     for subdir in dirs:\n#         print(os.path.join(rootdir, subdir))","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.053138Z","iopub.execute_input":"2023-10-15T14:14:44.053444Z","iopub.status.idle":"2023-10-15T14:14:44.070286Z","shell.execute_reply.started":"2023-10-15T14:14:44.053416Z","shell.execute_reply":"2023-10-15T14:14:44.069258Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# # GRADED FUNCTION: split_data\n# def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n#     \"\"\"\n#     Splits the data into train and test sets\n\n#     Args:\n#       SOURCE_DIR (string): directory path containing the images\n#       TRAINING_DIR (string): directory path to be used for training\n#       VALIDATION_DIR (string): directory path to be used for validation\n#       SPLIT_SIZE (float): proportion of the dataset to be used for training\n\n#     Returns:\n#       None\n#     \"\"\"\n\n#     # START CODE HERE\n\n#     contents_source_dir = os.listdir(SOURCE_DIR)\n#     contents_source_dir = random.sample(contents_source_dir, len(contents_source_dir))\n\n#     training_number = int(len(contents_source_dir) * SPLIT_SIZE)\n#     target_dir = TRAINING_DIR\n\n#     for index in range(len(contents_source_dir)):\n#         if os.path.getsize(os.path.join(SOURCE_DIR, contents_source_dir[index])) == 0:\n#             print(f\"{contents_source_dir[index]} is zero length, so ignoring.\")\n#         else:\n#             copyfile(os.path.join(SOURCE_DIR, contents_source_dir[index]), os.path.join(target_dir, contents_source_dir[index]))\n\n#         if index == training_number:\n#             target_dir = VALIDATION_DIR\n\n#     # END CODE HERE\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.071247Z","iopub.execute_input":"2023-10-15T14:14:44.072375Z","iopub.status.idle":"2023-10-15T14:14:44.085373Z","shell.execute_reply.started":"2023-10-15T14:14:44.072299Z","shell.execute_reply":"2023-10-15T14:14:44.084288Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# # Empty directories in case you run this cell multiple times\n# # if len(os.listdir(training_Healthy_dir)) > 0:\n# #     for file in os.scandir(training_Healthy_dir):\n# #         os.remove(file.path)\n\n# # if len(os.listdir(training_Mild_DR_dir)) > 0:\n# #     for file in os.scandir(training_Mild_DR_dir):\n# #         os.remove(file.path)\n\n# # if len(os.listdir(training_Moderate_DR_dir)) > 0:\n# #     for file in os.scandir(training_Moderate_DR_dir):\n# #         os.remove(file.path)\n\n# # if len(os.listdir(training_Proliferate_DR_dir)) > 0:\n# #     for file in os.scandir(training_Proliferate_DR_dir):\n# #         os.remove(file.path)\n\n# # if len(os.listdir(training_Severe_DR_dir)) > 0:\n# #     for file in os.scandir(training_Severe_DR_dir):\n# #         os.remove(file.path)\n\n\n\n\n# # if len(os.listdir(testing_Healthy_dir)) > 0:\n# #     for file in os.scandir(testing_Healthy_dir):\n# #         os.remove(file.path)\n\n# # if len(os.listdir(testing_Mild_DR_dir)) > 0:\n# #     for file in os.scandir(testing_Mild_DR_dir):\n# #         os.remove(file.path)\n\n# # if len(os.listdir(testing_Moderate_DR_dir)) > 0:\n# #     for file in os.scandir(testing_Moderate_DR_dir):\n# #         os.remove(file.path)\n\n# # if len(os.listdir(testing_Proliferate_DR_dir)) > 0:\n# #     for file in os.scandir(testing_Proliferate_DR_dir):\n# #         os.remove(file.path)\n\n# # if len(os.listdir(testing_Severe_DR_dir)) > 0:\n# #     for file in os.scandir(testing_Severe_DR_dir):\n# #         os.remove(file.path)\n\n# # Define proportion of images used for training\n# split_size = .8\n\n# # Run the function\n# # NOTE: Messages about zero length images should be printed out\n# for i in tqdm(range(len(class_names))):\n#     source_path = os.path.join(classes_dir, f\"{class_names[i]}\")\n#     train_path = os.path.join(training_dir, f\"{class_names[i]}\")\n#     test_path = os.path.join(testing_dir, f\"{class_names[i]}\")\n    \n#     split_data(source_path, train_path, test_path, split_size)\n\n\n# # Check that the number of images matches the expected output\n\n# # # Your function should perform copies rather than moving images so original directories should contain unchanged images\n# # print(f\"\\n\\nOriginal Healthy directory has {len(os.listdir(source_path_Healthy))} images\")\n# # print(f\"Original Mild DR directory has {len(os.listdir(source_path_Mild_DR))} images\")\n# # print(f\"Original Moderate DR directory has {len(os.listdir(source_path_Moderate_DR))} images\")\n# # print(f\"Original Proliferate DR directory has {len(os.listdir(source_path_Proliferate_DR))} images\")\n# # print(f\"Original Severe DR directory has {len(os.listdir(source_path_Severe_DR))} images\\n\")\n\n# # # Training and validation splits\n# # print(f\"There are {len(os.listdir(training_Healthy_dir))} images of Healthy for training\")\n# # print(f\"There are {len(os.listdir(training_Mild_DR_dir))} images of Mild DR for training\")\n# # print(f\"There are {len(os.listdir(training_Moderate_DR_dir))} images of Moderate DR for training\")\n# # print(f\"There are {len(os.listdir(training_Proliferate_DR_dir))} images of Proliferate DR for training\")\n# # print(f\"There are {len(os.listdir(training_Severe_DR_dir))} images of Severe for training\\n\\n\")\n\n# # print(f\"There are {len(os.listdir(testing_Healthy_dir))} images of Healthy for Validation\")\n# # print(f\"There are {len(os.listdir(testing_Mild_DR_dir))} images of Mild DR for Validation\")\n# # print(f\"There are {len(os.listdir(testing_Moderate_DR_dir))} images of Moderate DR for Validation\")\n# # print(f\"There are {len(os.listdir(testing_Proliferate_DR_dir))} images of Proliferate DR for Validation\")\n# # print(f\"There are {len(os.listdir(testing_Severe_DR_dir))} images of Severe for Validation\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.090630Z","iopub.execute_input":"2023-10-15T14:14:44.091289Z","iopub.status.idle":"2023-10-15T14:14:44.104480Z","shell.execute_reply.started":"2023-10-15T14:14:44.091259Z","shell.execute_reply":"2023-10-15T14:14:44.103454Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **Gaussian Filter**","metadata":{}},{"cell_type":"code","source":"# ! pip install imutils","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.106682Z","iopub.execute_input":"2023-10-15T14:14:44.107725Z","iopub.status.idle":"2023-10-15T14:14:44.119349Z","shell.execute_reply.started":"2023-10-15T14:14:44.107692Z","shell.execute_reply":"2023-10-15T14:14:44.118237Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# import os\n# from pathlib import Path\n# import imutils\n# import cv2\n# from tqdm.auto import tqdm\n\n# sigmaX = 10\n\n# rootdir = Path(\"/kaggle/input/ham10000-splitted/Images splitted/Splitted/train/mel\")\n# savedir = Path(\"/kaggle/working/splitted/train/mel\")\n\n# if not os.path.exists(savedir):\n#     os.makedirs(savedir)\n\n# for rootdir, dirs, files in os.walk(rootdir):\n#     print(rootdir)\n#     for file in tqdm(files):\n#         try:\n#             read_path = os.path.join(rootdir, file)\n#             write_path = f\"{savedir}/{file}\"\n#             image = cv2.imread(read_path)\n#             image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0), sigmaX), -4, 128)\n#             # gaussian = cv2.resize(image, (224,224))\n#             # gaussian = imutils.resize(image, height=224)\n#             cv2.imwrite(write_path, image)\n#         except:\n#             print(\"...\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.120301Z","iopub.execute_input":"2023-10-15T14:14:44.120582Z","iopub.status.idle":"2023-10-15T14:14:44.132222Z","shell.execute_reply.started":"2023-10-15T14:14:44.120552Z","shell.execute_reply":"2023-10-15T14:14:44.131159Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# **1. Get data**\n","metadata":{}},{"cell_type":"markdown","source":"Data might be downloaded as splitted (ready-made) or not. If not, we need to take care of it by splitting by ourself own <br>\nIf the image folder doesn't exist, download it as \"Retinal_image_all folder\" and prepare it... ","metadata":{}},{"cell_type":"code","source":"import os\nimport zipfile\n\nfrom pathlib import Path\nimport random\nimport shutil\nfrom shutil import copyfile\n\nimport requests\nimport pandas as pd\n\n# Setup path to data folder\ndata_path = Path(\"/kaggle/input/ham10000-splitted/Images splitted/Splitted\")\nimage_path = data_path # FOLDER path = splitted dataset into Train & Test\n# image_path_all = data_path / \"all\" # FOLDER path = not yet splitted dataset\n\n\n\n# # If the image folder doesn't exist, download it as \"Retinal_image_all folder\" and prepare it... \n\n\n\n# if image_path.is_dir():\n#     print(f\"{image_path} directory exists.\")\n# else:\n#     print(f\"Did not find {image_path} directory, creating one...\")\n#     image_path.mkdir(parents=True, exist_ok=True)\n    \n# # Download pizza, steak, sushi data\n# with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n#     request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n#     print(\"Downloading pizza, steak, sushi data...\")\n#     f.write(request.content)\n\n# # Unzip pizza, steak, sushi data\n# with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n#     print(\"Unzipping pizza, steak, sushi data...\") \n#     zip_ref.extractall(image_path)\n\n# # Remove zip file\n# os.remove(data_path / \"pizza_steak_sushi.zip\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.133183Z","iopub.execute_input":"2023-10-15T14:14:44.134317Z","iopub.status.idle":"2023-10-15T14:14:44.734005Z","shell.execute_reply.started":"2023-10-15T14:14:44.134285Z","shell.execute_reply":"2023-10-15T14:14:44.733051Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### (If necessary) Preparing the dataset into class-folders using csv info - maybe splitting isn't necessary when we have \"train.csv\" and \"test.csv\"","metadata":{}},{"cell_type":"code","source":"## tasks -\n##          1. taking the \"train\" folder images into \"____all\" folder using train.csv with making no of folder-classes inside it\n\n# import shutil\n\n# csv_location = data_path / \"train.csv\"\n# # csv_location_test = data_path / \"test.csv\"\n\n# df_train_csv = pd.read_csv(csv_location)\n# # df_test_csv = pd.read_csv(csv_location_test)\n\n# class_names = df_train_csv['diagnosis'].unique()\n\n\n# COMMENT IT IF MAKING DIRECTORIES && NOT COPYING----------(train)-------------------\n\n# ## making directories according to no of classes\n# for i in range(len(class_names)):\n#     name = class_names[i]\n#     os.makedirs(f'{image_path_all}/{name}', exist_ok=True)  \n\n\n\n\n# ## taking images from train folder --> __all forder's class folder\n# for i in range(len(df_train_csv)):\n#     image_name = df_train_csv[\"id_code\"][i]\n#     class_name = df_train_csv[\"diagnosis\"][i]\n#     source_path = data_path / \"train_images\" / f\"{image_name}.png\"\n#     destination = image_path_all/ f\"{class_name}\"/ f\"{image_name}.png\"\n#     shutil.copyfile(source_path, destination)\n\n# COMMENT IT IF NOT COPYING--------------------------------(train)-------------------\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.735405Z","iopub.execute_input":"2023-10-15T14:14:44.736364Z","iopub.status.idle":"2023-10-15T14:14:44.743967Z","shell.execute_reply.started":"2023-10-15T14:14:44.736323Z","shell.execute_reply":"2023-10-15T14:14:44.742825Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# no of samples per class\n\n# classes = os.listdir(image_path_all)\n# classes_no_of_data_dict = {}\n\n# for i in range(len(classes)):\n#     classes_no_of_data_dict[classes[i]] = len(os.listdir(image_path_all/classes[i]))\n\n# classes_no_of_data_dict\n\n\n\n\n\n\n## When you only upload splitted folder\nclasses = os.listdir(f'{image_path}/train')\nclasses_no_of_data_dict = {}\n# classes.remove(\"desktop.ini\")\nclasses\n\nfor i in range(len(classes)):\n    classes_no_of_data_dict[classes[i]] = len(os.listdir(f'{image_path}/train/{classes[i]}'))\n    \nfor i in range(len(classes)):\n    temp = len(os.listdir(f'{image_path}/test/{classes[i]}'))\n    classes_no_of_data_dict[classes[i]] = classes_no_of_data_dict[classes[i]] + temp\n\nclasses_no_of_data_dict","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:44.745299Z","iopub.execute_input":"2023-10-15T14:14:44.748450Z","iopub.status.idle":"2023-10-15T14:14:45.930172Z","shell.execute_reply.started":"2023-10-15T14:14:44.748400Z","shell.execute_reply":"2023-10-15T14:14:45.929259Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'mel': 1113,\n 'vasc': 142,\n 'df': 115,\n 'nv': 6705,\n 'bkl': 1099,\n 'akiec': 327,\n 'bcc': 514}"},"metadata":{}}]},{"cell_type":"markdown","source":" ### If dataset balanced or not?\n <a href=\"https://matplotlib.org/stable/gallery/lines_bars_and_markers/categorical_variables.html#sphx-glr-gallery-lines-bars-and-markers-categorical-variables-py\n\">Matplotlib documentation - plotting categorical values</a>\n\n\n```Python\ndata = {'apple': 10, 'orange': 15, 'lemon': 5, 'lime': 20}\nnames = list(data.keys())\nvalues = list(data.values())\n\nfig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True)\naxs[0].bar(names, values)\naxs[1].scatter(names, values)\naxs[2].plot(names, values)\nfig.suptitle('Categorical Plotting')\n```","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\ndata = classes_no_of_data_dict\nnames = list(data.keys())\nvalues = list(data.values())\n\nfig, axs = plt.subplots(nrows=1, ncols=3, figsize=(24, 8), sharey=True)\naxs[0].bar(names, values)\naxs[1].scatter(names, values)\naxs[2].plot(names, values)\nfig.suptitle('Categorical Plotting')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:45.934394Z","iopub.execute_input":"2023-10-15T14:14:45.936588Z","iopub.status.idle":"2023-10-15T14:14:46.847904Z","shell.execute_reply.started":"2023-10-15T14:14:45.936549Z","shell.execute_reply":"2023-10-15T14:14:46.845939Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 0.98, 'Categorical Plotting')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 2400x800 with 3 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"### Splitting","metadata":{}},{"cell_type":"markdown","source":"Data Description \n\n<ul>\n    <li> 0 - No DR </li>\n    <li> 1 - Mild </li>\n    <li> 2 - Moderate </li>\n    <li> 3 - Severe </li>\n    <li> 4 - Proliferative DR </li>\n<ul>","metadata":{}},{"cell_type":"code","source":"# # Split the dataset if not splitted into - \"Retinal_image_splitted\" folder\n\n# source_path = image_path_all\n# print(source_path)\n\n# source_path_Healthy = os.path.join(source_path, 'Healthy')\n# source_path_Mild_DR = os.path.join(source_path, 'Mild_DR')\n# source_path_Moderate_DR = os.path.join(source_path, 'Moderate_DR')\n# source_path_Proliferate_DR = os.path.join(source_path, 'Proliferate_DR')\n# source_path_Severe_DR = os.path.join(source_path, 'Severe_DR')\n\n# # Deletes all non-image files (there are two .db files bundled into the dataset)\n# # !find / tmp/PetImages / -type f ! -name \"*.jpg\" -exec rm {} +\n\n# # os.listdir returns a list containing all files under the given path\n# print(f\"There are {len(os.listdir(source_path_Healthy))} images of Healthy retinal fundus iamges.\")\n# print(f\"There are {len(os.listdir(source_path_Mild_DR))} images of Mild DR retinal fundus iamges.\")\n# print(f\"There are {len(os.listdir(source_path_Moderate_DR))} images of Moderate DR retinal fundus iamges.\")\n# print(f\"There are {len(os.listdir(source_path_Proliferate_DR))} images of Proliferate DR retinal fundus iamges.\")\n# print(f\"There are {len(os.listdir(source_path_Severe_DR))} images of Severe DR retinal fundus images.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:46.849210Z","iopub.execute_input":"2023-10-15T14:14:46.849628Z","iopub.status.idle":"2023-10-15T14:14:46.870752Z","shell.execute_reply.started":"2023-10-15T14:14:46.849587Z","shell.execute_reply":"2023-10-15T14:14:46.859146Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# # Define root directory\n# root_dir = image_path\n\n# # # Empty directory to prevent FileExistsError is the function is run several times\n# # if os.path.exists(root_dir):\n# #     shutil.rmtree(root_dir)\n\n# # # GRADED FUNCTION: create_train_val_dirs\n\n\n# def create_train_val_dirs(root_path):\n#     \"\"\"\n#     Creates directories for the train and test sets\n\n#     Args:\n#       root_path (string) - the base directory path to create subdirectories from\n\n#     Returns:\n#       None\n#     \"\"\"\n#     # START CODE HERE\n\n#     # HINT:\n#     # Use os.makedirs to create your directories with intermediate subdirectories\n#     # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n\n#     import os\n\n#     training_dir = os.path.join(root_dir, \"train\")\n#     testing_dir = os.path.join(root_dir, \"test\")\n#     os.makedirs(training_dir)\n#     os.makedirs(testing_dir)\n\n#     training_Healthy_dir = os.path.join(training_dir, \"Healthy\")\n#     training_Mild_DR_dir = os.path.join(training_dir, \"Mild_DR\")\n#     training_Moderate_DR_dir = os.path.join(training_dir, \"Moderate_DR\")\n#     training_Proliferate_DR_dir = os.path.join(training_dir, \"Proliferate_DR\")\n#     training_Severe_DR_dir = os.path.join(training_dir, \"Severe_DR\")\n#     os.makedirs(training_Healthy_dir)\n#     os.makedirs(training_Mild_DR_dir)\n#     os.makedirs(training_Moderate_DR_dir)\n#     os.makedirs(training_Proliferate_DR_dir)\n#     os.makedirs(training_Severe_DR_dir)\n\n#     testing_Healthy_dir = os.path.join(testing_dir, \"Healthy\")\n#     testing_Mild_DR_dir = os.path.join(testing_dir, \"Mild_DR\")\n#     testing_Moderate_DR_dir = os.path.join(testing_dir, \"Moderate_DR\")\n#     testing_Proliferate_DR_dir = os.path.join(testing_dir, \"Proliferate_DR\")\n#     testing_Severe_DR_dir = os.path.join(testing_dir, \"Severe_DR\")\n#     os.makedirs(testing_Healthy_dir)\n#     os.makedirs(testing_Mild_DR_dir)\n#     os.makedirs(testing_Moderate_DR_dir)\n#     os.makedirs(testing_Proliferate_DR_dir)\n#     os.makedirs(testing_Severe_DR_dir)\n\n#     return training_dir, testing_dir, training_Healthy_dir, training_Mild_DR_dir, training_Moderate_DR_dir, training_Proliferate_DR_dir, training_Severe_DR_dir, testing_Healthy_dir, testing_Mild_DR_dir, testing_Moderate_DR_dir, testing_Proliferate_DR_dir, testing_Severe_DR_dir\n#     # END CODE HERE\n\n\n# try:\n#     training_dir, testing_dir, training_Healthy_dir, training_Mild_DR_dir, training_Moderate_DR_dir, training_Proliferate_DR_dir, training_Severe_DR_dir, testing_Healthy_dir, testing_Mild_DR_dir, testing_Moderate_DR_dir, testing_Proliferate_DR_dir, testing_Severe_DR_dir = create_train_val_dirs(root_path=root_dir)\n# except FileExistsError:\n#     print(\"You should not be seeing this since the upper directory is removed beforehand\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:46.872948Z","iopub.execute_input":"2023-10-15T14:14:46.873988Z","iopub.status.idle":"2023-10-15T14:14:46.899837Z","shell.execute_reply.started":"2023-10-15T14:14:46.873931Z","shell.execute_reply":"2023-10-15T14:14:46.893296Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# # Test your create_train_val_dirs function\n\n# for rootdir, dirs, files in os.walk(root_dir):\n#     for subdir in dirs:\n#         print(os.path.join(rootdir, subdir))","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:46.901944Z","iopub.execute_input":"2023-10-15T14:14:46.902985Z","iopub.status.idle":"2023-10-15T14:14:46.919759Z","shell.execute_reply.started":"2023-10-15T14:14:46.902946Z","shell.execute_reply":"2023-10-15T14:14:46.918751Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# # GRADED FUNCTION: split_data\n# def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n#     \"\"\"\n#     Splits the data into train and test sets\n\n#     Args:\n#       SOURCE_DIR (string): directory path containing the images\n#       TRAINING_DIR (string): directory path to be used for training\n#       VALIDATION_DIR (string): directory path to be used for validation\n#       SPLIT_SIZE (float): proportion of the dataset to be used for training\n\n#     Returns:\n#       None\n#     \"\"\"\n\n#     # START CODE HERE\n\n#     contents_source_dir = os.listdir(SOURCE_DIR)\n#     contents_source_dir = random.sample(contents_source_dir, len(contents_source_dir))\n\n#     training_number = int(len(contents_source_dir) * SPLIT_SIZE)\n#     target_dir = TRAINING_DIR\n\n#     for index in range(len(contents_source_dir)):\n#         if os.path.getsize(os.path.join(SOURCE_DIR, contents_source_dir[index])) == 0:\n#             print(f\"{contents_source_dir[index]} is zero length, so ignoring.\")\n#         else:\n#             copyfile(os.path.join(SOURCE_DIR, contents_source_dir[index]), os.path.join(target_dir, contents_source_dir[index]))\n\n#         if index == training_number:\n#             target_dir = VALIDATION_DIR\n\n#     # END CODE HERE\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:46.923340Z","iopub.execute_input":"2023-10-15T14:14:46.926228Z","iopub.status.idle":"2023-10-15T14:14:46.939027Z","shell.execute_reply.started":"2023-10-15T14:14:46.925083Z","shell.execute_reply":"2023-10-15T14:14:46.937003Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# # Empty directories in case you run this cell multiple times\n# if len(os.listdir(training_Healthy_dir)) > 0:\n#     for file in os.scandir(training_Healthy_dir):\n#         os.remove(file.path)\n\n# if len(os.listdir(training_Mild_DR_dir)) > 0:\n#     for file in os.scandir(training_Mild_DR_dir):\n#         os.remove(file.path)\n\n# if len(os.listdir(training_Moderate_DR_dir)) > 0:\n#     for file in os.scandir(training_Moderate_DR_dir):\n#         os.remove(file.path)\n\n# if len(os.listdir(training_Proliferate_DR_dir)) > 0:\n#     for file in os.scandir(training_Proliferate_DR_dir):\n#         os.remove(file.path)\n\n# if len(os.listdir(training_Severe_DR_dir)) > 0:\n#     for file in os.scandir(training_Severe_DR_dir):\n#         os.remove(file.path)\n\n\n\n\n# if len(os.listdir(testing_Healthy_dir)) > 0:\n#     for file in os.scandir(testing_Healthy_dir):\n#         os.remove(file.path)\n\n# if len(os.listdir(testing_Mild_DR_dir)) > 0:\n#     for file in os.scandir(testing_Mild_DR_dir):\n#         os.remove(file.path)\n\n# if len(os.listdir(testing_Moderate_DR_dir)) > 0:\n#     for file in os.scandir(testing_Moderate_DR_dir):\n#         os.remove(file.path)\n\n# if len(os.listdir(testing_Proliferate_DR_dir)) > 0:\n#     for file in os.scandir(testing_Proliferate_DR_dir):\n#         os.remove(file.path)\n\n# if len(os.listdir(testing_Severe_DR_dir)) > 0:\n#     for file in os.scandir(testing_Severe_DR_dir):\n#         os.remove(file.path)\n\n\n\n\n\n# # Define proportion of images used for training\n# split_size = .8\n\n# # Run the function\n# # NOTE: Messages about zero length images should be printed out\n# split_data(source_path_Healthy, training_Healthy_dir, testing_Healthy_dir, split_size)\n# split_data(source_path_Mild_DR, training_Mild_DR_dir, testing_Mild_DR_dir, split_size)\n# split_data(source_path_Moderate_DR, training_Moderate_DR_dir, testing_Moderate_DR_dir, split_size)\n# split_data(source_path_Proliferate_DR, training_Proliferate_DR_dir, testing_Proliferate_DR_dir, split_size)\n# split_data(source_path_Severe_DR, training_Severe_DR_dir, testing_Severe_DR_dir, split_size)\n\n# # Check that the number of images matches the expected output\n\n# # Your function should perform copies rather than moving images so original directories should contain unchanged images\n# print(f\"\\n\\nOriginal Healthy directory has {len(os.listdir(source_path_Healthy))} images\")\n# print(f\"Original Mild DR directory has {len(os.listdir(source_path_Mild_DR))} images\")\n# print(f\"Original Moderate DR directory has {len(os.listdir(source_path_Moderate_DR))} images\")\n# print(f\"Original Proliferate DR directory has {len(os.listdir(source_path_Proliferate_DR))} images\")\n# print(f\"Original Severe DR directory has {len(os.listdir(source_path_Severe_DR))} images\\n\")\n\n# # Training and validation splits\n# print(f\"There are {len(os.listdir(training_Healthy_dir))} images of Healthy for training\")\n# print(f\"There are {len(os.listdir(training_Mild_DR_dir))} images of Mild DR for training\")\n# print(f\"There are {len(os.listdir(training_Moderate_DR_dir))} images of Moderate DR for training\")\n# print(f\"There are {len(os.listdir(training_Proliferate_DR_dir))} images of Proliferate DR for training\")\n# print(f\"There are {len(os.listdir(training_Severe_DR_dir))} images of Severe for training\\n\\n\")\n\n# print(f\"There are {len(os.listdir(testing_Healthy_dir))} images of Healthy for Validation\")\n# print(f\"There are {len(os.listdir(testing_Mild_DR_dir))} images of Mild DR for Validation\")\n# print(f\"There are {len(os.listdir(testing_Moderate_DR_dir))} images of Moderate DR for Validation\")\n# print(f\"There are {len(os.listdir(testing_Proliferate_DR_dir))} images of Proliferate DR for Validation\")\n# print(f\"There are {len(os.listdir(testing_Severe_DR_dir))} images of Severe for Validation\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:46.940437Z","iopub.execute_input":"2023-10-15T14:14:46.941043Z","iopub.status.idle":"2023-10-15T14:14:46.955828Z","shell.execute_reply.started":"2023-10-15T14:14:46.941002Z","shell.execute_reply":"2023-10-15T14:14:46.954954Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"##### Splitting process ends here.....................","metadata":{}},{"cell_type":"code","source":"# Setup train and testing paths\ntrain_dir = image_path / \"train\"\ntest_dir = image_path / \"test\"\n\ntrain_dir, test_dir","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:46.958927Z","iopub.execute_input":"2023-10-15T14:14:46.959832Z","iopub.status.idle":"2023-10-15T14:14:46.977033Z","shell.execute_reply.started":"2023-10-15T14:14:46.959800Z","shell.execute_reply":"2023-10-15T14:14:46.975953Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(PosixPath('/kaggle/input/ham10000-splitted/Images splitted/Splitted/train'),\n PosixPath('/kaggle/input/ham10000-splitted/Images splitted/Splitted/test'))"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Datasets and DataLoaders**\n\nLet's turn our data into PyTorch `Dataset`'s and `DataLoader`'s and find out a few useful attributes from them such as `classes` and their lengths. ","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torchvision.transforms.functional import InterpolationMode\n\n# Create image size (from Table 3 in the ViT paper) \n# IMG_SIZE = 224\n# IMG_SIZE = 64\nIMG_SIZE = 56\n\n# Create transform pipeline manually   \ndata_transform = transforms.Compose([\n#     transforms.CenterCrop(200),\n#     transforms.RandAugment(num_ops = 8, \n#                            magnitude = 9, \n#                            num_magnitude_bins = 31, \n#                            interpolation = InterpolationMode.BILINEAR, \n#                            ),\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.RandomRotation((-120,120)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n#     transforms.RandomAffine(degrees=360, scale=(1.0, 1.3)),\n#     transforms.RandomAdjustSharpness(sharpness_factor=0),\n#     transforms.RandomAdjustSharpness(sharpness_factor=2),\n    transforms.RandomPerspective(distortion_scale=0.2),\n    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    \n    # Calculated for train data\n    transforms.Normalize([0.5018, 0.5015, 0.5013], [0.1029, 0.0985, 0.0807]),\n])     \n\nprint(f\"Manually created transforms: {data_transform}\")\n\n\n\n\n\ndata_transform_test = transforms.Compose([\n#     transforms.CenterCrop(200),\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    # Kaggle winner : https://www.kaggle.com/competitions/aptos2019-blindness-detection/discussion/107954\n    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n\n    # Calculated for test data\n    transforms.Normalize([0.5018, 0.5015, 0.5013], [0.1029, 0.0985, 0.0807]),\n])  \n\n\n# Use ImageFolder to create dataset(s)\ntrain_data = datasets.ImageFolder(root=train_dir, # target folder of images\n                                  transform=data_transform, # transforms to perform on data (images)\n                                  target_transform=None) # transforms to perform on labels (if necessary)\n\n\ntest_data = datasets.ImageFolder(root=test_dir,\n                                 transform=data_transform_test,\n                                )\n\nprint(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:46.979936Z","iopub.execute_input":"2023-10-15T14:14:46.980715Z","iopub.status.idle":"2023-10-15T14:14:54.719168Z","shell.execute_reply.started":"2023-10-15T14:14:46.980682Z","shell.execute_reply":"2023-10-15T14:14:54.718113Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Manually created transforms: Compose(\n    Resize(size=(56, 56), interpolation=bilinear, max_size=None, antialias=warn)\n    ToTensor()\n    RandomRotation(degrees=[-120.0, 120.0], interpolation=nearest, expand=False, fill=0)\n    RandomHorizontalFlip(p=0.5)\n    RandomVerticalFlip(p=0.5)\n    RandomPerspective(p=0.5)\n    Normalize(mean=[0.5018, 0.5015, 0.5013], std=[0.1029, 0.0985, 0.0807])\n)\nTrain data:\nDataset ImageFolder\n    Number of datapoints: 8017\n    Root location: /kaggle/input/ham10000-splitted/Images splitted/Splitted/train\n    StandardTransform\nTransform: Compose(\n               Resize(size=(56, 56), interpolation=bilinear, max_size=None, antialias=warn)\n               ToTensor()\n               RandomRotation(degrees=[-120.0, 120.0], interpolation=nearest, expand=False, fill=0)\n               RandomHorizontalFlip(p=0.5)\n               RandomVerticalFlip(p=0.5)\n               RandomPerspective(p=0.5)\n               Normalize(mean=[0.5018, 0.5015, 0.5013], std=[0.1029, 0.0985, 0.0807])\n           )\nTest data:\nDataset ImageFolder\n    Number of datapoints: 1998\n    Root location: /kaggle/input/ham10000-splitted/Images splitted/Splitted/test\n    StandardTransform\nTransform: Compose(\n               Resize(size=(56, 56), interpolation=bilinear, max_size=None, antialias=warn)\n               ToTensor()\n               Normalize(mean=[0.5018, 0.5015, 0.5013], std=[0.1029, 0.0985, 0.0807])\n           )\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Auto Transform**","metadata":{}},{"cell_type":"code","source":"# import torchvision\n\n# # Get a set of pretrained model weights\n# weights = torchvision.models.EfficientNet_B5_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n# # Get the transforms used to create our pretrained weights\n# auto_transforms = weights.transforms()\n\n\n# from torchvision import datasets, transforms\n\n# # Use ImageFolder to create dataset(s)\n# train_data2 = datasets.ImageFolder(root=train_dir, # target folder of images\n#                                   transform=auto_transforms, # transforms to perform on data (images)\n#                                   target_transform=None) # transforms to perform on labels (if necessary)\n\n# test_data2 = datasets.ImageFolder(root=test_dir, \n#                                  transform=auto_transforms)\n\n# print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:54.720927Z","iopub.execute_input":"2023-10-15T14:14:54.721668Z","iopub.status.idle":"2023-10-15T14:14:54.727055Z","shell.execute_reply.started":"2023-10-15T14:14:54.721633Z","shell.execute_reply":"2023-10-15T14:14:54.725957Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Get class names as a list\nclass_names = train_data.classes\nclass_names","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:54.728664Z","iopub.execute_input":"2023-10-15T14:14:54.728976Z","iopub.status.idle":"2023-10-15T14:14:54.743667Z","shell.execute_reply.started":"2023-10-15T14:14:54.728948Z","shell.execute_reply":"2023-10-15T14:14:54.742748Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"},"metadata":{}}]},{"cell_type":"code","source":"# Can also get class names as a dict\nclass_dict = train_data.class_to_idx\nclass_dict","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:54.745243Z","iopub.execute_input":"2023-10-15T14:14:54.745626Z","iopub.status.idle":"2023-10-15T14:14:54.754556Z","shell.execute_reply.started":"2023-10-15T14:14:54.745598Z","shell.execute_reply":"2023-10-15T14:14:54.753576Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}"},"metadata":{}}]},{"cell_type":"code","source":"weights = []\n\nfor (X,y) in train_data:\n    if y == 0:\n        weights.append(1.0/262)\n\n    if y == 1:\n        weights.append(1.0/412)\n        \n    if y == 2:\n        weights.append(1.0/880)\n        \n    if y == 3:\n        weights.append(1.0/93)\n        \n    if y == 4:\n        weights.append(1.0/891)\n        \n    if y == 5:\n        weights.append(1.0/5365)\n        \n    if y == 6:\n        weights.append(1.0/114)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:14:54.755879Z","iopub.execute_input":"2023-10-15T14:14:54.756482Z","iopub.status.idle":"2023-10-15T14:17:32.860899Z","shell.execute_reply.started":"2023-10-15T14:14:54.756453Z","shell.execute_reply":"2023-10-15T14:17:32.859866Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Check the lengths\nlen(train_data), len(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:32.867948Z","iopub.execute_input":"2023-10-15T14:17:32.868266Z","iopub.status.idle":"2023-10-15T14:17:32.874229Z","shell.execute_reply.started":"2023-10-15T14:17:32.868240Z","shell.execute_reply":"2023-10-15T14:17:32.873322Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(8017, 1998)"},"metadata":{}}]},{"cell_type":"code","source":"# ## testing optimal num_worker value\n\n# from time import time\n# import multiprocessing as mp\n# from torch.utils.data import DataLoader\n\n# for num_workers in range(1, 14, 1):  \n#     train_loader = DataLoader(test_data,shuffle=True,num_workers=num_workers,batch_size=128,pin_memory=True)\n#     start = time()\n#     for epoch in range(1):\n#         for i, data in enumerate(train_loader, 0):\n#             pass\n#     end = time()\n#     print(\"Finish with:{} second, num_workers={}\".format(end - start, num_workers))","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:32.875761Z","iopub.execute_input":"2023-10-15T14:17:32.876307Z","iopub.status.idle":"2023-10-15T14:17:32.886881Z","shell.execute_reply.started":"2023-10-15T14:17:32.876277Z","shell.execute_reply":"2023-10-15T14:17:32.886104Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Turn train and test Datasets into DataLoaders\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\n# from torchsampler import ImbalancedDatasetSampler\n\nBATCH_SIZE = 256\n\nsampler = WeightedRandomSampler(weights, \n                                num_samples=8017,\n                                replacement=True)\n\n\n\ntrain_dataloader = DataLoader(dataset=train_data, \n                              batch_size=BATCH_SIZE, # how many samples per batch?\n                              num_workers=4, # how many subprocesses to use for data loading? (higher = more)\n                              shuffle=True,\n                              pin_memory=True,\n#                               sampler=sampler, \n                              ) # shuffle the data?\n\n\n\ntest_dataloader = DataLoader(dataset=test_data, \n                             batch_size=BATCH_SIZE, \n                             num_workers=4, \n                             shuffle=False,\n                             pin_memory=True,\n                             ) # don't usually need to shuffle testing data\n\n\nlen(train_dataloader), len(test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:32.888388Z","iopub.execute_input":"2023-10-15T14:17:32.889023Z","iopub.status.idle":"2023-10-15T14:17:32.914821Z","shell.execute_reply.started":"2023-10-15T14:17:32.888993Z","shell.execute_reply":"2023-10-15T14:17:32.913718Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(32, 8)"},"metadata":{}}]},{"cell_type":"code","source":"# train_dataloader2 = DataLoader(dataset=train_data2, \n#                               batch_size=BATCH_SIZE, # how many samples per batch?\n#                               num_workers=2, # how many subprocesses to use for data loading? (higher = more)\n#                               shuffle=True,\n#                               pin_memory=True,\n# #                               sampler=sampler, \n#                               # sampler=ImbalancedDatasetSampler(train_data)\n#                               ) # shuffle the data?\n\n# test_dataloader2 = DataLoader(dataset=test_data2, \n#                              batch_size=BATCH_SIZE, \n#                              num_workers=2, \n#                              shuffle=False,\n#                              pin_memory=True,\n#                              ) # don't usually need to shuffle testing data\n\n\n# len(train_dataloader2), len(test_dataloader2)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:32.916293Z","iopub.execute_input":"2023-10-15T14:17:32.916916Z","iopub.status.idle":"2023-10-15T14:17:32.922152Z","shell.execute_reply.started":"2023-10-15T14:17:32.916876Z","shell.execute_reply":"2023-10-15T14:17:32.920769Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# # python code to calculate mean and std \n\n# import torch\n# from torch.utils.data import DataLoader\n\n# batch_size = 64\n\n\n# def batch_mean_and_sd(test_dataloader):\n    \n#     cnt = 0\n#     fst_moment = torch.empty(3)\n#     snd_moment = torch.empty(3)\n\n#     for images, _ in test_dataloader:\n#         b, c, h, w = images.shape\n#         nb_pixels = b * h * w\n#         sum_ = torch.sum(images, dim=[0, 2, 3])\n#         sum_of_square = torch.sum(images ** 2,\n#                                   dim=[0, 2, 3])\n#         fst_moment = (cnt * fst_moment + sum_) / (\n#                       cnt + nb_pixels)\n#         snd_moment = (cnt * snd_moment + sum_of_square) / (\n#                             cnt + nb_pixels)\n#         cnt += nb_pixels\n\n#     mean, std = fst_moment, torch.sqrt(\n#       snd_moment - fst_moment ** 2)        \n#     return mean,std\n  \n    \n    \n# mean, std = batch_mean_and_sd(train_dataloader)\n# print(\"mean and std: \\n\", mean, std)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:32.923828Z","iopub.execute_input":"2023-10-15T14:17:32.924710Z","iopub.status.idle":"2023-10-15T14:17:32.938209Z","shell.execute_reply.started":"2023-10-15T14:17:32.924658Z","shell.execute_reply":"2023-10-15T14:17:32.937199Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# # Check out single image size/shape\n# img, label = next(iter(train_dataloader2))\n\n# # Batch size will now be 1, try changing the batch_size parameter above and see what happens\n# print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n# print(f\"Label shape: {label.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:32.939411Z","iopub.execute_input":"2023-10-15T14:17:32.940293Z","iopub.status.idle":"2023-10-15T14:17:32.950311Z","shell.execute_reply.started":"2023-10-15T14:17:32.940246Z","shell.execute_reply":"2023-10-15T14:17:32.949523Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# **Experimentations**","metadata":{}},{"cell_type":"code","source":"# ## Monitoring labels in batches\n# total = [0,0,0,0,0]\n# for batch, (X, y) in enumerate(train_dataloader):\n#     print(f\"{batch}th batch\")\n#     Y = y.tolist()\n#     print(f\"0 : {Y.count(0)}\\n1 : {Y.count(1)}\\n2 : {Y.count(2)}\\n3 : {Y.count(3)}\\n4 : {Y.count(4)}\")\n#     total[0] += Y.count(0)\n#     total[1] += Y.count(1)\n#     total[2] += Y.count(2)\n#     total[3] += Y.count(3)\n#     total[4] += Y.count(4)\n# total","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-10-15T14:17:32.951177Z","iopub.execute_input":"2023-10-15T14:17:32.951898Z","iopub.status.idle":"2023-10-15T14:17:32.968193Z","shell.execute_reply.started":"2023-10-15T14:17:32.951866Z","shell.execute_reply":"2023-10-15T14:17:32.967138Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# a = torch.randn(4, 4)\n# a\n# # tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n# #         [-0.7401, -0.8805, -0.3402, -1.1936],\n# #         [ 0.4907, -1.3948, -1.0691, -0.3132],\n# #         [-1.6092,  0.5419, -0.2993,  0.3195]])\n# # >>> torch.argmax(a)\n# # tensor(0)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:32.969734Z","iopub.execute_input":"2023-10-15T14:17:32.970029Z","iopub.status.idle":"2023-10-15T14:17:32.980544Z","shell.execute_reply.started":"2023-10-15T14:17:32.970001Z","shell.execute_reply":"2023-10-15T14:17:32.979755Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# torch.argmax(a, dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:32.981710Z","iopub.execute_input":"2023-10-15T14:17:32.982506Z","iopub.status.idle":"2023-10-15T14:17:32.993190Z","shell.execute_reply.started":"2023-10-15T14:17:32.982477Z","shell.execute_reply":"2023-10-15T14:17:32.992269Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# y_predicted = []\n# Y = []\n# for batch, (X, y) in enumerate(train_dataloader):\n#     # print(y, end=\"\\n\\n\")\n#     X = X.to(device)\n#     y_pred = model(X)\n#     y_predicted = y_pred\n#     Y = y \n#     # print(y_pred)\n#     break\n# print(y_predicted,end=\"/n\")\n# print(Y)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:32.994382Z","iopub.execute_input":"2023-10-15T14:17:32.995254Z","iopub.status.idle":"2023-10-15T14:17:33.003420Z","shell.execute_reply.started":"2023-10-15T14:17:32.995187Z","shell.execute_reply":"2023-10-15T14:17:33.002565Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# logits = torch.softmax(y_predicted, dim=1)\n# logits","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:33.004801Z","iopub.execute_input":"2023-10-15T14:17:33.005349Z","iopub.status.idle":"2023-10-15T14:17:33.014376Z","shell.execute_reply.started":"2023-10-15T14:17:33.005314Z","shell.execute_reply":"2023-10-15T14:17:33.013503Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# logits + logits","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:33.015708Z","iopub.execute_input":"2023-10-15T14:17:33.016018Z","iopub.status.idle":"2023-10-15T14:17:33.027242Z","shell.execute_reply.started":"2023-10-15T14:17:33.015989Z","shell.execute_reply":"2023-10-15T14:17:33.026278Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# y_pred_class = torch.argmax(torch.softmax(y_predicted, dim=1), dim=1)\n# print(y_pred_class)\n\n# Y = Y.to(device)\n# y_pred_class = y_pred_class.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:33.028574Z","iopub.execute_input":"2023-10-15T14:17:33.028924Z","iopub.status.idle":"2023-10-15T14:17:33.039684Z","shell.execute_reply.started":"2023-10-15T14:17:33.028895Z","shell.execute_reply":"2023-10-15T14:17:33.038894Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# (y_pred_class == Y).sum().item()/len(y_pred_class)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:33.041150Z","iopub.execute_input":"2023-10-15T14:17:33.041505Z","iopub.status.idle":"2023-10-15T14:17:33.052677Z","shell.execute_reply.started":"2023-10-15T14:17:33.041477Z","shell.execute_reply":"2023-10-15T14:17:33.051830Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n\n# # # fig = plt.figure(figsize=(224,224))\n# # # rows = 16\n# # # cols = 4\n\n# for batch, (X, y) in enumerate(train_dataloader):\n#     print(X[0].shape)\n#     plt.imshow(X[0].permute(1,2,0))\n#     plt.axis('off')\n#     plt.title(y[0])\n#     plt.show()\n\n# # train_dataloaders = [train_dataloader, train_dataloader_aug, train_dataloader_aug2, train_dataloader_aug3,train_dataloader_aug4, train_dataloader_aug5,train_dataloader_aug6,train_dataloader_aug7]\n# # train_dataloader_itrs = []\n\n# # for i in range(len(train_dataloaders)):\n# #     torch.manual_seed(42)\n# #     train_dataloader_itrs.append(iter(train_dataloaders[i]))\n\n\n# # test_dataloaders = [test_dataloader, test_dataloader_TTA, test_dataloader_TTA2,test_dataloader_TTA3,test_dataloader_TTA4,test_dataloader_TTA5,test_dataloader_TTA6,test_dataloader_TTA7]\n# # test_dataloader_itrs = []\n\n# # for i in range(len(test_dataloaders)):\n# #     torch.manual_seed(42)\n# #     test_dataloader_itrs.append(iter(test_dataloaders[i]))\n\n\n\n# # count = 0\n# # torch.manual_seed(42)\n# # for batch, (img, label) in enumerate(test_dataloader):\n# #     count += 1\n\n# #     for i in range(len(train_dataloader_itrs)):\n# #         torch.manual_seed(42)\n# #         X, y = next(train_dataloader_itrs[i])\n# #         print(f\"\\n\\n\\n\\nTrain_img{i}\")\n# #         plt.imshow(X[0].permute(1,2,0))\n# #         plt.axis('off')\n# #         plt.title(y[0])\n# #         plt.show()\n\n# #     for i in range(len(test_dataloader_itrs)):\n# #         torch.manual_seed(42)\n# #         X, y = next(test_dataloader_itrs[i])\n# #         print(f\"\\n\\n\\n\\nTest_img{i}\")\n# #         plt.imshow(X[0].permute(1,2,0))\n# #         plt.axis('off')\n# #         plt.title(y[0])\n# #         plt.show()\n\n# #     # torch.manual_seed(42)\n# #     # X, y = next(dataloader_itr_train)\n# # #     torch.manual_seed(42)\n# # #     img_TTA, label_TTA = next(dataloader_itr)\n# # #     torch.manual_seed(42)\n# # #     img_TTA2, label_TTA2 = next(dataloader_itr2)\n# # #     torch.manual_seed(42)\n# # #     img_TTA3, label_TTA3 = next(dataloader_itr3)\n# # #     torch.manual_seed(42)\n# # #     img_TTA4, label_TTA4 = next(dataloader_itr4)\n    \n\n# # #     for i in range(32):\n# # #         # fig.add_subplot(rows,cols,i+1)\n# # #         # print(img[0])\n\n# # #         print(\"Train img\")\n# # #         plt.imshow(X[i].permute(1,2,0))\n# # #         plt.axis('off')\n# # #         plt.title(y[i])\n# # #         plt.show()\n\n# # #         print(\"Test - no augmentations\")\n# # #         plt.imshow(img[i].permute(1,2,0))\n# # #         plt.axis('off')\n# # #         plt.title(label[i])\n# # #         plt.show()\n\n# # #         print(\"TTA - RandomAffine(360)\")\n# # #         plt.imshow(img_TTA[i].permute(1,2,0))\n# # #         plt.axis('off')\n# # #         plt.title(label_TTA[i])\n# # #         plt.show()\n\n# # #         print(\"TTA2 - RandomRotation(180)\")\n# # #         plt.imshow(img_TTA2[i].permute(1,2,0))\n# # #         plt.axis('off')\n# # #         plt.title(label_TTA2[i])\n# # #         plt.show()\n\n# # #         print(\"TTA3 - RandomHorizontalFlip(1)\")\n# # #         plt.imshow(img_TTA3[i].permute(1,2,0))\n# # #         plt.axis('off')\n# # #         plt.title(label_TTA3[i])\n# # #         plt.show()\n\n# # #         print(\"TTA4 - RandomVerticalFlip(1)\")\n# # #         plt.imshow(img_TTA4[i].permute(1,2,0))\n# # #         plt.axis('off')\n# # #         plt.title(label_TTA4[i])\n# # #         plt.show()\n\n# # #         # print(f\"Label: {label}\")\n# #     if count >= 1:\n# #         break","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:33.054830Z","iopub.execute_input":"2023-10-15T14:17:33.055476Z","iopub.status.idle":"2023-10-15T14:17:33.065981Z","shell.execute_reply.started":"2023-10-15T14:17:33.055445Z","shell.execute_reply":"2023-10-15T14:17:33.065075Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"# **Pyramid-ViG Building Blocks**","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Sequential as Seq\n\n# from gcn_lib import Grapher, act_layer\n\n# for Kaggle import\nimport sys\nsys.path.append(\"/kaggle/input/vig-pytorch/\")\nfrom gcn_lib import Grapher, act_layer\n\n\nfrom timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\nfrom timm.models.helpers import load_pretrained\nfrom timm.models.layers import DropPath, to_2tuple, trunc_normal_\nfrom timm.models.registry import register_model\n\n\n\n# class Stem(nn.Module):\n#     \"\"\" Image to Visual Embedding\n#     Overlap: https://arxiv.org/pdf/2106.13797.pdf\n#     \"\"\"\n#     def __init__(self, img_size=224, in_dim=3, out_dim=768, act='relu'):\n#         super().__init__()        \n#         self.convs = nn.Sequential(\n#             nn.Conv2d(in_dim, out_dim//2, 3, stride=2, padding=1),\n#             nn.BatchNorm2d(out_dim//2),\n#             act_layer(act),\n#             nn.Conv2d(out_dim//2, out_dim, 3, stride=2, padding=1),\n#             nn.BatchNorm2d(out_dim),\n#             act_layer(act),\n#             nn.Conv2d(out_dim, out_dim, 3, stride=1, padding=1),\n#             nn.BatchNorm2d(out_dim),\n#         )\n\n#     def forward(self, x):\n#         x = self.convs(x)\n#         return x\n    \nclass Stem(nn.Module):\n    \"\"\" Image to Visual Embedding\n    Overlap: https://arxiv.org/pdf/2106.13797.pdf\n    \"\"\"\n    def __init__(self, img_size=56, in_dim=3, out_dim=768, act='relu'):\n        super().__init__()        \n        self.convs = nn.Sequential(\n            nn.Conv2d(in_dim, out_dim, 3, stride=1, padding=1),\n            nn.BatchNorm2d(out_dim),\n            act_layer(act),\n            nn.Conv2d(out_dim, out_dim, 3, stride=1, padding=1),\n            nn.BatchNorm2d(out_dim),\n            act_layer(act),\n            nn.Conv2d(out_dim, out_dim, 3, stride=1, padding=1),\n            nn.BatchNorm2d(out_dim),\n        )\n\n    def forward(self, x):\n        x = self.convs(x)\n        return x\n    \n    \nclass Downsample(nn.Module):\n    \"\"\" Convolution-based downsample\n    \"\"\"\n    def __init__(self, in_dim=3, out_dim=768):\n        super().__init__()        \n        self.conv = nn.Sequential(\n            nn.Conv2d(in_dim, out_dim, 3, stride=2, padding=1),\n            nn.BatchNorm2d(out_dim),\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n    \n    \n    \n\nclass FFN(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None, act='relu', drop_path=0.0):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = nn.Sequential(\n            nn.Conv2d(in_features, hidden_features, 1, stride=1, padding=0),\n            nn.BatchNorm2d(hidden_features),\n        )\n        self.act = act_layer(act)\n        self.fc2 = nn.Sequential(\n            nn.Conv2d(hidden_features, out_features, 1, stride=1, padding=0),\n            nn.BatchNorm2d(out_features),\n        )\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n\n    def forward(self, x):\n        shortcut = x\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.fc2(x)\n        x = self.drop_path(x) + shortcut\n        return x#.reshape(B, C, N, 1)\n    \n    \n    \n\nclass DeepGCN(torch.nn.Module):\n    def __init__(self, opt):\n        super(DeepGCN, self).__init__()\n        print(opt)\n        k = opt.k\n        act = opt.act\n        norm = opt.norm\n        bias = opt.bias\n        epsilon = opt.epsilon\n        stochastic = opt.use_stochastic\n        conv = opt.conv\n        emb_dims = opt.emb_dims\n        drop_path = opt.drop_path\n        \n        blocks = opt.blocks\n        self.n_blocks = sum(blocks)\n        channels = opt.channels\n        reduce_ratios = [4, 2, 1, 1]\n        dpr = [x.item() for x in torch.linspace(0, drop_path, self.n_blocks)]  # stochastic depth decay rule \n        num_knn = [int(x.item()) for x in torch.linspace(k, k, self.n_blocks)]  # number of knn's k\n        max_dilation = 49 // max(num_knn)\n        \n        self.stem = Stem(out_dim=channels[0], act=act)\n        self.pos_embed = nn.Parameter(torch.zeros(1, channels[0], 224//4, 224//4))\n        HW = 224 // 4 * 224 // 4\n\n        self.backbone = nn.ModuleList([])\n        idx = 0\n        for i in range(len(blocks)):\n            if i > 0:\n                self.backbone.append(Downsample(channels[i-1], channels[i]))\n                HW = HW // 4\n            for j in range(blocks[i]):\n                self.backbone += [\n                    Seq(Grapher(channels[i], num_knn[idx], min(idx // 4 + 1, max_dilation), conv, act, norm,\n                                    bias, stochastic, epsilon, reduce_ratios[i], n=HW, drop_path=dpr[idx],\n                                    relative_pos=True),\n                          FFN(channels[i], channels[i] * 4, act=act, drop_path=dpr[idx])\n                         )]\n                idx += 1\n        self.backbone = Seq(*self.backbone)\n\n        self.prediction = Seq(nn.Conv2d(channels[-1], 1024, 1, bias=True),\n                              nn.BatchNorm2d(1024),\n                              act_layer(act),\n                              nn.Dropout(opt.dropout),\n                              nn.Conv2d(1024, opt.n_classes, 1, bias=True))\n        self.model_init()\n\n    def model_init(self):\n        for m in self.modules():\n            if isinstance(m, torch.nn.Conv2d):\n                torch.nn.init.kaiming_normal_(m.weight)\n                m.weight.requires_grad = True\n                if m.bias is not None:\n                    m.bias.data.zero_()\n                    m.bias.requires_grad = True\n\n    def forward(self, inputs):\n        x = self.stem(inputs) + self.pos_embed\n        B, C, H, W = x.shape\n        for i in range(len(self.backbone)):\n            x = self.backbone[i](x)\n\n        x = F.adaptive_avg_pool2d(x, 1)\n        return self.prediction(x).squeeze(-1).squeeze(-1)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:33.067448Z","iopub.execute_input":"2023-10-15T14:17:33.068137Z","iopub.status.idle":"2023-10-15T14:17:34.921565Z","shell.execute_reply.started":"2023-10-15T14:17:33.068083Z","shell.execute_reply":"2023-10-15T14:17:34.920635Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from going_modular.helper_functions import download_data, set_seeds, plot_loss_curves\n\nset_seeds()\n\n# # Create an instance of patch embedding layer\n# patchify = Stem(img_size=224, in_dim=3, out_dim=768, act='relu')\n\n# # Pass a single image through\n# print(f\"Input image shape: {image.unsqueeze(0).shape}\")\n# patch_embedded_image = patchify(image.unsqueeze(0)) # add an extra batch dimension on the 0th index, otherwise will error\n# print(f\"Output patch embedding shape: {patch_embedded_image.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:34.924666Z","iopub.execute_input":"2023-10-15T14:17:34.925407Z","iopub.status.idle":"2023-10-15T14:17:34.956987Z","shell.execute_reply.started":"2023-10-15T14:17:34.925384Z","shell.execute_reply":"2023-10-15T14:17:34.956133Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 7, 'input_size': (3, 56, 56), 'pool_size': None,\n        'crop_pct': .9, 'interpolation': 'bicubic',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n        **kwargs\n    }\n\n\ndefault_cfgs = {\n    'vig_224_gelu': _cfg(\n        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n    ),\n    'vig_b_224_gelu': _cfg(\n        crop_pct=0.95, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n    ),\n}\n\n\ndef pvig_ti_224_gelu(pretrained=False, **kwargs):\n    class OptInit:\n        def __init__(self, num_classes=7, drop_path_rate=0.0, **kwargs):\n            self.k = 9 # neighbor num (default:9)\n            self.conv = 'mr' # graph conv layer {edge, mr}\n            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n            self.norm = 'batch' # batch or instance normalization {batch, instance}\n            self.bias = True # bias of conv layer True or False\n            self.dropout = 0.001 # dropout rate\n            self.use_dilation = False # use dilated knn or not\n            self.epsilon = 0.2 # stochastic epsilon for gcn\n            self.use_stochastic = False # stochastic for gcn, True or False\n            self.drop_path = drop_path_rate\n            self.blocks = [2,2,6,2] # number of basic blocks in the backbone\n            self.channels = [48, 96, 240, 384] # number of channels of deep features\n            self.n_classes = num_classes # Dimension of out_channels\n            self.emb_dims = 1024 # Dimension of embeddings\n\n    opt = OptInit(**kwargs)\n    model = DeepGCN(opt)\n    model.default_cfg = default_cfgs['vig_224_gelu']\n    return model\n\n\n\ndef pvig_b_224_gelu(pretrained=False, **kwargs):\n    class OptInit:\n        def __init__(self, num_classes=7, drop_path_rate=0.0, **kwargs):\n            self.k = 9 # neighbor num (default:9)\n            self.conv = 'mr' # graph conv layer {edge, mr}\n            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n            self.norm = 'batch' # batch or instance normalization {batch, instance}\n            self.bias = False # bias of conv layer True or False\n            self.dropout = 0.0 # dropout rate\n            self.use_dilation = False # use dilated knn or not\n            self.epsilon = 0.2 # stochastic epsilon for gcn\n            self.use_stochastic = False # stochastic for gcn, True or False\n            self.drop_path = drop_path_rate\n            self.blocks = [2,2,18,2] # number of basic blocks in the backbone\n            self.channels = [128, 256, 512, 1024] # number of channels of deep features\n            self.n_classes = num_classes # Dimension of out_channels\n            self.emb_dims = 1024 # Dimension of embeddings\n\n    opt = OptInit(**kwargs)\n    model = DeepGCN(opt)\n    model.default_cfg = default_cfgs['vig_b_224_gelu']\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:34.958440Z","iopub.execute_input":"2023-10-15T14:17:34.958982Z","iopub.status.idle":"2023-10-15T14:17:34.970967Z","shell.execute_reply.started":"2023-10-15T14:17:34.958950Z","shell.execute_reply":"2023-10-15T14:17:34.970052Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model = pvig_ti_224_gelu().to(device)\n# model = pvig_b_224_gelu().to(device)\n# model\n\n# model.load_state_dict(torch.load(\"/kaggle/input/trained-models-testing-ensemble/0.8118131868131868 acc.pth\"))\n\n# model2 = torchvision.models.efficientnet_b5().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:34.972482Z","iopub.execute_input":"2023-10-15T14:17:34.972889Z","iopub.status.idle":"2023-10-15T14:17:40.610357Z","shell.execute_reply.started":"2023-10-15T14:17:34.972858Z","shell.execute_reply":"2023-10-15T14:17:40.609397Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"<__main__.pvig_ti_224_gelu.<locals>.OptInit object at 0x7f2a1cedf160>\nusing relative_pos\nusing relative_pos\nusing relative_pos\nusing relative_pos\nusing relative_pos\nusing relative_pos\nusing relative_pos\nusing relative_pos\nusing relative_pos\nusing relative_pos\nusing relative_pos\nusing relative_pos\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Set the manual seeds\n# torch.manual_seed(42)\n# torch.cuda.manual_seed(42)\n\n# # Get the length of class_names (one output unit for each class)\n# output_shape = len(class_names)\n\n# # Recreate the classifier layer and seed it to the target device\n# model2.classifier = torch.nn.Sequential(\n#     torch.nn.Dropout(p=0, inplace=True), \n#     torch.nn.Linear(in_features=2048, \n#                     out_features=output_shape, # same number of output units as our number of classes\n#                     bias=True)).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:40.611823Z","iopub.execute_input":"2023-10-15T14:17:40.612377Z","iopub.status.idle":"2023-10-15T14:17:40.617263Z","shell.execute_reply.started":"2023-10-15T14:17:40.612345Z","shell.execute_reply":"2023-10-15T14:17:40.616184Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# from torchinfo import summary\n\n# # Create an instance of TransformerEncoderBlock\n# model_summary = model2\n\n# # Print an input and output summary of our Transformer Encoder (uncomment for full output)\n# summary(model=model_summary,\n#         input_size=(64, 3, 224, 224), # (batch_size, num_patches, embedding_dimension)\n#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n#         col_width=20,\n#         row_settings=[\"var_names\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:40.618916Z","iopub.execute_input":"2023-10-15T14:17:40.619589Z","iopub.status.idle":"2023-10-15T14:17:40.635503Z","shell.execute_reply.started":"2023-10-15T14:17:40.619558Z","shell.execute_reply":"2023-10-15T14:17:40.634620Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# model2 = nn.DataParallel(model2)  ### for two GPU faster computations ","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:40.636917Z","iopub.execute_input":"2023-10-15T14:17:40.637255Z","iopub.status.idle":"2023-10-15T14:17:40.648935Z","shell.execute_reply.started":"2023-10-15T14:17:40.637225Z","shell.execute_reply":"2023-10-15T14:17:40.648067Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model = nn.DataParallel(model)  ### for two GPU faster computations ","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:40.650118Z","iopub.execute_input":"2023-10-15T14:17:40.650827Z","iopub.status.idle":"2023-10-15T14:17:40.662216Z","shell.execute_reply.started":"2023-10-15T14:17:40.650795Z","shell.execute_reply":"2023-10-15T14:17:40.661326Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# from torchinfo import summary\n\n# # Create an instance of TransformerEncoderBlock\n# model_summary = model\n\n# # Print an input and output summary of our Transformer Encoder (uncomment for full output)\n# summary(model=model_summary,\n#         input_size=(128, 3, 224, 224), # (batch_size, num_patches, embedding_dimension)\n#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n#         col_width=20,\n#         row_settings=[\"var_names\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:40.663606Z","iopub.execute_input":"2023-10-15T14:17:40.664253Z","iopub.status.idle":"2023-10-15T14:17:40.673787Z","shell.execute_reply.started":"2023-10-15T14:17:40.664222Z","shell.execute_reply":"2023-10-15T14:17:40.672909Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"import wandb\n\n# start a new wandb run to track this script\ntracking = wandb.init(\n    # set the wandb project where this run will be logged\n    project=\"Glaucoma Fundus Imaging\",\n    name=\"HAM10000: 56x56 images\",\n    notes=\"\",\n    # track hyperparameters and run metadata\n    config={\n        \"learning_rate\": 2e-3,\n        \"architecture\": \"ViG_ti_224_gelu\",\n        \"dataset\": \"Default\",\n        \"epochs\": 200,\n    }\n)\n\n# 4b7dfb240ea0d5aae1afac2de518c0e940547396","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:17:40.675001Z","iopub.execute_input":"2023-10-15T14:17:40.675886Z","iopub.status.idle":"2023-10-15T14:18:54.211478Z","shell.execute_reply.started":"2023-10-15T14:17:40.675855Z","shell.execute_reply":"2023-10-15T14:18:54.210556Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  \n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231015_141822-uziijjyk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging/runs/uziijjyk' target=\"_blank\">HAM10000: 56x56 images</a></strong> to <a href='https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging' target=\"_blank\">https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging/runs/uziijjyk' target=\"_blank\">https://wandb.ai/shkiam33/Glaucoma%20Fundus%20Imaging/runs/uziijjyk</a>"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"\"\"\"\nContains functions for training and testing a PyTorch model.\n\"\"\"\nfrom typing import Dict, List, Tuple\nfrom sklearn.metrics import classification_report\n\nimport torch\n\nfrom tqdm.auto import tqdm\nimport wandb\n\n\ndef train_step(model: torch.nn.Module, \n               dataloader: torch.utils.data.DataLoader, \n               loss_fn: torch.nn.Module, \n               optimizer: torch.optim.Optimizer,\n               device: torch.device,\n               len_train_data) -> Tuple[float, float]:\n    \"\"\"Trains a PyTorch model for a single epoch.\n\n    Turns a target PyTorch model to training mode and then\n    runs through all of the required training steps (forward\n    pass, loss calculation, optimizer step).\n\n    Args:\n    model: A PyTorch model to be trained.\n    dataloader: A DataLoader instance for the model to be trained on.\n    loss_fn: A PyTorch loss function to minimize.\n    optimizer: A PyTorch optimizer to help minimize the loss function.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A tuple of training loss and training accuracy metrics.\n    In the form (train_loss, train_accuracy). For example:\n\n    (0.1112, 0.8743)\n    \"\"\"\n    # Put model in train mode\n    model.train()\n\n    # Setup train loss and train accuracy values\n    train_loss = 0.0 \n    train_acc = 0.0\n\n    # for evaluation\n    y_true_train_data = []\n    y_predicted_train_data = []\n\n    # Loop through data loader data batches\n    for batch, (X, y) in enumerate(dataloader):\n        # Send data to target device\n        X, y = X.to(device), y.to(device)\n\n\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. Calculate  and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item() \n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n        # Calculate and accumulate accuracy metric across all batches\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        # train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n        train_acc += (y_pred_class == y).sum().item()\n        \n        # for evaluaiton\n        y_true_train_data.append(y)\n        y_predicted_train_data.append(y_pred_class)\n\n    # Adjust metrics to get average loss and accuracy per batch \n    train_loss = train_loss / len(dataloader)\n#     train_acc = train_acc / len(dataloader)\n    train_acc = train_acc / len_train_data\n    \n    #     New way of accuracy calculation\n    true = 0\n    tot = 0\n    for i in range(len(y_true_train_data)):\n        x = (y_true_train_data[i] == y_predicted_train_data[i])\n        for j in range(len(x)):\n            tot += 1\n            if x[j] == True:\n                true += 1\n    train_acc = (true/tot)\n\n    # return train_loss, train_acc\n    return train_loss, train_acc, y_true_train_data, y_predicted_train_data\n\n\n\n\ndef test_step(model: torch.nn.Module, \n              dataloader: torch.utils.data.DataLoader,\n              loss_fn: torch.nn.Module,\n              device: torch.device,\n              len_test_data) -> Tuple[float, float]:\n    \"\"\"Tests a PyTorch model for a single epoch.\n\n    Turns a target PyTorch model to \"eval\" mode and then performs\n    a forward pass on a testing dataset.\n\n    Args:\n    model: A PyTorch model to be tested.\n    dataloader: A DataLoader instance for the model to be tested on.\n    loss_fn: A PyTorch loss function to calculate loss on the test data.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A tuple of testing loss and testing accuracy metrics.\n    In the form (test_loss, test_accuracy). For example:\n\n    (0.0223, 0.8985)\n    \"\"\"\n    # Put model in eval mode\n    model.eval() \n\n    # Setup test loss and test accuracy values\n    test_loss = 0.0 \n    test_acc = 0.0\n\n    # for evaluation\n    y_true_test_data = []\n    y_predicted_test_data = []\n\n\n    # Turn on inference context manager\n    with torch.inference_mode():\n\n        # Loop through DataLoader batches\n        for batch, (X, y) in enumerate(dataloader):\n            # Send data to target device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred_logits = model(X)\n            \n            # 2. Calculate and accumulate loss\n            loss = loss_fn(test_pred_logits, y)\n            test_loss += loss.item()\n\n            # Calculate and accumulate accuracy\n            test_pred_labels = test_pred_logits.argmax(dim=1)\n            # test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n            test_acc += (test_pred_labels == y).sum().item()\n\n            # test_pred_labels = torch.argmax(torch.softmax(test_pred_logits, dim=1), dim=1)\n            # test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels)) \n            \n\n            # for evaluaiton\n            y_true_test_data.append(y)\n            y_predicted_test_data.append(test_pred_labels)\n\n\n    # Adjust metrics to get average loss and accuracy per batch \n    test_loss = test_loss / len(dataloader)\n#     test_acc = test_acc / len(dataloader)\n    test_acc = test_acc / len_test_data\n\n\n    \n#     New way of accuracy calculation\n    true = 0\n    tot = 0\n    for i in range(len(y_true_test_data)):\n        x = (y_true_test_data[i] == y_predicted_test_data[i])\n        for j in range(len(x)):\n            tot += 1\n            if x[j] == True:\n                true += 1\n    test_acc = (true/tot)\n    \n    # return test_loss, test_acc\n    return test_loss, test_acc, y_true_test_data, y_predicted_test_data\n\n\n\n\ndef train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader,\n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device,\n          tracking,\n          best_accuracy,\n          len_train_data,\n          len_test_data,\n        ) -> Dict[str, List[float]]:\n    \"\"\"Trains and tests a PyTorch model.\n\n    Passes a target PyTorch models through train_step() and test_step()\n    functions for a number of epochs, training and testing the model\n    in the same epoch loop.\n\n    Calculates, prints and stores evaluation metrics throughout.\n\n    Args:\n    model: A PyTorch model to be trained and tested.\n    train_dataloader: A DataLoader instance for the model to be trained on.\n    test_dataloader: A DataLoader instance for the model to be tested on.\n    optimizer: A PyTorch optimizer to help minimize the loss function.\n    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n    epochs: An integer indicating how many epochs to train for.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A dictionary of training and testing loss as well as training and\n    testing accuracy metrics. Each metric has a value in a list for \n    each epoch.\n    In the form: {train_loss: [...],\n              train_acc: [...],\n              test_loss: [...],\n              test_acc: [...]} \n    For example if training for epochs=2: \n             {train_loss: [2.0616, 1.0537],\n              train_acc: [0.3945, 0.3945],\n              test_loss: [1.2641, 1.5706],\n              test_acc: [0.3400, 0.2973]} \n    \"\"\"\n    # Create empty results dictionary\n    results = {\"train_loss\": [],\n               \"train_acc\": [],\n               \"test_loss\": [],\n               \"test_acc\": []\n    }\n\n\n        \n    # Loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc, y_true_train_data, y_predicted_train_data = train_step(model=model,\n                                                                                      dataloader=train_dataloader,\n                                                                                      loss_fn=loss_fn,\n                                                                                      optimizer=optimizer,\n                                                                                      device=device,\n                                                                                      len_train_data=len_train_data,\n                                                                                      )\n        test_loss, test_acc, y_true_test_data, y_predicted_test_data = test_step(model=model,\n                                                                                 dataloader=test_dataloader,\n                                                                                 loss_fn=loss_fn,\n                                                                                 device=device,\n                                                                                 len_test_data=len_test_data,\n                                                                                 )\n\n        if best_accuracy < test_acc:\n            print(f\"\\nAccuracy Improved ({best_accuracy} to {test_acc}), Saving the model...............................................\\n\")\n            best_accuracy = test_acc\n            best_y_true_test_data = y_true_test_data\n            best_y_predicted_test_data = y_predicted_test_data\n\n            model_name_path = f\"{best_accuracy} acc.pth\"\n            torch.save(model.state_dict(), model_name_path)\n            \n            \n            \n            \n            \n            # taking \"y_predicted_train_data\" & \"y_true_train_data\" into 1D array because it came out as batch by batch 2D list\n            predicted_train_data_1D = []\n            true_train_data_1D = []\n\n            for i in range(len(y_predicted_train_data)):\n                for j in range(len(y_predicted_train_data[i])):\n                    predicted_train_data_1D.append(y_predicted_train_data[i][j])\n                    true_train_data_1D.append(y_true_train_data[i][j])\n\n            # taking both into CPU\n            predicted_train_data_cpu = torch.tensor(predicted_train_data_1D, device = 'cpu')\n            true_train_data_cpu = torch.tensor(true_train_data_1D, device = 'cpu')\n\n\n\n            # now same procedure for test data's\n            predicted_test_data_1D = []\n            true_test_data_1D = []\n\n            for i in range(len(y_predicted_test_data)):\n                for j in range(len(y_predicted_test_data[i])):\n                    predicted_test_data_1D.append(y_predicted_test_data[i][j])\n                    true_test_data_1D.append(y_true_test_data[i][j])\n\n            # taking both into CPU\n            predicted_test_data_cpu = torch.tensor(predicted_test_data_1D, device = 'cpu')\n            true_test_data_cpu = torch.tensor(true_test_data_1D, device = 'cpu')\n\n\n\n            # now same procedure for best test data's\n            best_predicted_test_data_1D = []\n            best_true_test_data_1D = []\n\n            for i in range(len(best_y_predicted_test_data)):\n                for j in range(len(best_y_predicted_test_data[i])):\n                    best_predicted_test_data_1D.append(best_y_predicted_test_data[i][j])\n                    best_true_test_data_1D.append(best_y_true_test_data[i][j])\n\n            # taking both into CPU\n            best_predicted_test_data_cpu = torch.tensor(best_predicted_test_data_1D, device = 'cpu')\n            best_true_test_data_cpu = torch.tensor(best_true_test_data_1D, device = 'cpu')\n            \n            \n\n            # Generate a classification report\n            # F1 score on train data\n            y_true_train = true_train_data_cpu\n            y_pred_train = predicted_train_data_cpu\n\n            report = classification_report(y_true_train, y_pred_train, target_names=class_names)\n\n            print(f\"Evaluation report on Train data: \\n\\n{report}\\n\\n\\n\\n\")\n\n\n            # F1 score on test data\n            y_true_test = true_test_data_cpu\n            y_pred_test = predicted_test_data_cpu\n\n            report = classification_report(y_true_test, y_pred_test, target_names=class_names)\n\n            print(f\"Evaluation report on Test data: \\n\\n{report}\")\n            \n            \n            \n            \n            \n            \n            \n            \n        #     Live result tracking#####################################\n        #     for i in range(len(y_true_test_data)):\n        #         print(f\"{y_true_test_data[i]} and {y_predicted_test_data[i]}\")\n        acc_0 = 0\n        acc_1 = 0\n        total_0 = 0\n        total_1 = 0\n        for i in range(len(y_predicted_test_data)):\n            for j in range(len(y_true_test_data[i])):\n                if (y_true_test_data[i][j] == 0):\n                    total_0 += 1\n                    if (y_true_test_data[i][j] == y_predicted_test_data[i][j]):\n                        acc_0 += 1\n                elif (y_true_test_data[i][j] == 1): \n                    total_1 += 1\n                    if (y_true_test_data[i][j] == y_predicted_test_data[i][j]):\n                        acc_1 += 1\n#         print(f\"\\n0: {acc_0}/{total_0} and 1: {acc_1}/{total_1}\\n\\n\")\n        #     Live result tracking#####################################\n\n        \n        # Print out what's happening\n        print(\n          f\"Epoch: {epoch+1} | \"\n          f\"train_loss: {train_loss:.4f} | \"\n          f\"train_acc: {train_acc:.4f} | \"\n          f\"test_loss: {test_loss:.4f} | \"\n          f\"test_acc: {test_acc:.4f} | \"\n#           f\"0: {acc_0}/{total_0} | \"\n#           f\"1: {acc_1}/{total_1}\"\n        )\n        \n\n        # Update results dictionary\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n\n        \n        tracking.log({\n            \"train_acc\": train_acc,\n            \"test_acc\": test_acc,\n        })\n\n    # Return the filled results at the end of the epochs\n    # return results\n    \n\n    return results, y_true_train_data, y_predicted_train_data, y_true_test_data, y_predicted_test_data, best_accuracy, best_y_true_test_data, best_y_predicted_test_data\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:18:54.215841Z","iopub.execute_input":"2023-10-15T14:18:54.217951Z","iopub.status.idle":"2023-10-15T14:18:54.970677Z","shell.execute_reply.started":"2023-10-15T14:18:54.217915Z","shell.execute_reply":"2023-10-15T14:18:54.969743Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from going_modular import engine\n\n# Setup the optimizer to optimize our ViT model parameters using hyperparameters from the ViT paper \noptimizer = torch.optim.AdamW(params=model.parameters(), \n                              lr=2e-3, # Base LR from Table 3 for ViT-* ImageNet-1k                                    ## learning rate decre..\n#                               lr = 1e-1,\n                              betas=(0.9, 0.999), # default values but also mentioned in ViT paper section 4.1 (Training & Fine-tuning)\n                              weight_decay=0.05,\n#                               weight_decay=1e-5\n                              ) # from the ViT paper section 4.1 (Training & Fine-tuning) and Table 3 for ViT-* ImageNet-1k\n\n# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=5)\n# Setup the loss function for multi-class classification\nloss_fn = torch.nn.CrossEntropyLoss()\n\n# Set the seeds\nset_seeds()\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\nbest_accuracy=0.0","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:18:54.975250Z","iopub.execute_input":"2023-10-15T14:18:54.977808Z","iopub.status.idle":"2023-10-15T14:18:55.000432Z","shell.execute_reply.started":"2023-10-15T14:18:54.977774Z","shell.execute_reply":"2023-10-15T14:18:54.999468Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# from going_modular import engine\n\n# # Setup the optimizer to optimize our ViT model parameters using hyperparameters from the ViT paper \n# optimizer = torch.optim.AdamW(params=model2.parameters(), \n# #                               lr=2e-3, # Base LR from Table 3 for ViT-* ImageNet-1k                                    ## learning rate decre..\n#                               lr = 1e-3,\n#                               betas=(0.9, 0.999), # default values but also mentioned in ViT paper section 4.1 (Training & Fine-tuning)\n#                               weight_decay=0.05,\n# #                               weight_decay=1e-5\n#                               ) # from the ViT paper section 4.1 (Training & Fine-tuning) and Table 3 for ViT-* ImageNet-1k\n\n# # lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=5)\n# # Setup the loss function for multi-class classification\n# loss_fn = torch.nn.CrossEntropyLoss()\n\n# # Set the seeds\n# set_seeds()\n# torch.manual_seed(42)\n# torch.cuda.manual_seed(42)\n\n# best_accuracy=0.0","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:18:55.004889Z","iopub.execute_input":"2023-10-15T14:18:55.007128Z","iopub.status.idle":"2023-10-15T14:18:55.014457Z","shell.execute_reply.started":"2023-10-15T14:18:55.007057Z","shell.execute_reply":"2023-10-15T14:18:55.013531Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Train the model and save the training results to a dictionary\nresults, y_true_train_data, y_predicted_train_data, y_true_test_data, y_predicted_test_data, best_accuracy, best_y_true_test_data, best_y_predicted_test_data = train(model=model,\n                                                                                                           train_dataloader=train_dataloader,\n                                                                                                           test_dataloader=test_dataloader,\n                                                                                                           optimizer=optimizer,\n                                                                                                           loss_fn=loss_fn,\n                                                                                                           epochs=500,\n                                                                                                           device=device,\n                                                                                                           tracking=tracking,\n                                                                                                           best_accuracy=best_accuracy,\n                                                                                                           len_train_data=len(train_data),\n                                                                                                           len_test_data=len(test_data)\n                                                                                                           )","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:18:55.018550Z","iopub.execute_input":"2023-10-15T14:18:55.020820Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a60afeef33a249298dd1be32e99f64ce"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy Improved (0.0 to 0.6616616616616616), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.24      0.08      0.12       262\n         bcc       0.13      0.05      0.08       412\n         bkl       0.27      0.18      0.21       880\n          df       0.00      0.00      0.00        93\n         mel       0.22      0.10      0.13       891\n          nv       0.71      0.89      0.79      5365\n        vasc       0.00      0.00      0.00       114\n\n    accuracy                           0.63      8017\n   macro avg       0.22      0.19      0.19      8017\nweighted avg       0.54      0.63      0.57      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.00      0.00      0.00        65\n         bcc       0.50      0.02      0.04       102\n         bkl       0.31      0.14      0.19       219\n          df       0.00      0.00      0.00        22\n         mel       0.32      0.50      0.39       222\n          nv       0.76      0.88      0.82      1340\n        vasc       0.00      0.00      0.00        28\n\n    accuracy                           0.66      1998\n   macro avg       0.27      0.22      0.21      1998\nweighted avg       0.61      0.66      0.61      1998\n\nEpoch: 1 | train_loss: 1.0959 | train_acc: 0.6315 | test_loss: 1.2328 | test_acc: 0.6617 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy Improved (0.6616616616616616 to 0.6751751751751752), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.26      0.15      0.19       262\n         bcc       0.34      0.31      0.32       412\n         bkl       0.37      0.28      0.32       880\n          df       0.00      0.00      0.00        93\n         mel       0.41      0.16      0.23       891\n          nv       0.77      0.94      0.85      5365\n        vasc       0.00      0.00      0.00       114\n\n    accuracy                           0.70      8017\n   macro avg       0.31      0.26      0.27      8017\nweighted avg       0.63      0.70      0.65      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.33      0.03      0.06        65\n         bcc       1.00      0.01      0.02       102\n         bkl       0.29      0.06      0.10       219\n          df       0.00      0.00      0.00        22\n         mel       0.38      0.26      0.31       222\n          nv       0.71      0.95      0.81      1340\n        vasc       0.00      0.00      0.00        28\n\n    accuracy                           0.68      1998\n   macro avg       0.39      0.19      0.19      1998\nweighted avg       0.61      0.68      0.59      1998\n\nEpoch: 2 | train_loss: 0.8358 | train_acc: 0.6951 | test_loss: 1.1831 | test_acc: 0.6752 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy Improved (0.6751751751751752 to 0.7222222222222222), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.25      0.16      0.19       262\n         bcc       0.36      0.33      0.34       412\n         bkl       0.42      0.34      0.38       880\n          df       0.00      0.00      0.00        93\n         mel       0.48      0.30      0.37       891\n          nv       0.80      0.93      0.86      5365\n        vasc       0.50      0.02      0.03       114\n\n    accuracy                           0.71      8017\n   macro avg       0.40      0.30      0.31      8017\nweighted avg       0.67      0.71      0.68      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.00      0.00      0.00        65\n         bcc       0.38      0.37      0.37       102\n         bkl       0.42      0.27      0.33       219\n          df       0.00      0.00      0.00        22\n         mel       0.50      0.40      0.45       222\n          nv       0.79      0.94      0.86      1340\n        vasc       1.00      0.07      0.13        28\n\n    accuracy                           0.72      1998\n   macro avg       0.44      0.29      0.31      1998\nweighted avg       0.67      0.72      0.68      1998\n\nEpoch: 3 | train_loss: 0.7773 | train_acc: 0.7149 | test_loss: 0.7749 | test_acc: 0.7222 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy Improved (0.7222222222222222 to 0.7457457457457457), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.30      0.17      0.22       262\n         bcc       0.38      0.42      0.40       412\n         bkl       0.44      0.34      0.38       880\n          df       0.00      0.00      0.00        93\n         mel       0.47      0.29      0.36       891\n          nv       0.81      0.93      0.87      5365\n        vasc       0.76      0.27      0.40       114\n\n    accuracy                           0.72      8017\n   macro avg       0.45      0.35      0.38      8017\nweighted avg       0.68      0.72      0.70      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.47      0.29      0.36        65\n         bcc       0.39      0.55      0.46       102\n         bkl       0.55      0.42      0.48       219\n          df       0.00      0.00      0.00        22\n         mel       0.43      0.57      0.49       222\n          nv       0.88      0.88      0.88      1340\n        vasc       0.80      0.43      0.56        28\n\n    accuracy                           0.75      1998\n   macro avg       0.51      0.45      0.46      1998\nweighted avg       0.75      0.75      0.74      1998\n\nEpoch: 4 | train_loss: 0.7374 | train_acc: 0.7230 | test_loss: 0.7453 | test_acc: 0.7457 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 5 | train_loss: 0.7016 | train_acc: 0.7434 | test_loss: 0.8213 | test_acc: 0.7242 | \nEpoch: 6 | train_loss: 0.6974 | train_acc: 0.7469 | test_loss: 0.7481 | test_acc: 0.7227 | \nEpoch: 7 | train_loss: 0.6603 | train_acc: 0.7517 | test_loss: 0.7806 | test_acc: 0.7252 | \nEpoch: 8 | train_loss: 0.6658 | train_acc: 0.7493 | test_loss: 0.7203 | test_acc: 0.7422 | \nEpoch: 9 | train_loss: 0.6685 | train_acc: 0.7468 | test_loss: 0.7812 | test_acc: 0.7442 | \n\nAccuracy Improved (0.7457457457457457 to 0.7597597597597597), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.38      0.27      0.32       262\n         bcc       0.44      0.44      0.44       412\n         bkl       0.48      0.43      0.45       880\n          df       0.14      0.01      0.02        93\n         mel       0.53      0.38      0.44       891\n          nv       0.85      0.93      0.89      5365\n        vasc       0.69      0.60      0.64       114\n\n    accuracy                           0.75      8017\n   macro avg       0.50      0.44      0.46      8017\nweighted avg       0.73      0.75      0.74      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.53      0.31      0.39        65\n         bcc       0.50      0.49      0.50       102\n         bkl       0.62      0.23      0.34       219\n          df       0.00      0.00      0.00        22\n         mel       0.50      0.41      0.45       222\n          nv       0.82      0.96      0.88      1340\n        vasc       0.67      0.71      0.69        28\n\n    accuracy                           0.76      1998\n   macro avg       0.52      0.45      0.46      1998\nweighted avg       0.73      0.76      0.73      1998\n\nEpoch: 10 | train_loss: 0.6597 | train_acc: 0.7520 | test_loss: 0.6702 | test_acc: 0.7598 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy Improved (0.7597597597597597 to 0.7702702702702703), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.39      0.30      0.34       262\n         bcc       0.49      0.57      0.53       412\n         bkl       0.51      0.41      0.46       880\n          df       0.00      0.00      0.00        93\n         mel       0.52      0.41      0.46       891\n          nv       0.86      0.93      0.89      5365\n        vasc       0.72      0.71      0.72       114\n\n    accuracy                           0.76      8017\n   macro avg       0.50      0.48      0.48      8017\nweighted avg       0.74      0.76      0.75      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.53      0.35      0.43        65\n         bcc       0.58      0.34      0.43       102\n         bkl       0.51      0.49      0.50       219\n          df       0.00      0.00      0.00        22\n         mel       0.50      0.46      0.48       222\n          nv       0.86      0.94      0.90      1340\n        vasc       0.94      0.61      0.74        28\n\n    accuracy                           0.77      1998\n   macro avg       0.56      0.46      0.50      1998\nweighted avg       0.75      0.77      0.76      1998\n\nEpoch: 11 | train_loss: 0.6291 | train_acc: 0.7610 | test_loss: 0.6606 | test_acc: 0.7703 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 12 | train_loss: 0.6201 | train_acc: 0.7685 | test_loss: 0.6931 | test_acc: 0.7317 | \nEpoch: 13 | train_loss: 0.6315 | train_acc: 0.7625 | test_loss: 0.7035 | test_acc: 0.7377 | \nEpoch: 14 | train_loss: 0.6068 | train_acc: 0.7720 | test_loss: 0.6762 | test_acc: 0.7638 | \nEpoch: 15 | train_loss: 0.6025 | train_acc: 0.7737 | test_loss: 0.7363 | test_acc: 0.7317 | \nEpoch: 16 | train_loss: 0.6053 | train_acc: 0.7724 | test_loss: 0.6440 | test_acc: 0.7588 | \nEpoch: 17 | train_loss: 0.5853 | train_acc: 0.7813 | test_loss: 0.6607 | test_acc: 0.7683 | \n\nAccuracy Improved (0.7702702702702703 to 0.7707707707707707), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.43      0.38      0.40       262\n         bcc       0.51      0.60      0.55       412\n         bkl       0.57      0.45      0.51       880\n          df       0.60      0.03      0.06        93\n         mel       0.57      0.44      0.50       891\n          nv       0.86      0.93      0.90      5365\n        vasc       0.75      0.73      0.74       114\n\n    accuracy                           0.78      8017\n   macro avg       0.61      0.51      0.52      8017\nweighted avg       0.76      0.78      0.76      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.43      0.46      0.44        65\n         bcc       0.51      0.63      0.56       102\n         bkl       0.59      0.43      0.50       219\n          df       0.00      0.00      0.00        22\n         mel       0.48      0.47      0.47       222\n          nv       0.88      0.91      0.90      1340\n        vasc       0.88      0.82      0.85        28\n\n    accuracy                           0.77      1998\n   macro avg       0.54      0.53      0.53      1998\nweighted avg       0.76      0.77      0.76      1998\n\nEpoch: 18 | train_loss: 0.5804 | train_acc: 0.7781 | test_loss: 0.6545 | test_acc: 0.7708 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 19 | train_loss: 0.5757 | train_acc: 0.7832 | test_loss: 0.6950 | test_acc: 0.7518 | \n\nAccuracy Improved (0.7707707707707707 to 0.7712712712712713), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.40      0.36      0.38       262\n         bcc       0.52      0.57      0.54       412\n         bkl       0.59      0.52      0.55       880\n          df       0.40      0.02      0.04        93\n         mel       0.57      0.43      0.49       891\n          nv       0.87      0.94      0.90      5365\n        vasc       0.75      0.81      0.78       114\n\n    accuracy                           0.78      8017\n   macro avg       0.58      0.52      0.53      8017\nweighted avg       0.77      0.78      0.77      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.42      0.65      0.51        65\n         bcc       0.54      0.32      0.40       102\n         bkl       0.51      0.56      0.53       219\n          df       1.00      0.05      0.09        22\n         mel       0.55      0.32      0.40       222\n          nv       0.87      0.93      0.90      1340\n        vasc       0.67      0.86      0.75        28\n\n    accuracy                           0.77      1998\n   macro avg       0.65      0.53      0.51      1998\nweighted avg       0.76      0.77      0.76      1998\n\nEpoch: 20 | train_loss: 0.5756 | train_acc: 0.7826 | test_loss: 0.6200 | test_acc: 0.7713 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 21 | train_loss: 0.5796 | train_acc: 0.7793 | test_loss: 0.6639 | test_acc: 0.7653 | \n\nAccuracy Improved (0.7712712712712713 to 0.7747747747747747), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.46      0.37      0.41       262\n         bcc       0.50      0.60      0.55       412\n         bkl       0.59      0.49      0.54       880\n          df       0.67      0.02      0.04        93\n         mel       0.58      0.46      0.51       891\n          nv       0.88      0.94      0.91      5365\n        vasc       0.81      0.80      0.80       114\n\n    accuracy                           0.79      8017\n   macro avg       0.64      0.53      0.54      8017\nweighted avg       0.78      0.79      0.78      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.38      0.62      0.47        65\n         bcc       0.58      0.53      0.55       102\n         bkl       0.58      0.26      0.36       219\n          df       1.00      0.05      0.09        22\n         mel       0.57      0.42      0.49       222\n          nv       0.85      0.96      0.90      1340\n        vasc       0.95      0.75      0.84        28\n\n    accuracy                           0.77      1998\n   macro avg       0.70      0.51      0.53      1998\nweighted avg       0.76      0.77      0.75      1998\n\nEpoch: 22 | train_loss: 0.5631 | train_acc: 0.7886 | test_loss: 0.6065 | test_acc: 0.7748 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 23 | train_loss: 0.5725 | train_acc: 0.7837 | test_loss: 0.6803 | test_acc: 0.7658 | \n\nAccuracy Improved (0.7747747747747747 to 0.7787787787787788), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.46      0.40      0.43       262\n         bcc       0.57      0.68      0.62       412\n         bkl       0.58      0.49      0.53       880\n          df       0.36      0.04      0.08        93\n         mel       0.60      0.45      0.52       891\n          nv       0.88      0.94      0.91      5365\n        vasc       0.78      0.77      0.78       114\n\n    accuracy                           0.79      8017\n   macro avg       0.60      0.54      0.55      8017\nweighted avg       0.78      0.79      0.78      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.38      0.51      0.43        65\n         bcc       0.59      0.40      0.48       102\n         bkl       0.52      0.54      0.53       219\n          df       1.00      0.05      0.09        22\n         mel       0.54      0.50      0.52       222\n          nv       0.89      0.92      0.90      1340\n        vasc       0.78      0.75      0.76        28\n\n    accuracy                           0.78      1998\n   macro avg       0.67      0.52      0.53      1998\nweighted avg       0.78      0.78      0.77      1998\n\nEpoch: 24 | train_loss: 0.5611 | train_acc: 0.7917 | test_loss: 0.6228 | test_acc: 0.7788 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 25 | train_loss: 0.5561 | train_acc: 0.7927 | test_loss: 0.6322 | test_acc: 0.7763 | \nEpoch: 26 | train_loss: 0.5646 | train_acc: 0.7888 | test_loss: 0.6916 | test_acc: 0.7568 | \nEpoch: 27 | train_loss: 0.5521 | train_acc: 0.7881 | test_loss: 0.6426 | test_acc: 0.7688 | \nEpoch: 28 | train_loss: 0.5550 | train_acc: 0.7888 | test_loss: 0.6258 | test_acc: 0.7683 | \nEpoch: 29 | train_loss: 0.5424 | train_acc: 0.7924 | test_loss: 0.6495 | test_acc: 0.7633 | \nEpoch: 30 | train_loss: 0.5425 | train_acc: 0.7932 | test_loss: 0.6421 | test_acc: 0.7688 | \n\nAccuracy Improved (0.7787787787787788 to 0.7962962962962963), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.49      0.40      0.44       262\n         bcc       0.57      0.67      0.62       412\n         bkl       0.60      0.50      0.54       880\n          df       0.60      0.06      0.12        93\n         mel       0.60      0.47      0.53       891\n          nv       0.88      0.94      0.91      5365\n        vasc       0.82      0.76      0.79       114\n\n    accuracy                           0.80      8017\n   macro avg       0.65      0.54      0.56      8017\nweighted avg       0.78      0.80      0.79      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.58      0.40      0.47        65\n         bcc       0.62      0.53      0.57       102\n         bkl       0.58      0.52      0.55       219\n          df       0.31      0.23      0.26        22\n         mel       0.56      0.46      0.50       222\n          nv       0.88      0.95      0.91      1340\n        vasc       0.79      0.68      0.73        28\n\n    accuracy                           0.80      1998\n   macro avg       0.62      0.54      0.57      1998\nweighted avg       0.78      0.80      0.79      1998\n\nEpoch: 31 | train_loss: 0.5377 | train_acc: 0.7978 | test_loss: 0.5940 | test_acc: 0.7963 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 32 | train_loss: 0.5387 | train_acc: 0.8003 | test_loss: 0.6473 | test_acc: 0.7663 | \nEpoch: 33 | train_loss: 0.5401 | train_acc: 0.7908 | test_loss: 0.6504 | test_acc: 0.7753 | \nEpoch: 34 | train_loss: 0.5335 | train_acc: 0.7982 | test_loss: 0.6345 | test_acc: 0.7758 | \nEpoch: 35 | train_loss: 0.5366 | train_acc: 0.7959 | test_loss: 0.6368 | test_acc: 0.7768 | \nEpoch: 36 | train_loss: 0.5260 | train_acc: 0.7969 | test_loss: 0.6962 | test_acc: 0.7583 | \nEpoch: 37 | train_loss: 0.5124 | train_acc: 0.8050 | test_loss: 0.7010 | test_acc: 0.7482 | \nEpoch: 38 | train_loss: 0.5378 | train_acc: 0.7946 | test_loss: 0.6323 | test_acc: 0.7748 | \nEpoch: 39 | train_loss: 0.5072 | train_acc: 0.8029 | test_loss: 0.5768 | test_acc: 0.7963 | \nEpoch: 40 | train_loss: 0.5077 | train_acc: 0.8073 | test_loss: 0.6019 | test_acc: 0.7793 | \nEpoch: 41 | train_loss: 0.5170 | train_acc: 0.8037 | test_loss: 0.6324 | test_acc: 0.7758 | \nEpoch: 42 | train_loss: 0.5161 | train_acc: 0.8012 | test_loss: 0.5873 | test_acc: 0.7888 | \nEpoch: 43 | train_loss: 0.5091 | train_acc: 0.8060 | test_loss: 0.6172 | test_acc: 0.7743 | \nEpoch: 44 | train_loss: 0.5182 | train_acc: 0.8042 | test_loss: 0.6326 | test_acc: 0.7778 | \nEpoch: 45 | train_loss: 0.4975 | train_acc: 0.8094 | test_loss: 0.6685 | test_acc: 0.7773 | \nEpoch: 46 | train_loss: 0.5108 | train_acc: 0.8044 | test_loss: 0.6837 | test_acc: 0.7513 | \nEpoch: 47 | train_loss: 0.5060 | train_acc: 0.8073 | test_loss: 0.6541 | test_acc: 0.7808 | \nEpoch: 48 | train_loss: 0.5020 | train_acc: 0.8068 | test_loss: 0.6240 | test_acc: 0.7788 | \nEpoch: 49 | train_loss: 0.5079 | train_acc: 0.8082 | test_loss: 0.6126 | test_acc: 0.7793 | \nEpoch: 50 | train_loss: 0.4882 | train_acc: 0.8134 | test_loss: 0.6009 | test_acc: 0.7908 | \nEpoch: 51 | train_loss: 0.4905 | train_acc: 0.8145 | test_loss: 0.6653 | test_acc: 0.7608 | \nEpoch: 52 | train_loss: 0.4932 | train_acc: 0.8129 | test_loss: 0.6844 | test_acc: 0.7678 | \nEpoch: 53 | train_loss: 0.4945 | train_acc: 0.8114 | test_loss: 0.6934 | test_acc: 0.7648 | \n\nAccuracy Improved (0.7962962962962963 to 0.7982982982982983), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.50      0.47      0.48       262\n         bcc       0.63      0.64      0.63       412\n         bkl       0.61      0.55      0.58       880\n          df       0.71      0.49      0.58        93\n         mel       0.63      0.47      0.54       891\n          nv       0.89      0.95      0.92      5365\n        vasc       0.90      0.82      0.86       114\n\n    accuracy                           0.81      8017\n   macro avg       0.69      0.63      0.66      8017\nweighted avg       0.80      0.81      0.80      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.54      0.48      0.51        65\n         bcc       0.49      0.52      0.50       102\n         bkl       0.61      0.53      0.57       219\n          df       0.64      0.32      0.42        22\n         mel       0.69      0.37      0.48       222\n          nv       0.87      0.96      0.91      1340\n        vasc       0.72      0.82      0.77        28\n\n    accuracy                           0.80      1998\n   macro avg       0.65      0.57      0.59      1998\nweighted avg       0.78      0.80      0.78      1998\n\nEpoch: 54 | train_loss: 0.4959 | train_acc: 0.8119 | test_loss: 0.5840 | test_acc: 0.7983 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 55 | train_loss: 0.4791 | train_acc: 0.8131 | test_loss: 0.6068 | test_acc: 0.7873 | \nEpoch: 56 | train_loss: 0.4867 | train_acc: 0.8188 | test_loss: 0.6850 | test_acc: 0.7713 | \nEpoch: 57 | train_loss: 0.4847 | train_acc: 0.8121 | test_loss: 0.6385 | test_acc: 0.7753 | \nEpoch: 58 | train_loss: 0.4827 | train_acc: 0.8113 | test_loss: 0.6113 | test_acc: 0.7863 | \nEpoch: 59 | train_loss: 0.4787 | train_acc: 0.8181 | test_loss: 0.6441 | test_acc: 0.7813 | \nEpoch: 60 | train_loss: 0.4710 | train_acc: 0.8166 | test_loss: 0.6278 | test_acc: 0.7728 | \nEpoch: 61 | train_loss: 0.4589 | train_acc: 0.8201 | test_loss: 0.6401 | test_acc: 0.7908 | \nEpoch: 62 | train_loss: 0.4660 | train_acc: 0.8180 | test_loss: 0.5991 | test_acc: 0.7763 | \nEpoch: 63 | train_loss: 0.4714 | train_acc: 0.8190 | test_loss: 0.6123 | test_acc: 0.7723 | \nEpoch: 64 | train_loss: 0.4630 | train_acc: 0.8193 | test_loss: 0.5772 | test_acc: 0.7983 | \nEpoch: 65 | train_loss: 0.4637 | train_acc: 0.8256 | test_loss: 0.6129 | test_acc: 0.7688 | \nEpoch: 66 | train_loss: 0.4754 | train_acc: 0.8183 | test_loss: 0.6176 | test_acc: 0.7953 | \nEpoch: 67 | train_loss: 0.4591 | train_acc: 0.8211 | test_loss: 0.6025 | test_acc: 0.7938 | \nEpoch: 68 | train_loss: 0.4480 | train_acc: 0.8290 | test_loss: 0.6261 | test_acc: 0.7833 | \nEpoch: 69 | train_loss: 0.4505 | train_acc: 0.8269 | test_loss: 0.6117 | test_acc: 0.7783 | \nEpoch: 70 | train_loss: 0.4517 | train_acc: 0.8291 | test_loss: 0.5664 | test_acc: 0.7958 | \nEpoch: 71 | train_loss: 0.4427 | train_acc: 0.8252 | test_loss: 0.6577 | test_acc: 0.7808 | \n\nAccuracy Improved (0.7982982982982983 to 0.8018018018018018), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.59      0.49      0.54       262\n         bcc       0.67      0.70      0.69       412\n         bkl       0.64      0.58      0.61       880\n          df       0.75      0.59      0.66        93\n         mel       0.66      0.53      0.59       891\n          nv       0.90      0.95      0.92      5365\n        vasc       0.91      0.90      0.91       114\n\n    accuracy                           0.83      8017\n   macro avg       0.73      0.68      0.70      8017\nweighted avg       0.82      0.83      0.82      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.57      0.48      0.52        65\n         bcc       0.60      0.66      0.63       102\n         bkl       0.57      0.65      0.61       219\n          df       0.41      0.55      0.47        22\n         mel       0.56      0.59      0.58       222\n          nv       0.92      0.89      0.91      1340\n        vasc       0.95      0.68      0.79        28\n\n    accuracy                           0.80      1998\n   macro avg       0.66      0.64      0.64      1998\nweighted avg       0.81      0.80      0.81      1998\n\nEpoch: 72 | train_loss: 0.4456 | train_acc: 0.8305 | test_loss: 0.6026 | test_acc: 0.8018 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 73 | train_loss: 0.4475 | train_acc: 0.8299 | test_loss: 0.6560 | test_acc: 0.7868 | \nEpoch: 74 | train_loss: 0.4536 | train_acc: 0.8266 | test_loss: 0.5743 | test_acc: 0.8003 | \nEpoch: 75 | train_loss: 0.4392 | train_acc: 0.8331 | test_loss: 0.6837 | test_acc: 0.7653 | \nEpoch: 76 | train_loss: 0.4390 | train_acc: 0.8307 | test_loss: 0.6256 | test_acc: 0.7863 | \nEpoch: 77 | train_loss: 0.4392 | train_acc: 0.8284 | test_loss: 0.6206 | test_acc: 0.7808 | \nEpoch: 78 | train_loss: 0.4413 | train_acc: 0.8287 | test_loss: 0.6059 | test_acc: 0.7878 | \n\nAccuracy Improved (0.8018018018018018 to 0.8033033033033034), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.55      0.49      0.52       262\n         bcc       0.69      0.72      0.71       412\n         bkl       0.63      0.60      0.62       880\n          df       0.67      0.60      0.64        93\n         mel       0.65      0.51      0.57       891\n          nv       0.90      0.94      0.92      5365\n        vasc       0.92      0.90      0.91       114\n\n    accuracy                           0.83      8017\n   macro avg       0.72      0.68      0.70      8017\nweighted avg       0.82      0.83      0.82      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.56      0.34      0.42        65\n         bcc       0.56      0.56      0.56       102\n         bkl       0.61      0.50      0.55       219\n          df       0.73      0.36      0.48        22\n         mel       0.56      0.62      0.59       222\n          nv       0.89      0.93      0.91      1340\n        vasc       0.92      0.82      0.87        28\n\n    accuracy                           0.80      1998\n   macro avg       0.69      0.59      0.63      1998\nweighted avg       0.80      0.80      0.80      1998\n\nEpoch: 79 | train_loss: 0.4339 | train_acc: 0.8277 | test_loss: 0.5721 | test_acc: 0.8033 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 80 | train_loss: 0.4159 | train_acc: 0.8398 | test_loss: 0.6855 | test_acc: 0.7858 | \nEpoch: 81 | train_loss: 0.4193 | train_acc: 0.8410 | test_loss: 0.5851 | test_acc: 0.8003 | \nEpoch: 82 | train_loss: 0.4346 | train_acc: 0.8339 | test_loss: 0.6632 | test_acc: 0.7698 | \nEpoch: 83 | train_loss: 0.4199 | train_acc: 0.8385 | test_loss: 0.5897 | test_acc: 0.7998 | \nEpoch: 84 | train_loss: 0.4195 | train_acc: 0.8372 | test_loss: 0.6260 | test_acc: 0.7843 | \nEpoch: 85 | train_loss: 0.4186 | train_acc: 0.8368 | test_loss: 0.5936 | test_acc: 0.7968 | \nEpoch: 86 | train_loss: 0.4303 | train_acc: 0.8349 | test_loss: 0.5706 | test_acc: 0.7928 | \nEpoch: 87 | train_loss: 0.4238 | train_acc: 0.8302 | test_loss: 0.7228 | test_acc: 0.7758 | \nEpoch: 88 | train_loss: 0.4356 | train_acc: 0.8356 | test_loss: 0.6788 | test_acc: 0.7718 | \nEpoch: 89 | train_loss: 0.4192 | train_acc: 0.8353 | test_loss: 0.5876 | test_acc: 0.7873 | \nEpoch: 90 | train_loss: 0.4311 | train_acc: 0.8327 | test_loss: 0.6071 | test_acc: 0.7898 | \nEpoch: 91 | train_loss: 0.4046 | train_acc: 0.8443 | test_loss: 0.5975 | test_acc: 0.7903 | \nEpoch: 92 | train_loss: 0.4061 | train_acc: 0.8458 | test_loss: 0.6153 | test_acc: 0.7848 | \n\nAccuracy Improved (0.8033033033033034 to 0.8073073073073073), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.60      0.54      0.57       262\n         bcc       0.69      0.72      0.70       412\n         bkl       0.66      0.64      0.65       880\n          df       0.62      0.62      0.62        93\n         mel       0.68      0.55      0.61       891\n          nv       0.91      0.95      0.93      5365\n        vasc       0.88      0.84      0.86       114\n\n    accuracy                           0.84      8017\n   macro avg       0.72      0.69      0.71      8017\nweighted avg       0.83      0.84      0.83      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.59      0.54      0.56        65\n         bcc       0.54      0.65      0.59       102\n         bkl       0.64      0.48      0.55       219\n          df       0.83      0.45      0.59        22\n         mel       0.62      0.45      0.52       222\n          nv       0.88      0.95      0.91      1340\n        vasc       0.62      0.93      0.74        28\n\n    accuracy                           0.81      1998\n   macro avg       0.68      0.64      0.64      1998\nweighted avg       0.80      0.81      0.80      1998\n\nEpoch: 93 | train_loss: 0.4140 | train_acc: 0.8382 | test_loss: 0.5700 | test_acc: 0.8073 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 94 | train_loss: 0.4038 | train_acc: 0.8426 | test_loss: 0.6518 | test_acc: 0.7778 | \nEpoch: 95 | train_loss: 0.4086 | train_acc: 0.8428 | test_loss: 0.5848 | test_acc: 0.7923 | \nEpoch: 96 | train_loss: 0.3935 | train_acc: 0.8461 | test_loss: 0.6146 | test_acc: 0.7828 | \nEpoch: 97 | train_loss: 0.4013 | train_acc: 0.8445 | test_loss: 0.5607 | test_acc: 0.7983 | \nEpoch: 98 | train_loss: 0.3982 | train_acc: 0.8431 | test_loss: 0.6376 | test_acc: 0.7818 | \nEpoch: 99 | train_loss: 0.3972 | train_acc: 0.8452 | test_loss: 0.6695 | test_acc: 0.7803 | \nEpoch: 100 | train_loss: 0.3966 | train_acc: 0.8451 | test_loss: 0.6031 | test_acc: 0.7968 | \nEpoch: 101 | train_loss: 0.3849 | train_acc: 0.8468 | test_loss: 0.6586 | test_acc: 0.7703 | \nEpoch: 102 | train_loss: 0.3962 | train_acc: 0.8426 | test_loss: 0.6234 | test_acc: 0.7828 | \nEpoch: 103 | train_loss: 0.3888 | train_acc: 0.8484 | test_loss: 0.5716 | test_acc: 0.8013 | \nEpoch: 104 | train_loss: 0.3772 | train_acc: 0.8507 | test_loss: 0.6543 | test_acc: 0.7758 | \nEpoch: 105 | train_loss: 0.3905 | train_acc: 0.8470 | test_loss: 0.7040 | test_acc: 0.7573 | \nEpoch: 106 | train_loss: 0.3884 | train_acc: 0.8438 | test_loss: 0.6125 | test_acc: 0.7913 | \nEpoch: 107 | train_loss: 0.3898 | train_acc: 0.8498 | test_loss: 0.6137 | test_acc: 0.7958 | \nEpoch: 108 | train_loss: 0.3781 | train_acc: 0.8501 | test_loss: 0.6581 | test_acc: 0.7813 | \nEpoch: 109 | train_loss: 0.3762 | train_acc: 0.8532 | test_loss: 0.6536 | test_acc: 0.7848 | \nEpoch: 110 | train_loss: 0.3808 | train_acc: 0.8524 | test_loss: 0.6453 | test_acc: 0.7943 | \nEpoch: 111 | train_loss: 0.3919 | train_acc: 0.8527 | test_loss: 0.6220 | test_acc: 0.8043 | \nEpoch: 112 | train_loss: 0.3725 | train_acc: 0.8551 | test_loss: 0.6062 | test_acc: 0.7973 | \nEpoch: 113 | train_loss: 0.3780 | train_acc: 0.8561 | test_loss: 0.5901 | test_acc: 0.7983 | \nEpoch: 114 | train_loss: 0.3687 | train_acc: 0.8576 | test_loss: 0.6562 | test_acc: 0.7753 | \nEpoch: 115 | train_loss: 0.3669 | train_acc: 0.8581 | test_loss: 0.6276 | test_acc: 0.8038 | \n\nAccuracy Improved (0.8073073073073073 to 0.8098098098098098), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.67      0.59      0.62       262\n         bcc       0.75      0.80      0.78       412\n         bkl       0.69      0.66      0.68       880\n          df       0.80      0.73      0.76        93\n         mel       0.68      0.61      0.64       891\n          nv       0.92      0.95      0.94      5365\n        vasc       0.96      0.94      0.95       114\n\n    accuracy                           0.86      8017\n   macro avg       0.78      0.75      0.77      8017\nweighted avg       0.85      0.86      0.85      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.52      0.52      0.52        65\n         bcc       0.69      0.50      0.58       102\n         bkl       0.59      0.59      0.59       219\n          df       0.52      0.64      0.57        22\n         mel       0.68      0.41      0.51       222\n          nv       0.88      0.95      0.91      1340\n        vasc       0.79      0.79      0.79        28\n\n    accuracy                           0.81      1998\n   macro avg       0.67      0.63      0.64      1998\nweighted avg       0.80      0.81      0.80      1998\n\nEpoch: 116 | train_loss: 0.3637 | train_acc: 0.8577 | test_loss: 0.6122 | test_acc: 0.8098 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 117 | train_loss: 0.3616 | train_acc: 0.8644 | test_loss: 0.6212 | test_acc: 0.8003 | \nEpoch: 118 | train_loss: 0.3595 | train_acc: 0.8633 | test_loss: 0.6308 | test_acc: 0.7878 | \nEpoch: 119 | train_loss: 0.3580 | train_acc: 0.8594 | test_loss: 0.6696 | test_acc: 0.7753 | \nEpoch: 120 | train_loss: 0.3738 | train_acc: 0.8543 | test_loss: 0.6315 | test_acc: 0.7943 | \nEpoch: 121 | train_loss: 0.3499 | train_acc: 0.8589 | test_loss: 0.6187 | test_acc: 0.8058 | \nEpoch: 122 | train_loss: 0.3485 | train_acc: 0.8638 | test_loss: 0.6087 | test_acc: 0.7973 | \nEpoch: 123 | train_loss: 0.3451 | train_acc: 0.8637 | test_loss: 0.6626 | test_acc: 0.7953 | \nEpoch: 124 | train_loss: 0.3554 | train_acc: 0.8609 | test_loss: 0.6686 | test_acc: 0.7873 | \nEpoch: 125 | train_loss: 0.3396 | train_acc: 0.8677 | test_loss: 0.6555 | test_acc: 0.7763 | \nEpoch: 126 | train_loss: 0.3710 | train_acc: 0.8538 | test_loss: 0.6578 | test_acc: 0.7788 | \nEpoch: 127 | train_loss: 0.3474 | train_acc: 0.8632 | test_loss: 0.6869 | test_acc: 0.7803 | \nEpoch: 128 | train_loss: 0.3475 | train_acc: 0.8639 | test_loss: 0.6179 | test_acc: 0.8078 | \nEpoch: 129 | train_loss: 0.3475 | train_acc: 0.8648 | test_loss: 0.7376 | test_acc: 0.7763 | \nEpoch: 130 | train_loss: 0.3614 | train_acc: 0.8612 | test_loss: 0.6481 | test_acc: 0.7928 | \nEpoch: 131 | train_loss: 0.3354 | train_acc: 0.8705 | test_loss: 0.6810 | test_acc: 0.7993 | \nEpoch: 132 | train_loss: 0.3293 | train_acc: 0.8764 | test_loss: 0.6303 | test_acc: 0.8053 | \nEpoch: 133 | train_loss: 0.3435 | train_acc: 0.8678 | test_loss: 0.6689 | test_acc: 0.7968 | \nEpoch: 134 | train_loss: 0.3232 | train_acc: 0.8734 | test_loss: 0.6223 | test_acc: 0.7933 | \nEpoch: 135 | train_loss: 0.3376 | train_acc: 0.8669 | test_loss: 0.6620 | test_acc: 0.7963 | \nEpoch: 136 | train_loss: 0.3361 | train_acc: 0.8679 | test_loss: 0.6727 | test_acc: 0.7928 | \nEpoch: 137 | train_loss: 0.3309 | train_acc: 0.8689 | test_loss: 0.6670 | test_acc: 0.7878 | \nEpoch: 138 | train_loss: 0.3426 | train_acc: 0.8677 | test_loss: 0.7255 | test_acc: 0.7673 | \nEpoch: 139 | train_loss: 0.3428 | train_acc: 0.8698 | test_loss: 0.6370 | test_acc: 0.8038 | \nEpoch: 140 | train_loss: 0.3137 | train_acc: 0.8774 | test_loss: 0.6223 | test_acc: 0.7988 | \nEpoch: 141 | train_loss: 0.3054 | train_acc: 0.8801 | test_loss: 0.6404 | test_acc: 0.8003 | \nEpoch: 142 | train_loss: 0.3242 | train_acc: 0.8721 | test_loss: 0.6734 | test_acc: 0.8018 | \nEpoch: 143 | train_loss: 0.3188 | train_acc: 0.8774 | test_loss: 0.7018 | test_acc: 0.7943 | \nEpoch: 144 | train_loss: 0.3101 | train_acc: 0.8800 | test_loss: 0.6770 | test_acc: 0.7813 | \nEpoch: 145 | train_loss: 0.3188 | train_acc: 0.8753 | test_loss: 0.6737 | test_acc: 0.7773 | \nEpoch: 146 | train_loss: 0.3199 | train_acc: 0.8783 | test_loss: 0.6963 | test_acc: 0.8028 | \nEpoch: 147 | train_loss: 0.3107 | train_acc: 0.8780 | test_loss: 0.6628 | test_acc: 0.7943 | \nEpoch: 148 | train_loss: 0.3124 | train_acc: 0.8793 | test_loss: 0.6457 | test_acc: 0.7988 | \nEpoch: 149 | train_loss: 0.3050 | train_acc: 0.8890 | test_loss: 0.6797 | test_acc: 0.7943 | \nEpoch: 150 | train_loss: 0.3188 | train_acc: 0.8750 | test_loss: 0.6709 | test_acc: 0.8073 | \nEpoch: 151 | train_loss: 0.3007 | train_acc: 0.8836 | test_loss: 0.6954 | test_acc: 0.8078 | \nEpoch: 152 | train_loss: 0.3243 | train_acc: 0.8714 | test_loss: 0.6451 | test_acc: 0.8008 | \n\nAccuracy Improved (0.8098098098098098 to 0.8113113113113113), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.70      0.69      0.69       262\n         bcc       0.79      0.78      0.79       412\n         bkl       0.77      0.75      0.76       880\n          df       0.75      0.75      0.75        93\n         mel       0.72      0.68      0.70       891\n          nv       0.94      0.95      0.95      5365\n        vasc       0.92      0.96      0.94       114\n\n    accuracy                           0.88      8017\n   macro avg       0.80      0.79      0.80      8017\nweighted avg       0.88      0.88      0.88      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.68      0.38      0.49        65\n         bcc       0.58      0.66      0.61       102\n         bkl       0.55      0.67      0.61       219\n          df       0.52      0.64      0.57        22\n         mel       0.63      0.46      0.53       222\n          nv       0.91      0.93      0.92      1340\n        vasc       0.86      0.89      0.88        28\n\n    accuracy                           0.81      1998\n   macro avg       0.68      0.66      0.66      1998\nweighted avg       0.81      0.81      0.81      1998\n\nEpoch: 153 | train_loss: 0.3154 | train_acc: 0.8803 | test_loss: 0.6369 | test_acc: 0.8113 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 154 | train_loss: 0.3060 | train_acc: 0.8811 | test_loss: 0.6880 | test_acc: 0.7888 | \nEpoch: 155 | train_loss: 0.2994 | train_acc: 0.8801 | test_loss: 0.6397 | test_acc: 0.8063 | \nEpoch: 156 | train_loss: 0.2993 | train_acc: 0.8842 | test_loss: 0.6620 | test_acc: 0.7978 | \nEpoch: 157 | train_loss: 0.2825 | train_acc: 0.8907 | test_loss: 0.6859 | test_acc: 0.8003 | \nEpoch: 158 | train_loss: 0.2741 | train_acc: 0.8940 | test_loss: 0.6921 | test_acc: 0.7898 | \nEpoch: 159 | train_loss: 0.2985 | train_acc: 0.8810 | test_loss: 0.6716 | test_acc: 0.8003 | \nEpoch: 160 | train_loss: 0.2801 | train_acc: 0.8906 | test_loss: 0.7472 | test_acc: 0.7968 | \nEpoch: 161 | train_loss: 0.2855 | train_acc: 0.8866 | test_loss: 0.7056 | test_acc: 0.8003 | \nEpoch: 162 | train_loss: 0.2850 | train_acc: 0.8899 | test_loss: 0.7102 | test_acc: 0.7938 | \nEpoch: 163 | train_loss: 0.3026 | train_acc: 0.8816 | test_loss: 0.7030 | test_acc: 0.7858 | \nEpoch: 164 | train_loss: 0.2719 | train_acc: 0.8947 | test_loss: 0.7051 | test_acc: 0.8038 | \nEpoch: 165 | train_loss: 0.2821 | train_acc: 0.8925 | test_loss: 0.7088 | test_acc: 0.7983 | \nEpoch: 166 | train_loss: 0.2800 | train_acc: 0.8945 | test_loss: 0.8068 | test_acc: 0.7838 | \nEpoch: 167 | train_loss: 0.2899 | train_acc: 0.8892 | test_loss: 0.6656 | test_acc: 0.8003 | \nEpoch: 168 | train_loss: 0.2745 | train_acc: 0.8924 | test_loss: 0.7865 | test_acc: 0.7883 | \nEpoch: 169 | train_loss: 0.2707 | train_acc: 0.8942 | test_loss: 0.6930 | test_acc: 0.8058 | \nEpoch: 170 | train_loss: 0.2832 | train_acc: 0.8921 | test_loss: 0.6800 | test_acc: 0.7983 | \nEpoch: 171 | train_loss: 0.2825 | train_acc: 0.8901 | test_loss: 0.7331 | test_acc: 0.7873 | \nEpoch: 172 | train_loss: 0.2645 | train_acc: 0.8996 | test_loss: 0.7877 | test_acc: 0.7988 | \nEpoch: 173 | train_loss: 0.2639 | train_acc: 0.8943 | test_loss: 0.7239 | test_acc: 0.7928 | \nEpoch: 174 | train_loss: 0.2821 | train_acc: 0.8920 | test_loss: 0.6798 | test_acc: 0.7943 | \nEpoch: 175 | train_loss: 0.2735 | train_acc: 0.8937 | test_loss: 0.6527 | test_acc: 0.8058 | \nEpoch: 176 | train_loss: 0.2736 | train_acc: 0.8930 | test_loss: 0.7917 | test_acc: 0.7818 | \nEpoch: 177 | train_loss: 0.2674 | train_acc: 0.8991 | test_loss: 0.7197 | test_acc: 0.8018 | \nEpoch: 178 | train_loss: 0.2489 | train_acc: 0.9016 | test_loss: 0.7096 | test_acc: 0.7968 | \nEpoch: 179 | train_loss: 0.2700 | train_acc: 0.8963 | test_loss: 0.6968 | test_acc: 0.8013 | \nEpoch: 180 | train_loss: 0.2775 | train_acc: 0.8931 | test_loss: 0.7347 | test_acc: 0.7813 | \nEpoch: 181 | train_loss: 0.2795 | train_acc: 0.8922 | test_loss: 0.6829 | test_acc: 0.7983 | \nEpoch: 182 | train_loss: 0.2626 | train_acc: 0.8983 | test_loss: 0.7022 | test_acc: 0.8108 | \nEpoch: 183 | train_loss: 0.2716 | train_acc: 0.8983 | test_loss: 0.6733 | test_acc: 0.8078 | \nEpoch: 184 | train_loss: 0.2680 | train_acc: 0.8980 | test_loss: 0.6930 | test_acc: 0.7983 | \nEpoch: 185 | train_loss: 0.2624 | train_acc: 0.8975 | test_loss: 0.7792 | test_acc: 0.7908 | \nEpoch: 186 | train_loss: 0.2556 | train_acc: 0.9021 | test_loss: 0.6803 | test_acc: 0.8063 | \nEpoch: 187 | train_loss: 0.2471 | train_acc: 0.9043 | test_loss: 0.7563 | test_acc: 0.7903 | \nEpoch: 188 | train_loss: 0.2588 | train_acc: 0.9018 | test_loss: 0.7225 | test_acc: 0.7878 | \nEpoch: 189 | train_loss: 0.2552 | train_acc: 0.9021 | test_loss: 0.7448 | test_acc: 0.7968 | \nEpoch: 190 | train_loss: 0.2590 | train_acc: 0.9016 | test_loss: 0.7129 | test_acc: 0.7953 | \nEpoch: 191 | train_loss: 0.2543 | train_acc: 0.9023 | test_loss: 0.7065 | test_acc: 0.8048 | \nEpoch: 192 | train_loss: 0.2354 | train_acc: 0.9122 | test_loss: 0.7633 | test_acc: 0.7928 | \n\nAccuracy Improved (0.8113113113113113 to 0.8123123123123123), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.76      0.73      0.74       262\n         bcc       0.84      0.85      0.85       412\n         bkl       0.81      0.80      0.81       880\n          df       0.85      0.88      0.86        93\n         mel       0.79      0.74      0.76       891\n          nv       0.95      0.96      0.96      5365\n        vasc       0.96      0.96      0.96       114\n\n    accuracy                           0.91      8017\n   macro avg       0.85      0.85      0.85      8017\nweighted avg       0.90      0.91      0.90      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.54      0.51      0.52        65\n         bcc       0.55      0.64      0.59       102\n         bkl       0.61      0.59      0.60       219\n          df       0.56      0.45      0.50        22\n         mel       0.65      0.53      0.58       222\n          nv       0.90      0.93      0.92      1340\n        vasc       1.00      0.71      0.83        28\n\n    accuracy                           0.81      1998\n   macro avg       0.69      0.62      0.65      1998\nweighted avg       0.81      0.81      0.81      1998\n\nEpoch: 193 | train_loss: 0.2413 | train_acc: 0.9052 | test_loss: 0.7097 | test_acc: 0.8123 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 194 | train_loss: 0.2547 | train_acc: 0.9006 | test_loss: 0.7398 | test_acc: 0.8048 | \nEpoch: 195 | train_loss: 0.2512 | train_acc: 0.9035 | test_loss: 0.7383 | test_acc: 0.8043 | \nEpoch: 196 | train_loss: 0.2454 | train_acc: 0.9050 | test_loss: 0.7300 | test_acc: 0.8038 | \nEpoch: 197 | train_loss: 0.2443 | train_acc: 0.9050 | test_loss: 0.7540 | test_acc: 0.7998 | \nEpoch: 198 | train_loss: 0.2432 | train_acc: 0.9081 | test_loss: 0.7220 | test_acc: 0.7968 | \nEpoch: 199 | train_loss: 0.2473 | train_acc: 0.9040 | test_loss: 0.7682 | test_acc: 0.7923 | \nEpoch: 200 | train_loss: 0.2268 | train_acc: 0.9112 | test_loss: 0.7418 | test_acc: 0.7888 | \nEpoch: 201 | train_loss: 0.2202 | train_acc: 0.9152 | test_loss: 0.7854 | test_acc: 0.7818 | \nEpoch: 202 | train_loss: 0.2209 | train_acc: 0.9163 | test_loss: 0.7453 | test_acc: 0.8003 | \nEpoch: 203 | train_loss: 0.2274 | train_acc: 0.9113 | test_loss: 0.7899 | test_acc: 0.7958 | \nEpoch: 204 | train_loss: 0.2180 | train_acc: 0.9169 | test_loss: 0.7661 | test_acc: 0.7963 | \nEpoch: 205 | train_loss: 0.2284 | train_acc: 0.9154 | test_loss: 0.7601 | test_acc: 0.7978 | \nEpoch: 206 | train_loss: 0.2515 | train_acc: 0.9042 | test_loss: 0.7302 | test_acc: 0.8123 | \nEpoch: 207 | train_loss: 0.2219 | train_acc: 0.9187 | test_loss: 0.7238 | test_acc: 0.8108 | \nEpoch: 208 | train_loss: 0.2265 | train_acc: 0.9139 | test_loss: 0.7702 | test_acc: 0.8043 | \nEpoch: 209 | train_loss: 0.2225 | train_acc: 0.9168 | test_loss: 0.8115 | test_acc: 0.8053 | \nEpoch: 210 | train_loss: 0.2300 | train_acc: 0.9152 | test_loss: 0.7292 | test_acc: 0.8053 | \nEpoch: 211 | train_loss: 0.2141 | train_acc: 0.9200 | test_loss: 0.8090 | test_acc: 0.8008 | \nEpoch: 212 | train_loss: 0.2196 | train_acc: 0.9161 | test_loss: 0.7613 | test_acc: 0.7833 | \nEpoch: 213 | train_loss: 0.2134 | train_acc: 0.9185 | test_loss: 0.7597 | test_acc: 0.7993 | \nEpoch: 214 | train_loss: 0.2161 | train_acc: 0.9178 | test_loss: 0.7198 | test_acc: 0.7988 | \n\nAccuracy Improved (0.8123123123123123 to 0.8133133133133134), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.82      0.79      0.80       262\n         bcc       0.88      0.88      0.88       412\n         bkl       0.80      0.81      0.81       880\n          df       0.85      0.84      0.84        93\n         mel       0.82      0.76      0.79       891\n          nv       0.95      0.97      0.96      5365\n        vasc       0.96      0.95      0.96       114\n\n    accuracy                           0.91      8017\n   macro avg       0.87      0.86      0.86      8017\nweighted avg       0.91      0.91      0.91      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.71      0.49      0.58        65\n         bcc       0.68      0.64      0.66       102\n         bkl       0.72      0.45      0.56       219\n          df       0.48      0.68      0.57        22\n         mel       0.57      0.53      0.55       222\n          nv       0.88      0.95      0.91      1340\n        vasc       0.83      0.86      0.84        28\n\n    accuracy                           0.81      1998\n   macro avg       0.70      0.66      0.67      1998\nweighted avg       0.80      0.81      0.80      1998\n\nEpoch: 215 | train_loss: 0.2243 | train_acc: 0.9138 | test_loss: 0.7948 | test_acc: 0.8133 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 216 | train_loss: 0.2083 | train_acc: 0.9194 | test_loss: 0.8024 | test_acc: 0.7978 | \nEpoch: 217 | train_loss: 0.2211 | train_acc: 0.9154 | test_loss: 0.7718 | test_acc: 0.7953 | \nEpoch: 218 | train_loss: 0.2255 | train_acc: 0.9149 | test_loss: 0.7624 | test_acc: 0.8043 | \nEpoch: 219 | train_loss: 0.2327 | train_acc: 0.9114 | test_loss: 0.8162 | test_acc: 0.7933 | \nEpoch: 220 | train_loss: 0.2156 | train_acc: 0.9180 | test_loss: 0.7456 | test_acc: 0.8018 | \nEpoch: 221 | train_loss: 0.2117 | train_acc: 0.9189 | test_loss: 0.7623 | test_acc: 0.8013 | \nEpoch: 222 | train_loss: 0.2206 | train_acc: 0.9180 | test_loss: 0.7651 | test_acc: 0.7853 | \nEpoch: 223 | train_loss: 0.2177 | train_acc: 0.9163 | test_loss: 0.7687 | test_acc: 0.8008 | \nEpoch: 224 | train_loss: 0.2039 | train_acc: 0.9237 | test_loss: 0.7625 | test_acc: 0.8073 | \nEpoch: 225 | train_loss: 0.1990 | train_acc: 0.9243 | test_loss: 0.9461 | test_acc: 0.7773 | \nEpoch: 226 | train_loss: 0.2107 | train_acc: 0.9214 | test_loss: 0.7029 | test_acc: 0.8078 | \nEpoch: 227 | train_loss: 0.1943 | train_acc: 0.9287 | test_loss: 0.7712 | test_acc: 0.7918 | \nEpoch: 228 | train_loss: 0.2114 | train_acc: 0.9198 | test_loss: 0.8540 | test_acc: 0.7778 | \nEpoch: 229 | train_loss: 0.2017 | train_acc: 0.9223 | test_loss: 0.7225 | test_acc: 0.8118 | \nEpoch: 230 | train_loss: 0.1948 | train_acc: 0.9235 | test_loss: 0.8015 | test_acc: 0.7838 | \nEpoch: 231 | train_loss: 0.1992 | train_acc: 0.9222 | test_loss: 0.8515 | test_acc: 0.7733 | \nEpoch: 232 | train_loss: 0.2265 | train_acc: 0.9122 | test_loss: 0.7801 | test_acc: 0.7988 | \nEpoch: 233 | train_loss: 0.1974 | train_acc: 0.9243 | test_loss: 0.7982 | test_acc: 0.7908 | \nEpoch: 234 | train_loss: 0.1921 | train_acc: 0.9260 | test_loss: 0.7910 | test_acc: 0.7988 | \nEpoch: 235 | train_loss: 0.1929 | train_acc: 0.9268 | test_loss: 0.7616 | test_acc: 0.7923 | \nEpoch: 236 | train_loss: 0.1930 | train_acc: 0.9314 | test_loss: 0.7550 | test_acc: 0.8053 | \nEpoch: 237 | train_loss: 0.1857 | train_acc: 0.9283 | test_loss: 0.7318 | test_acc: 0.8023 | \nEpoch: 238 | train_loss: 0.1976 | train_acc: 0.9264 | test_loss: 0.8194 | test_acc: 0.7903 | \nEpoch: 239 | train_loss: 0.1982 | train_acc: 0.9252 | test_loss: 0.8112 | test_acc: 0.7973 | \nEpoch: 240 | train_loss: 0.1886 | train_acc: 0.9260 | test_loss: 0.7712 | test_acc: 0.7993 | \nEpoch: 241 | train_loss: 0.1769 | train_acc: 0.9319 | test_loss: 0.7673 | test_acc: 0.8023 | \nEpoch: 242 | train_loss: 0.1752 | train_acc: 0.9328 | test_loss: 0.8443 | test_acc: 0.7838 | \nEpoch: 243 | train_loss: 0.1824 | train_acc: 0.9288 | test_loss: 0.7675 | test_acc: 0.8103 | \nEpoch: 244 | train_loss: 0.1986 | train_acc: 0.9240 | test_loss: 0.7949 | test_acc: 0.8048 | \nEpoch: 245 | train_loss: 0.1970 | train_acc: 0.9284 | test_loss: 0.8080 | test_acc: 0.7953 | \nEpoch: 246 | train_loss: 0.1900 | train_acc: 0.9284 | test_loss: 0.8578 | test_acc: 0.7833 | \nEpoch: 247 | train_loss: 0.1967 | train_acc: 0.9282 | test_loss: 0.7523 | test_acc: 0.8008 | \nEpoch: 248 | train_loss: 0.1772 | train_acc: 0.9309 | test_loss: 0.7682 | test_acc: 0.7998 | \nEpoch: 249 | train_loss: 0.1827 | train_acc: 0.9321 | test_loss: 0.8132 | test_acc: 0.8013 | \nEpoch: 250 | train_loss: 0.1973 | train_acc: 0.9265 | test_loss: 0.7665 | test_acc: 0.7898 | \n\nAccuracy Improved (0.8133133133133134 to 0.8143143143143143), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.86      0.84      0.85       262\n         bcc       0.89      0.91      0.90       412\n         bkl       0.85      0.86      0.85       880\n          df       0.91      0.90      0.91        93\n         mel       0.83      0.81      0.82       891\n          nv       0.96      0.97      0.97      5365\n        vasc       0.97      0.96      0.97       114\n\n    accuracy                           0.93      8017\n   macro avg       0.90      0.89      0.90      8017\nweighted avg       0.93      0.93      0.93      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.74      0.48      0.58        65\n         bcc       0.62      0.67      0.64       102\n         bkl       0.58      0.61      0.60       219\n          df       0.47      0.64      0.54        22\n         mel       0.61      0.51      0.55       222\n          nv       0.91      0.93      0.92      1340\n        vasc       0.73      0.79      0.76        28\n\n    accuracy                           0.81      1998\n   macro avg       0.67      0.66      0.66      1998\nweighted avg       0.81      0.81      0.81      1998\n\nEpoch: 251 | train_loss: 0.1858 | train_acc: 0.9294 | test_loss: 0.7603 | test_acc: 0.8143 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 252 | train_loss: 0.1697 | train_acc: 0.9359 | test_loss: 0.8727 | test_acc: 0.7858 | \nEpoch: 253 | train_loss: 0.1623 | train_acc: 0.9383 | test_loss: 0.8291 | test_acc: 0.7998 | \nEpoch: 254 | train_loss: 0.1914 | train_acc: 0.9274 | test_loss: 0.8153 | test_acc: 0.8023 | \nEpoch: 255 | train_loss: 0.1837 | train_acc: 0.9299 | test_loss: 0.8469 | test_acc: 0.8048 | \nEpoch: 256 | train_loss: 0.1827 | train_acc: 0.9329 | test_loss: 0.8015 | test_acc: 0.7933 | \nEpoch: 257 | train_loss: 0.1876 | train_acc: 0.9304 | test_loss: 0.8066 | test_acc: 0.8088 | \nEpoch: 258 | train_loss: 0.1911 | train_acc: 0.9304 | test_loss: 0.7770 | test_acc: 0.8103 | \nEpoch: 259 | train_loss: 0.1681 | train_acc: 0.9365 | test_loss: 0.7779 | test_acc: 0.8033 | \nEpoch: 260 | train_loss: 0.1629 | train_acc: 0.9378 | test_loss: 0.8560 | test_acc: 0.7688 | \nEpoch: 261 | train_loss: 0.1658 | train_acc: 0.9390 | test_loss: 0.8981 | test_acc: 0.7998 | \nEpoch: 262 | train_loss: 0.1702 | train_acc: 0.9338 | test_loss: 0.8190 | test_acc: 0.8063 | \nEpoch: 263 | train_loss: 0.1774 | train_acc: 0.9331 | test_loss: 0.9481 | test_acc: 0.8003 | \nEpoch: 264 | train_loss: 0.1603 | train_acc: 0.9381 | test_loss: 0.8376 | test_acc: 0.7928 | \nEpoch: 265 | train_loss: 0.1848 | train_acc: 0.9295 | test_loss: 0.7950 | test_acc: 0.8008 | \nEpoch: 266 | train_loss: 0.1709 | train_acc: 0.9369 | test_loss: 0.8602 | test_acc: 0.7988 | \nEpoch: 267 | train_loss: 0.1568 | train_acc: 0.9430 | test_loss: 0.9084 | test_acc: 0.8033 | \nEpoch: 268 | train_loss: 0.1731 | train_acc: 0.9365 | test_loss: 0.8156 | test_acc: 0.7803 | \nEpoch: 269 | train_loss: 0.1531 | train_acc: 0.9403 | test_loss: 0.8792 | test_acc: 0.8113 | \nEpoch: 270 | train_loss: 0.1758 | train_acc: 0.9353 | test_loss: 0.8278 | test_acc: 0.7953 | \nEpoch: 271 | train_loss: 0.1704 | train_acc: 0.9338 | test_loss: 0.8159 | test_acc: 0.8013 | \nEpoch: 272 | train_loss: 0.1689 | train_acc: 0.9359 | test_loss: 0.8212 | test_acc: 0.8013 | \nEpoch: 273 | train_loss: 0.1481 | train_acc: 0.9427 | test_loss: 0.8766 | test_acc: 0.8063 | \nEpoch: 274 | train_loss: 0.1607 | train_acc: 0.9386 | test_loss: 0.7875 | test_acc: 0.8108 | \nEpoch: 275 | train_loss: 0.1703 | train_acc: 0.9320 | test_loss: 0.8393 | test_acc: 0.7958 | \nEpoch: 276 | train_loss: 0.1728 | train_acc: 0.9354 | test_loss: 0.8623 | test_acc: 0.7983 | \nEpoch: 277 | train_loss: 0.1758 | train_acc: 0.9306 | test_loss: 0.7618 | test_acc: 0.8078 | \nEpoch: 278 | train_loss: 0.1449 | train_acc: 0.9447 | test_loss: 0.8489 | test_acc: 0.8063 | \nEpoch: 279 | train_loss: 0.1654 | train_acc: 0.9404 | test_loss: 0.9006 | test_acc: 0.7908 | \n\nAccuracy Improved (0.8143143143143143 to 0.8198198198198198), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.82      0.82      0.82       262\n         bcc       0.89      0.89      0.89       412\n         bkl       0.88      0.88      0.88       880\n          df       0.87      0.89      0.88        93\n         mel       0.84      0.81      0.83       891\n          nv       0.96      0.97      0.97      5365\n        vasc       0.91      0.89      0.90       114\n\n    accuracy                           0.93      8017\n   macro avg       0.88      0.88      0.88      8017\nweighted avg       0.93      0.93      0.93      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.57      0.43      0.49        65\n         bcc       0.60      0.67      0.63       102\n         bkl       0.61      0.63      0.62       219\n          df       0.57      0.59      0.58        22\n         mel       0.70      0.47      0.56       222\n          nv       0.90      0.94      0.92      1340\n        vasc       0.77      0.86      0.81        28\n\n    accuracy                           0.82      1998\n   macro avg       0.67      0.66      0.66      1998\nweighted avg       0.81      0.82      0.81      1998\n\nEpoch: 280 | train_loss: 0.1838 | train_acc: 0.9304 | test_loss: 0.7599 | test_acc: 0.8198 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 281 | train_loss: 0.1594 | train_acc: 0.9394 | test_loss: 0.7685 | test_acc: 0.8023 | \nEpoch: 282 | train_loss: 0.1557 | train_acc: 0.9426 | test_loss: 0.8158 | test_acc: 0.8063 | \nEpoch: 283 | train_loss: 0.1553 | train_acc: 0.9430 | test_loss: 0.8435 | test_acc: 0.8088 | \nEpoch: 284 | train_loss: 0.1641 | train_acc: 0.9409 | test_loss: 0.8911 | test_acc: 0.7708 | \nEpoch: 285 | train_loss: 0.1429 | train_acc: 0.9474 | test_loss: 0.8542 | test_acc: 0.7983 | \nEpoch: 286 | train_loss: 0.1564 | train_acc: 0.9441 | test_loss: 0.8398 | test_acc: 0.7933 | \nEpoch: 287 | train_loss: 0.1964 | train_acc: 0.9253 | test_loss: 0.8713 | test_acc: 0.7968 | \nEpoch: 288 | train_loss: 0.1715 | train_acc: 0.9360 | test_loss: 0.7632 | test_acc: 0.8063 | \nEpoch: 289 | train_loss: 0.1667 | train_acc: 0.9401 | test_loss: 0.7627 | test_acc: 0.8113 | \nEpoch: 290 | train_loss: 0.1627 | train_acc: 0.9400 | test_loss: 0.8894 | test_acc: 0.7938 | \nEpoch: 291 | train_loss: 0.1551 | train_acc: 0.9415 | test_loss: 0.8552 | test_acc: 0.8028 | \nEpoch: 292 | train_loss: 0.1530 | train_acc: 0.9435 | test_loss: 0.8458 | test_acc: 0.7978 | \nEpoch: 293 | train_loss: 0.1666 | train_acc: 0.9389 | test_loss: 0.8689 | test_acc: 0.8023 | \nEpoch: 294 | train_loss: 0.1530 | train_acc: 0.9414 | test_loss: 0.7973 | test_acc: 0.7993 | \nEpoch: 295 | train_loss: 0.1524 | train_acc: 0.9451 | test_loss: 0.8194 | test_acc: 0.8028 | \nEpoch: 296 | train_loss: 0.1542 | train_acc: 0.9416 | test_loss: 0.7909 | test_acc: 0.7898 | \nEpoch: 297 | train_loss: 0.1673 | train_acc: 0.9395 | test_loss: 0.8316 | test_acc: 0.7973 | \nEpoch: 298 | train_loss: 0.1488 | train_acc: 0.9474 | test_loss: 0.8563 | test_acc: 0.8013 | \nEpoch: 299 | train_loss: 0.1416 | train_acc: 0.9476 | test_loss: 0.8146 | test_acc: 0.7993 | \nEpoch: 300 | train_loss: 0.1223 | train_acc: 0.9548 | test_loss: 0.9456 | test_acc: 0.7953 | \nEpoch: 301 | train_loss: 0.1541 | train_acc: 0.9440 | test_loss: 0.8370 | test_acc: 0.7988 | \nEpoch: 302 | train_loss: 0.1363 | train_acc: 0.9450 | test_loss: 0.8135 | test_acc: 0.8173 | \nEpoch: 303 | train_loss: 0.1540 | train_acc: 0.9446 | test_loss: 0.7757 | test_acc: 0.8033 | \nEpoch: 304 | train_loss: 0.1505 | train_acc: 0.9456 | test_loss: 0.9419 | test_acc: 0.7963 | \nEpoch: 305 | train_loss: 0.1364 | train_acc: 0.9496 | test_loss: 0.8704 | test_acc: 0.7928 | \nEpoch: 306 | train_loss: 0.1478 | train_acc: 0.9422 | test_loss: 0.8356 | test_acc: 0.7988 | \nEpoch: 307 | train_loss: 0.1402 | train_acc: 0.9492 | test_loss: 0.8000 | test_acc: 0.8063 | \nEpoch: 308 | train_loss: 0.1556 | train_acc: 0.9416 | test_loss: 0.8177 | test_acc: 0.8098 | \nEpoch: 309 | train_loss: 0.1617 | train_acc: 0.9403 | test_loss: 0.8191 | test_acc: 0.8043 | \nEpoch: 310 | train_loss: 0.1531 | train_acc: 0.9426 | test_loss: 0.9335 | test_acc: 0.8018 | \nEpoch: 311 | train_loss: 0.1567 | train_acc: 0.9430 | test_loss: 0.8152 | test_acc: 0.8093 | \nEpoch: 312 | train_loss: 0.1448 | train_acc: 0.9467 | test_loss: 0.7966 | test_acc: 0.8133 | \nEpoch: 313 | train_loss: 0.1644 | train_acc: 0.9386 | test_loss: 0.8721 | test_acc: 0.7938 | \nEpoch: 314 | train_loss: 0.1495 | train_acc: 0.9422 | test_loss: 0.7452 | test_acc: 0.7988 | \nEpoch: 315 | train_loss: 0.1385 | train_acc: 0.9500 | test_loss: 0.8451 | test_acc: 0.8068 | \nEpoch: 316 | train_loss: 0.1603 | train_acc: 0.9424 | test_loss: 0.7523 | test_acc: 0.8033 | \nEpoch: 317 | train_loss: 0.1415 | train_acc: 0.9480 | test_loss: 0.8318 | test_acc: 0.8108 | \nEpoch: 318 | train_loss: 0.1538 | train_acc: 0.9415 | test_loss: 0.8616 | test_acc: 0.8023 | \nEpoch: 319 | train_loss: 0.1744 | train_acc: 0.9330 | test_loss: 0.7985 | test_acc: 0.8063 | \nEpoch: 320 | train_loss: 0.1487 | train_acc: 0.9427 | test_loss: 0.7754 | test_acc: 0.8033 | \nEpoch: 321 | train_loss: 0.1242 | train_acc: 0.9520 | test_loss: 0.8506 | test_acc: 0.8113 | \nEpoch: 322 | train_loss: 0.1249 | train_acc: 0.9517 | test_loss: 0.9211 | test_acc: 0.7998 | \nEpoch: 323 | train_loss: 0.1430 | train_acc: 0.9465 | test_loss: 0.9517 | test_acc: 0.7848 | \nEpoch: 324 | train_loss: 0.1336 | train_acc: 0.9501 | test_loss: 0.8742 | test_acc: 0.8038 | \nEpoch: 325 | train_loss: 0.1358 | train_acc: 0.9507 | test_loss: 0.8567 | test_acc: 0.8088 | \nEpoch: 326 | train_loss: 0.1247 | train_acc: 0.9570 | test_loss: 0.8058 | test_acc: 0.8118 | \nEpoch: 327 | train_loss: 0.1406 | train_acc: 0.9500 | test_loss: 0.8278 | test_acc: 0.8108 | \nEpoch: 328 | train_loss: 0.1636 | train_acc: 0.9384 | test_loss: 0.8423 | test_acc: 0.8158 | \nEpoch: 329 | train_loss: 0.1276 | train_acc: 0.9522 | test_loss: 0.8218 | test_acc: 0.8068 | \nEpoch: 330 | train_loss: 0.1299 | train_acc: 0.9536 | test_loss: 0.8276 | test_acc: 0.8023 | \nEpoch: 331 | train_loss: 0.1427 | train_acc: 0.9456 | test_loss: 0.8169 | test_acc: 0.8098 | \nEpoch: 332 | train_loss: 0.1321 | train_acc: 0.9509 | test_loss: 0.9279 | test_acc: 0.8003 | \nEpoch: 333 | train_loss: 0.1443 | train_acc: 0.9492 | test_loss: 0.7944 | test_acc: 0.8108 | \nEpoch: 334 | train_loss: 0.1265 | train_acc: 0.9512 | test_loss: 0.8811 | test_acc: 0.8018 | \nEpoch: 335 | train_loss: 0.1322 | train_acc: 0.9514 | test_loss: 0.8893 | test_acc: 0.8023 | \nEpoch: 336 | train_loss: 0.1324 | train_acc: 0.9510 | test_loss: 0.8366 | test_acc: 0.8143 | \nEpoch: 337 | train_loss: 0.1271 | train_acc: 0.9538 | test_loss: 0.8575 | test_acc: 0.8123 | \nEpoch: 338 | train_loss: 0.1502 | train_acc: 0.9429 | test_loss: 0.8172 | test_acc: 0.8038 | \nEpoch: 339 | train_loss: 0.1429 | train_acc: 0.9496 | test_loss: 0.8156 | test_acc: 0.8033 | \nEpoch: 340 | train_loss: 0.1169 | train_acc: 0.9582 | test_loss: 0.7928 | test_acc: 0.8158 | \nEpoch: 341 | train_loss: 0.1224 | train_acc: 0.9553 | test_loss: 0.9645 | test_acc: 0.8118 | \nEpoch: 342 | train_loss: 0.1303 | train_acc: 0.9509 | test_loss: 0.9798 | test_acc: 0.7953 | \nEpoch: 343 | train_loss: 0.1368 | train_acc: 0.9495 | test_loss: 0.8529 | test_acc: 0.7998 | \nEpoch: 344 | train_loss: 0.1388 | train_acc: 0.9482 | test_loss: 0.7927 | test_acc: 0.8118 | \nEpoch: 345 | train_loss: 0.1000 | train_acc: 0.9653 | test_loss: 0.8787 | test_acc: 0.7988 | \nEpoch: 346 | train_loss: 0.1205 | train_acc: 0.9573 | test_loss: 0.9535 | test_acc: 0.8173 | \nEpoch: 347 | train_loss: 0.1379 | train_acc: 0.9504 | test_loss: 0.8365 | test_acc: 0.8053 | \nEpoch: 348 | train_loss: 0.1361 | train_acc: 0.9548 | test_loss: 0.9114 | test_acc: 0.7963 | \n\nAccuracy Improved (0.8198198198198198 to 0.8233233233233234), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.87      0.87      0.87       262\n         bcc       0.93      0.92      0.93       412\n         bkl       0.88      0.88      0.88       880\n          df       0.92      0.90      0.91        93\n         mel       0.89      0.88      0.88       891\n          nv       0.97      0.98      0.98      5365\n        vasc       0.96      0.96      0.96       114\n\n    accuracy                           0.95      8017\n   macro avg       0.92      0.91      0.92      8017\nweighted avg       0.95      0.95      0.95      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.63      0.52      0.57        65\n         bcc       0.66      0.59      0.62       102\n         bkl       0.63      0.58      0.60       219\n          df       0.52      0.55      0.53        22\n         mel       0.65      0.57      0.61       222\n          nv       0.90      0.94      0.92      1340\n        vasc       0.81      0.79      0.80        28\n\n    accuracy                           0.82      1998\n   macro avg       0.69      0.65      0.67      1998\nweighted avg       0.81      0.82      0.82      1998\n\nEpoch: 349 | train_loss: 0.1370 | train_acc: 0.9485 | test_loss: 0.8071 | test_acc: 0.8233 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 350 | train_loss: 0.1309 | train_acc: 0.9530 | test_loss: 0.8025 | test_acc: 0.8148 | \n\nAccuracy Improved (0.8233233233233234 to 0.8268268268268268), Saving the model...............................................\n\nEvaluation report on Train data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.86      0.87      0.87       262\n         bcc       0.92      0.92      0.92       412\n         bkl       0.89      0.90      0.90       880\n          df       0.87      0.88      0.88        93\n         mel       0.90      0.87      0.89       891\n          nv       0.98      0.98      0.98      5365\n        vasc       0.94      0.90      0.92       114\n\n    accuracy                           0.95      8017\n   macro avg       0.91      0.90      0.91      8017\nweighted avg       0.95      0.95      0.95      8017\n\n\n\n\n\nEvaluation report on Test data: \n\n              precision    recall  f1-score   support\n\n       akiec       0.58      0.57      0.57        65\n         bcc       0.66      0.63      0.64       102\n         bkl       0.62      0.65      0.64       219\n          df       0.57      0.59      0.58        22\n         mel       0.67      0.58      0.62       222\n          nv       0.91      0.93      0.92      1340\n        vasc       0.85      0.79      0.81        28\n\n    accuracy                           0.83      1998\n   macro avg       0.69      0.68      0.68      1998\nweighted avg       0.82      0.83      0.82      1998\n\nEpoch: 351 | train_loss: 0.1327 | train_acc: 0.9507 | test_loss: 0.7813 | test_acc: 0.8268 | \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 352 | train_loss: 0.1243 | train_acc: 0.9524 | test_loss: 0.8762 | test_acc: 0.8083 | \nEpoch: 353 | train_loss: 0.1034 | train_acc: 0.9636 | test_loss: 0.9393 | test_acc: 0.8028 | \nEpoch: 354 | train_loss: 0.1237 | train_acc: 0.9519 | test_loss: 0.9533 | test_acc: 0.8078 | \nEpoch: 355 | train_loss: 0.1571 | train_acc: 0.9404 | test_loss: 0.8286 | test_acc: 0.7913 | \nEpoch: 356 | train_loss: 0.1453 | train_acc: 0.9464 | test_loss: 0.8011 | test_acc: 0.8103 | \nEpoch: 357 | train_loss: 0.1364 | train_acc: 0.9471 | test_loss: 0.8692 | test_acc: 0.8123 | \nEpoch: 358 | train_loss: 0.1357 | train_acc: 0.9505 | test_loss: 0.7804 | test_acc: 0.8128 | \nEpoch: 359 | train_loss: 0.1164 | train_acc: 0.9591 | test_loss: 0.8540 | test_acc: 0.8078 | \nEpoch: 360 | train_loss: 0.1099 | train_acc: 0.9595 | test_loss: 0.8627 | test_acc: 0.8168 | \nEpoch: 361 | train_loss: 0.1287 | train_acc: 0.9524 | test_loss: 0.9650 | test_acc: 0.8028 | \nEpoch: 362 | train_loss: 0.1274 | train_acc: 0.9531 | test_loss: 0.8254 | test_acc: 0.8078 | \nEpoch: 363 | train_loss: 0.1171 | train_acc: 0.9532 | test_loss: 1.1306 | test_acc: 0.7923 | \nEpoch: 364 | train_loss: 0.1129 | train_acc: 0.9571 | test_loss: 0.8677 | test_acc: 0.8068 | \nEpoch: 365 | train_loss: 0.1400 | train_acc: 0.9514 | test_loss: 0.8615 | test_acc: 0.8123 | \nEpoch: 366 | train_loss: 0.1201 | train_acc: 0.9558 | test_loss: 0.9402 | test_acc: 0.7968 | \nEpoch: 367 | train_loss: 0.1086 | train_acc: 0.9590 | test_loss: 0.9661 | test_acc: 0.7933 | \nEpoch: 368 | train_loss: 0.1190 | train_acc: 0.9565 | test_loss: 0.8159 | test_acc: 0.8118 | \nEpoch: 369 | train_loss: 0.1132 | train_acc: 0.9577 | test_loss: 0.8632 | test_acc: 0.8193 | \nEpoch: 370 | train_loss: 0.1174 | train_acc: 0.9572 | test_loss: 1.0334 | test_acc: 0.7923 | \nEpoch: 371 | train_loss: 0.1152 | train_acc: 0.9573 | test_loss: 0.8523 | test_acc: 0.8123 | \nEpoch: 372 | train_loss: 0.0930 | train_acc: 0.9661 | test_loss: 0.9599 | test_acc: 0.8108 | \nEpoch: 373 | train_loss: 0.1165 | train_acc: 0.9565 | test_loss: 0.9847 | test_acc: 0.7908 | \nEpoch: 374 | train_loss: 0.1273 | train_acc: 0.9526 | test_loss: 0.8864 | test_acc: 0.8098 | \nEpoch: 375 | train_loss: 0.1202 | train_acc: 0.9568 | test_loss: 0.8950 | test_acc: 0.8013 | \nEpoch: 376 | train_loss: 0.1117 | train_acc: 0.9603 | test_loss: 0.8600 | test_acc: 0.8133 | \nEpoch: 377 | train_loss: 0.1230 | train_acc: 0.9515 | test_loss: 0.8549 | test_acc: 0.7983 | \nEpoch: 378 | train_loss: 0.1189 | train_acc: 0.9550 | test_loss: 0.8756 | test_acc: 0.8098 | \nEpoch: 379 | train_loss: 0.1105 | train_acc: 0.9605 | test_loss: 0.9352 | test_acc: 0.7958 | \nEpoch: 380 | train_loss: 0.0937 | train_acc: 0.9661 | test_loss: 0.9233 | test_acc: 0.7948 | \nEpoch: 381 | train_loss: 0.1143 | train_acc: 0.9587 | test_loss: 0.9321 | test_acc: 0.8173 | \nEpoch: 382 | train_loss: 0.1166 | train_acc: 0.9590 | test_loss: 0.8693 | test_acc: 0.8083 | \nEpoch: 383 | train_loss: 0.1260 | train_acc: 0.9535 | test_loss: 0.9496 | test_acc: 0.7888 | \nEpoch: 384 | train_loss: 0.1264 | train_acc: 0.9556 | test_loss: 0.9109 | test_acc: 0.8063 | \nEpoch: 385 | train_loss: 0.1057 | train_acc: 0.9617 | test_loss: 0.9475 | test_acc: 0.8008 | \nEpoch: 386 | train_loss: 0.1070 | train_acc: 0.9648 | test_loss: 0.9305 | test_acc: 0.8053 | \nEpoch: 387 | train_loss: 0.1181 | train_acc: 0.9577 | test_loss: 1.0065 | test_acc: 0.7963 | \nEpoch: 388 | train_loss: 0.1188 | train_acc: 0.9550 | test_loss: 0.9625 | test_acc: 0.7843 | \nEpoch: 389 | train_loss: 0.1070 | train_acc: 0.9600 | test_loss: 0.8961 | test_acc: 0.8173 | \nEpoch: 390 | train_loss: 0.1060 | train_acc: 0.9615 | test_loss: 0.9127 | test_acc: 0.8068 | \nEpoch: 391 | train_loss: 0.1015 | train_acc: 0.9606 | test_loss: 0.9929 | test_acc: 0.8138 | \nEpoch: 392 | train_loss: 0.1052 | train_acc: 0.9648 | test_loss: 0.9445 | test_acc: 0.8013 | \nEpoch: 393 | train_loss: 0.1093 | train_acc: 0.9600 | test_loss: 0.9954 | test_acc: 0.7948 | \nEpoch: 394 | train_loss: 0.1340 | train_acc: 0.9529 | test_loss: 0.8644 | test_acc: 0.8008 | \nEpoch: 395 | train_loss: 0.1347 | train_acc: 0.9516 | test_loss: 0.8889 | test_acc: 0.7963 | \nEpoch: 396 | train_loss: 0.1108 | train_acc: 0.9595 | test_loss: 0.9018 | test_acc: 0.7953 | \nEpoch: 397 | train_loss: 0.1128 | train_acc: 0.9597 | test_loss: 0.9674 | test_acc: 0.7938 | \nEpoch: 398 | train_loss: 0.1104 | train_acc: 0.9581 | test_loss: 0.9053 | test_acc: 0.8078 | \nEpoch: 399 | train_loss: 0.0956 | train_acc: 0.9654 | test_loss: 0.9800 | test_acc: 0.8058 | \nEpoch: 400 | train_loss: 0.1106 | train_acc: 0.9590 | test_loss: 0.8811 | test_acc: 0.8128 | \nEpoch: 401 | train_loss: 0.1069 | train_acc: 0.9623 | test_loss: 0.9033 | test_acc: 0.8098 | \nEpoch: 402 | train_loss: 0.1259 | train_acc: 0.9542 | test_loss: 0.9564 | test_acc: 0.8058 | \nEpoch: 403 | train_loss: 0.1410 | train_acc: 0.9500 | test_loss: 0.8483 | test_acc: 0.8083 | \nEpoch: 404 | train_loss: 0.1203 | train_acc: 0.9565 | test_loss: 0.8952 | test_acc: 0.8043 | \nEpoch: 405 | train_loss: 0.1031 | train_acc: 0.9626 | test_loss: 0.8783 | test_acc: 0.8163 | \nEpoch: 406 | train_loss: 0.0940 | train_acc: 0.9654 | test_loss: 0.9307 | test_acc: 0.8048 | \nEpoch: 407 | train_loss: 0.1083 | train_acc: 0.9598 | test_loss: 0.8821 | test_acc: 0.8018 | \nEpoch: 408 | train_loss: 0.1136 | train_acc: 0.9587 | test_loss: 0.8836 | test_acc: 0.8068 | \nEpoch: 409 | train_loss: 0.1178 | train_acc: 0.9563 | test_loss: 1.0395 | test_acc: 0.8048 | \nEpoch: 410 | train_loss: 0.1242 | train_acc: 0.9526 | test_loss: 0.8400 | test_acc: 0.7958 | \nEpoch: 411 | train_loss: 0.1008 | train_acc: 0.9626 | test_loss: 0.9731 | test_acc: 0.8048 | \nEpoch: 412 | train_loss: 0.1160 | train_acc: 0.9541 | test_loss: 0.8678 | test_acc: 0.7923 | \nEpoch: 413 | train_loss: 0.0955 | train_acc: 0.9648 | test_loss: 0.9556 | test_acc: 0.8118 | \nEpoch: 414 | train_loss: 0.1352 | train_acc: 0.9536 | test_loss: 0.8404 | test_acc: 0.8068 | \nEpoch: 415 | train_loss: 0.1167 | train_acc: 0.9590 | test_loss: 0.8959 | test_acc: 0.8003 | \nEpoch: 416 | train_loss: 0.1215 | train_acc: 0.9558 | test_loss: 0.8734 | test_acc: 0.8098 | \nEpoch: 417 | train_loss: 0.1219 | train_acc: 0.9571 | test_loss: 0.8861 | test_acc: 0.7958 | \nEpoch: 418 | train_loss: 0.1061 | train_acc: 0.9613 | test_loss: 0.9509 | test_acc: 0.8043 | \nEpoch: 419 | train_loss: 0.1132 | train_acc: 0.9617 | test_loss: 0.8882 | test_acc: 0.8048 | \nEpoch: 420 | train_loss: 0.1074 | train_acc: 0.9628 | test_loss: 0.8843 | test_acc: 0.7988 | \nEpoch: 421 | train_loss: 0.1062 | train_acc: 0.9621 | test_loss: 0.9094 | test_acc: 0.7988 | \nEpoch: 422 | train_loss: 0.1050 | train_acc: 0.9616 | test_loss: 1.0027 | test_acc: 0.7963 | \nEpoch: 423 | train_loss: 0.1002 | train_acc: 0.9638 | test_loss: 0.9442 | test_acc: 0.8068 | \nEpoch: 424 | train_loss: 0.0983 | train_acc: 0.9635 | test_loss: 0.9758 | test_acc: 0.7763 | \nEpoch: 425 | train_loss: 0.1194 | train_acc: 0.9572 | test_loss: 0.8890 | test_acc: 0.8003 | \nEpoch: 426 | train_loss: 0.1343 | train_acc: 0.9506 | test_loss: 0.8683 | test_acc: 0.8038 | \nEpoch: 427 | train_loss: 0.0891 | train_acc: 0.9694 | test_loss: 0.8784 | test_acc: 0.8008 | \nEpoch: 428 | train_loss: 0.0834 | train_acc: 0.9721 | test_loss: 1.0516 | test_acc: 0.8003 | \nEpoch: 429 | train_loss: 0.1161 | train_acc: 0.9593 | test_loss: 0.8412 | test_acc: 0.8013 | \nEpoch: 430 | train_loss: 0.1136 | train_acc: 0.9595 | test_loss: 0.8470 | test_acc: 0.8063 | \nEpoch: 431 | train_loss: 0.1120 | train_acc: 0.9588 | test_loss: 0.9537 | test_acc: 0.8018 | \nEpoch: 432 | train_loss: 0.1099 | train_acc: 0.9631 | test_loss: 0.8904 | test_acc: 0.7943 | \nEpoch: 433 | train_loss: 0.1126 | train_acc: 0.9592 | test_loss: 0.8419 | test_acc: 0.8023 | \nEpoch: 434 | train_loss: 0.0923 | train_acc: 0.9669 | test_loss: 1.0036 | test_acc: 0.7838 | \nEpoch: 435 | train_loss: 0.1068 | train_acc: 0.9623 | test_loss: 0.8624 | test_acc: 0.8108 | \nEpoch: 436 | train_loss: 0.1151 | train_acc: 0.9590 | test_loss: 0.9240 | test_acc: 0.8008 | \nEpoch: 437 | train_loss: 0.1263 | train_acc: 0.9532 | test_loss: 0.8873 | test_acc: 0.8098 | \nEpoch: 438 | train_loss: 0.0940 | train_acc: 0.9657 | test_loss: 0.8948 | test_acc: 0.8098 | \nEpoch: 439 | train_loss: 0.0835 | train_acc: 0.9686 | test_loss: 0.9482 | test_acc: 0.7938 | \nEpoch: 440 | train_loss: 0.1066 | train_acc: 0.9610 | test_loss: 0.9803 | test_acc: 0.7923 | \nEpoch: 441 | train_loss: 0.1186 | train_acc: 0.9571 | test_loss: 0.9294 | test_acc: 0.7958 | \nEpoch: 442 | train_loss: 0.0992 | train_acc: 0.9640 | test_loss: 0.9448 | test_acc: 0.8018 | \nEpoch: 443 | train_loss: 0.1245 | train_acc: 0.9567 | test_loss: 0.8881 | test_acc: 0.7938 | \nEpoch: 444 | train_loss: 0.1126 | train_acc: 0.9607 | test_loss: 0.8812 | test_acc: 0.7968 | \nEpoch: 445 | train_loss: 0.0972 | train_acc: 0.9659 | test_loss: 0.9314 | test_acc: 0.8103 | \nEpoch: 446 | train_loss: 0.0890 | train_acc: 0.9669 | test_loss: 0.9234 | test_acc: 0.8033 | \nEpoch: 447 | train_loss: 0.1003 | train_acc: 0.9652 | test_loss: 1.0095 | test_acc: 0.8083 | \nEpoch: 448 | train_loss: 0.1035 | train_acc: 0.9631 | test_loss: 0.9256 | test_acc: 0.8078 | \nEpoch: 449 | train_loss: 0.1000 | train_acc: 0.9625 | test_loss: 0.8705 | test_acc: 0.8098 | \nEpoch: 450 | train_loss: 0.0909 | train_acc: 0.9662 | test_loss: 0.9256 | test_acc: 0.8053 | \nEpoch: 451 | train_loss: 0.0884 | train_acc: 0.9697 | test_loss: 0.9545 | test_acc: 0.7943 | \nEpoch: 452 | train_loss: 0.0855 | train_acc: 0.9691 | test_loss: 1.0413 | test_acc: 0.7988 | \nEpoch: 453 | train_loss: 0.0939 | train_acc: 0.9645 | test_loss: 0.9060 | test_acc: 0.7933 | \nEpoch: 454 | train_loss: 0.1019 | train_acc: 0.9635 | test_loss: 0.9807 | test_acc: 0.8083 | \nEpoch: 455 | train_loss: 0.0994 | train_acc: 0.9631 | test_loss: 0.9387 | test_acc: 0.7993 | \nEpoch: 456 | train_loss: 0.0971 | train_acc: 0.9646 | test_loss: 0.9415 | test_acc: 0.8103 | \nEpoch: 457 | train_loss: 0.1067 | train_acc: 0.9598 | test_loss: 0.9553 | test_acc: 0.8038 | \nEpoch: 458 | train_loss: 0.1008 | train_acc: 0.9664 | test_loss: 0.8975 | test_acc: 0.8038 | \nEpoch: 459 | train_loss: 0.1059 | train_acc: 0.9620 | test_loss: 1.0050 | test_acc: 0.7938 | \nEpoch: 460 | train_loss: 0.1138 | train_acc: 0.9596 | test_loss: 0.9569 | test_acc: 0.8038 | \nEpoch: 461 | train_loss: 0.1037 | train_acc: 0.9628 | test_loss: 1.0102 | test_acc: 0.7993 | \nEpoch: 462 | train_loss: 0.1077 | train_acc: 0.9595 | test_loss: 0.8935 | test_acc: 0.8078 | \n","output_type":"stream"}]},{"cell_type":"code","source":"# taking \"y_predicted_train_data\" & \"y_true_train_data\" into 1D array because it came out as batch by batch 2D list\npredicted_train_data_1D = []\ntrue_train_data_1D = []\n\nfor i in range(len(y_predicted_train_data)):\n    for j in range(len(y_predicted_train_data[i])):\n        predicted_train_data_1D.append(y_predicted_train_data[i][j])\n        true_train_data_1D.append(y_true_train_data[i][j])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Truee = 0\nfor i in range(len(true_train_data_1D)):\n    if true_train_data_1D[i] == predicted_train_data_1D[i]:\n        Truee += 1\n\nprint(Truee/len(true_train_data_1D))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluations","metadata":{}},{"cell_type":"code","source":"# taking \"y_predicted_train_data\" & \"y_true_train_data\" into 1D array because it came out as batch by batch 2D list\npredicted_train_data_1D = []\ntrue_train_data_1D = []\n\nfor i in range(len(y_predicted_train_data)):\n    for j in range(len(y_predicted_train_data[i])):\n        predicted_train_data_1D.append(y_predicted_train_data[i][j])\n        true_train_data_1D.append(y_true_train_data[i][j])\n\n# taking both into CPU\npredicted_train_data_cpu = torch.tensor(predicted_train_data_1D, device = 'cpu')\ntrue_train_data_cpu = torch.tensor(true_train_data_1D, device = 'cpu')\n\n\n\n# now same procedure for test data's\npredicted_test_data_1D = []\ntrue_test_data_1D = []\n\nfor i in range(len(y_predicted_test_data)):\n    for j in range(len(y_predicted_test_data[i])):\n        predicted_test_data_1D.append(y_predicted_test_data[i][j])\n        true_test_data_1D.append(y_true_test_data[i][j])\n\n# taking both into CPU\npredicted_test_data_cpu = torch.tensor(predicted_test_data_1D, device = 'cpu')\ntrue_test_data_cpu = torch.tensor(true_test_data_1D, device = 'cpu')\n\n\n\n# now same procedure for best test data's\nbest_predicted_test_data_1D = []\nbest_true_test_data_1D = []\n\nfor i in range(len(best_y_predicted_test_data)):\n    for j in range(len(best_y_predicted_test_data[i])):\n        best_predicted_test_data_1D.append(best_y_predicted_test_data[i][j])\n        best_true_test_data_1D.append(best_y_true_test_data[i][j])\n\n# taking both into CPU\nbest_predicted_test_data_cpu = torch.tensor(best_predicted_test_data_1D, device = 'cpu')\nbest_true_test_data_cpu = torch.tensor(best_true_test_data_1D, device = 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Precision, Recall and F1 scores","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate a classification report\n\n\n# F1 score on train data\ny_true_train = true_train_data_cpu\ny_pred_train = predicted_train_data_cpu\n\nreport = classification_report(y_true_train, y_pred_train, target_names=class_names)\n\nprint(f\"Evaluation report on Train data: \\n\\n{report}\\n\\n\\n\\n\")\n\n\n# F1 score on test data\ny_true_test = true_test_data_cpu\ny_pred_test = predicted_test_data_cpu\n\nreport = classification_report(y_true_test, y_pred_test, target_names=class_names)\n\nprint(f\"Evaluation report on Test data: \\n\\n{report}\")\n\n\n# F1 score on best test score\nbest_y_true_test = best_true_test_data_cpu\nbest_y_pred_test = best_predicted_test_data_cpu\n\nreport = classification_report(best_y_true_test, best_y_pred_test, target_names=class_names)\n\nprint(f\"Evaluation report on Best Test score: \\n\\n{report}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Kappa score","metadata":{}},{"cell_type":"code","source":"from torchmetrics.classification import MulticlassCohenKappa\ntarget = y_true_train\npreds = y_pred_train\nmetric = MulticlassCohenKappa(num_classes=5)\nprint(f\"Kappa score on train data : {metric(preds, target)}\")\n\ntarget = y_true_test\npreds = y_pred_test\nprint(f\"Kappa score on test data : {metric(preds, target)}\")\n\n\ntarget = best_y_true_test\npreds = best_y_pred_test\nprint(f\"Kappa score on Best test score : {metric(preds, target)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Confusion Matrix","metadata":{}},{"cell_type":"code","source":"from torchmetrics import ConfusionMatrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\n# 2. Setup confusion matrix instance and compare predictions to targets\nconfmat = ConfusionMatrix(num_classes=len(class_names), task='multiclass')\nconfmat_tensor = confmat(preds=y_pred_train,\n                         target=y_true_train)\n\n# 3. Plot the confusion matrix\nfig, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy \n    class_names=class_names, # turn the row and column labels into class names\n    figsize=(10, 7)\n);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# 2. Setup confusion matrix instance and compare predictions to targets\nconfmat = ConfusionMatrix(num_classes=len(class_names), task='multiclass')\nconfmat_tensor = confmat(preds=y_pred_test,\n                         target=y_true_test)\n\n# 3. Plot the confusion matrix\nfig, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy \n    class_names=class_names, # turn the row and column labels into class names\n    figsize=(10, 7)\n);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Best Score Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# 2. Setup confusion matrix instance and compare predictions to targets\nconfmat = ConfusionMatrix(num_classes=len(class_names), task='multiclass')\nconfmat_tensor = confmat(preds=best_y_pred_test,\n                         target=best_y_true_test)\n\n# 3. Plot the confusion matrix\nfig, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy \n    class_names=class_names, # turn the row and column labels into class names\n    figsize=(10, 7)\n);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plottings","metadata":{}},{"cell_type":"code","source":"# Get the plot_loss_curves() function from helper_functions.py, download the file if we don't have it\ntry:\n    from going_modular.helper_functions import plot_loss_curves\nexcept:\n    print(\"[INFO] Couldn't find helper_functions.py, downloading...\")\n    # with open(\"helper_functions.py\", \"wb\") as f:\n    #     import requests\n    #     request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n    #     f.write(request.content)\n    # from helper_functions import plot_loss_curves\n\n# Plot the loss curves of our model\nplot_loss_curves(results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}